{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7316,
     "status": "ok",
     "timestamp": 1576595542339,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "9USFNVeqaAxO",
    "outputId": "6304e9b2-81ad-48ea-f73f-a9db10a7a9e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Install TensorFlow\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2519,
     "status": "ok",
     "timestamp": 1576595545404,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "Kxk6MHEaaAxT",
    "outputId": "4ebe036d-febe-4052-d602-6e8d8773563c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
    "input_filepath = \"./shakespeare.txt\"\n",
    "text = open(input_filepath, 'r').read()\n",
    "\n",
    "print(len(text))\n",
    "print(text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MCu7msfaAxX"
   },
   "source": [
    "步骤：  \n",
    "1. 生成词表\n",
    "2. 建立映射 char -> id\n",
    "3. 数据转成id data -> id\n",
    "4. 定义输入输出 abcd -> bcd<eos>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1142,
     "status": "ok",
     "timestamp": 1576595548031,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "pnOMB7J2aAxY",
    "outputId": "f7786a54-aa88-44eb-a5c8-040c3945cd2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# 建立词表\n",
    "vocab = sorted(set(text))    # 建立一个无序不重复元素序列 set(), 并排序 sorted()\n",
    "print(len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2875,
     "status": "ok",
     "timestamp": 1576595551877,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "gS9G8aTCaAxb",
    "outputId": "329e607b-4379-4e90-f416-c2e6b0a3e0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
     ]
    }
   ],
   "source": [
    "char2idx = {char:idx for idx, char in enumerate(vocab)}\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4137,
     "status": "ok",
     "timestamp": 1576595556488,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "cHBk78OCaAxe",
    "outputId": "f37d665f-ba4c-44af-e649-f71f497c8044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n' ' ' '!' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' 'A' 'B' 'C' 'D' 'E'\n",
      " 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W'\n",
      " 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
      " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
     ]
    }
   ],
   "source": [
    "idx2char = np.array(vocab)\n",
    "print(idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3078,
     "status": "ok",
     "timestamp": 1576595565444,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "XF5gJHiuaAx3",
    "outputId": "8afeee4d-d32f-44c7-e0a9-3a7aaeb77d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56]\n",
      "First Citizen:\n",
      "Befor\n"
     ]
    }
   ],
   "source": [
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "print(text_as_int[0: 20])\n",
    "print(text[0: 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8744,
     "status": "ok",
     "timestamp": 1576595575107,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "LgHPCeygaAyN",
    "outputId": "13de9e8e-4fa1-45c9-be6b-f50025c27ecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18, shape=(), dtype=int64) F\n",
      "tf.Tensor(47, shape=(), dtype=int64) i\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59  1]\n",
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
      " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
      " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
      "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
      " 63 53 59  1 49]\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(id_text):\n",
    "    \"\"\"\n",
    "    abcde -> abcd, bcde\n",
    "    \"\"\"\n",
    "    return id_text[0:-1], id_text[1:]\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "seq_length = 100\n",
    "seq_dataset = char_dataset.batch(seq_length + 1, drop_remainder = True)\n",
    "# drop_reminder = True 如果取到最后长度不够，就丢弃\n",
    "\n",
    "for ch_id in char_dataset.take(2):\n",
    "    print(ch_id, idx2char[ch_id.numpy()])\n",
    "    \n",
    "for seq_id in seq_dataset.take(2):\n",
    "    print(seq_id.numpy())\n",
    "    print(repr(''.join(idx2char[seq_id.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3511,
     "status": "ok",
     "timestamp": 1576595580475,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "P0DiBTQlaAyS",
    "outputId": "a1ded77e-13ea-430a-f642-a1582062a15e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59]\n",
      "[47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43  1\n",
      " 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43 39\n",
      " 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49  6\n",
      "  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0\n",
      " 37 53 59  1]\n",
      "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
      " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
      " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
      "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
      " 63 53 59  1]\n",
      "[56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1 58\n",
      " 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0 13\n",
      " 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8  0\n",
      "  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1 63\n",
      " 53 59  1 49]\n"
     ]
    }
   ],
   "source": [
    "seq_dataset = seq_dataset.map(split_input_target)\n",
    "\n",
    "for item_input, item_output in seq_dataset.take(2):\n",
    "    print(item_input.numpy())\n",
    "    print(item_output.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ff2-9bViaAyv"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "\n",
    "seq_dataset = seq_dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4479,
     "status": "ok",
     "timestamp": 1576595593099,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "8zVe0abjaAyy",
    "outputId": "0ead52e3-64e4-4353-b36a-d74c9725277f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (64, None, 1024)          1311744   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 1,395,009\n",
      "Trainable params: 1,395,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape = [batch_size, None]),\n",
    "        keras.layers.SimpleRNN(units = rnn_units, return_sequences = True),\n",
    "        keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim = embedding_dim,\n",
    "    rnn_units = rnn_units,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5613,
     "status": "ok",
     "timestamp": 1576595599644,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "xD6GL4-raAzC",
    "outputId": "edff5ae9-1828-4e9f-f9eb-a7463bccc02d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in seq_dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5335,
     "status": "ok",
     "timestamp": 1576595605443,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "eXOnpDQtaAzZ",
    "outputId": "94308d56-85b8-4d40-ab01-6da3090adf52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[23]\n",
      " [29]\n",
      " [35]\n",
      " [22]\n",
      " [ 4]\n",
      " [ 0]\n",
      " [38]\n",
      " [34]\n",
      " [59]\n",
      " [56]\n",
      " [33]\n",
      " [55]\n",
      " [20]\n",
      " [31]\n",
      " [16]\n",
      " [51]\n",
      " [17]\n",
      " [ 2]\n",
      " [35]\n",
      " [53]\n",
      " [57]\n",
      " [15]\n",
      " [60]\n",
      " [39]\n",
      " [15]\n",
      " [31]\n",
      " [46]\n",
      " [60]\n",
      " [31]\n",
      " [64]\n",
      " [47]\n",
      " [15]\n",
      " [61]\n",
      " [53]\n",
      " [54]\n",
      " [43]\n",
      " [40]\n",
      " [43]\n",
      " [51]\n",
      " [ 6]\n",
      " [33]\n",
      " [42]\n",
      " [47]\n",
      " [26]\n",
      " [52]\n",
      " [18]\n",
      " [48]\n",
      " [35]\n",
      " [14]\n",
      " [63]\n",
      " [ 2]\n",
      " [59]\n",
      " [15]\n",
      " [27]\n",
      " [11]\n",
      " [ 9]\n",
      " [26]\n",
      " [59]\n",
      " [58]\n",
      " [37]\n",
      " [26]\n",
      " [18]\n",
      " [43]\n",
      " [ 1]\n",
      " [30]\n",
      " [17]\n",
      " [54]\n",
      " [58]\n",
      " [30]\n",
      " [12]\n",
      " [44]\n",
      " [33]\n",
      " [36]\n",
      " [17]\n",
      " [21]\n",
      " [ 2]\n",
      " [10]\n",
      " [48]\n",
      " [35]\n",
      " [59]\n",
      " [56]\n",
      " [33]\n",
      " [58]\n",
      " [63]\n",
      " [64]\n",
      " [ 1]\n",
      " [20]\n",
      " [ 9]\n",
      " [38]\n",
      " [35]\n",
      " [16]\n",
      " [35]\n",
      " [29]\n",
      " [44]\n",
      " [11]\n",
      " [54]\n",
      " [34]\n",
      " [19]\n",
      " [50]\n",
      " [36]], shape=(100, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[23 29 35 22  4  0 38 34 59 56 33 55 20 31 16 51 17  2 35 53 57 15 60 39\n",
      " 15 31 46 60 31 64 47 15 61 53 54 43 40 43 51  6 33 42 47 26 52 18 48 35\n",
      " 14 63  2 59 15 27 11  9 26 59 58 37 26 18 43  1 30 17 54 58 30 12 44 33\n",
      " 36 17 21  2 10 48 35 59 56 33 58 63 64  1 20  9 38 35 16 35 29 44 11 54\n",
      " 34 19 50 36], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 随机采样\n",
    "sample_indices = tf.random.categorical(\n",
    "    logits = example_batch_predictions[0], num_samples = 1)\n",
    "print(sample_indices)\n",
    "# (100, 65) -> (100, 1)\n",
    "sample_indices = tf.squeeze(sample_indices, axis = -1)\n",
    "# 降低维度 (100, 1) -> (100, )\n",
    "print(sample_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1359,
     "status": "ok",
     "timestamp": 1576595606234,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "MH3KY4KNaAzf",
    "outputId": "4ebe6926-4afc-487a-9a0a-7df25169f9db",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  'me!\\n\\nFirst Conspirator:\\nHow is it with our general?\\n\\nAUFIDIUS:\\nEven so\\nAs with a man by his own alms'\n",
      "\n",
      "Output:  'e!\\n\\nFirst Conspirator:\\nHow is it with our general?\\n\\nAUFIDIUS:\\nEven so\\nAs with a man by his own alms '\n",
      "\n",
      "Predictions:  'KQWJ&\\nZVurUqHSDmE!WosCvaCShvSziCwopebem,UdiNnFjWBy!uCO;3NutYNFe REptR?fUXEI!:jWurUtyz H3ZWDWQf;pVGlX'\n"
     ]
    }
   ],
   "source": [
    "# 输出演示\n",
    "print(\"Input: \", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Output: \", repr(\"\".join(idx2char[target_example_batch[0]])))\n",
    "print()\n",
    "print(\"Predictions: \", repr(\"\".join(idx2char[sample_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2782,
     "status": "ok",
     "timestamp": 1576595614984,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "_1A4GYT2aAzo",
    "outputId": "2e265eb4-cd82-40ce-92d6-1e7b27c080eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100)\n",
      "4.1838703\n"
     ]
    }
   ],
   "source": [
    "# 自定义一个loss\n",
    "def loss(labels, logits):\n",
    "    return keras.losses.sparse_categorical_crossentropy(\n",
    "        labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "example_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(example_loss.shape)\n",
    "print(example_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2273805,
     "status": "ok",
     "timestamp": 1576597889932,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "jfEUQv0maAzx",
    "outputId": "e88d97b5-447c-46c1-cb29-980211537763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 172 steps\n",
      "Epoch 1/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 2.6805\n",
      "Epoch 00001: saving model to training_text_generation_1/cp-0001.ckpt\n",
      "172/172 [==============================] - 24s 137ms/step - loss: 2.6778\n",
      "Epoch 2/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 2.0449\n",
      "Epoch 00002: saving model to training_text_generation_1/cp-0002.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 2.0440\n",
      "Epoch 3/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.8308\n",
      "Epoch 00003: saving model to training_text_generation_1/cp-0003.ckpt\n",
      "172/172 [==============================] - 23s 133ms/step - loss: 1.8305\n",
      "Epoch 4/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.6919\n",
      "Epoch 00004: saving model to training_text_generation_1/cp-0004.ckpt\n",
      "172/172 [==============================] - 22s 130ms/step - loss: 1.6918\n",
      "Epoch 5/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.5965\n",
      "Epoch 00005: saving model to training_text_generation_1/cp-0005.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.5964\n",
      "Epoch 6/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.5286\n",
      "Epoch 00006: saving model to training_text_generation_1/cp-0006.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.5284\n",
      "Epoch 7/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.4792\n",
      "Epoch 00007: saving model to training_text_generation_1/cp-0007.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.4793\n",
      "Epoch 8/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.4396\n",
      "Epoch 00008: saving model to training_text_generation_1/cp-0008.ckpt\n",
      "172/172 [==============================] - 23s 133ms/step - loss: 1.4396\n",
      "Epoch 9/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.4100\n",
      "Epoch 00009: saving model to training_text_generation_1/cp-0009.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.4099\n",
      "Epoch 10/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.3841\n",
      "Epoch 00010: saving model to training_text_generation_1/cp-0010.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 1.3840\n",
      "Epoch 11/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.3620\n",
      "Epoch 00011: saving model to training_text_generation_1/cp-0011.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.3623\n",
      "Epoch 12/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.3419\n",
      "Epoch 00012: saving model to training_text_generation_1/cp-0012.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 1.3420\n",
      "Epoch 13/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.3217\n",
      "Epoch 00013: saving model to training_text_generation_1/cp-0013.ckpt\n",
      "172/172 [==============================] - 22s 131ms/step - loss: 1.3219\n",
      "Epoch 14/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.3025\n",
      "Epoch 00014: saving model to training_text_generation_1/cp-0014.ckpt\n",
      "172/172 [==============================] - 22s 130ms/step - loss: 1.3029\n",
      "Epoch 15/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.2877\n",
      "Epoch 00015: saving model to training_text_generation_1/cp-0015.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 1.2875\n",
      "Epoch 16/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.2741\n",
      "Epoch 00016: saving model to training_text_generation_1/cp-0016.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.2738\n",
      "Epoch 17/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.2560\n",
      "Epoch 00017: saving model to training_text_generation_1/cp-0017.ckpt\n",
      "172/172 [==============================] - 23s 133ms/step - loss: 1.2562\n",
      "Epoch 18/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.2430\n",
      "Epoch 00018: saving model to training_text_generation_1/cp-0018.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.2428\n",
      "Epoch 19/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.2284\n",
      "Epoch 00019: saving model to training_text_generation_1/cp-0019.ckpt\n",
      "172/172 [==============================] - 23s 134ms/step - loss: 1.2287\n",
      "Epoch 20/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.2153\n",
      "Epoch 00020: saving model to training_text_generation_1/cp-0020.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.2154\n",
      "Epoch 21/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.2011\n",
      "Epoch 00021: saving model to training_text_generation_1/cp-0021.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.2012\n",
      "Epoch 22/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.1855\n",
      "Epoch 00022: saving model to training_text_generation_1/cp-0022.ckpt\n",
      "172/172 [==============================] - 23s 133ms/step - loss: 1.1854\n",
      "Epoch 23/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.1732\n",
      "Epoch 00023: saving model to training_text_generation_1/cp-0023.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.1735\n",
      "Epoch 24/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.1601\n",
      "Epoch 00024: saving model to training_text_generation_1/cp-0024.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.1605\n",
      "Epoch 25/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.1480\n",
      "Epoch 00025: saving model to training_text_generation_1/cp-0025.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.1483\n",
      "Epoch 26/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.1344\n",
      "Epoch 00026: saving model to training_text_generation_1/cp-0026.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.1342\n",
      "Epoch 27/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.1235\n",
      "Epoch 00027: saving model to training_text_generation_1/cp-0027.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.1234\n",
      "Epoch 28/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.1091\n",
      "Epoch 00028: saving model to training_text_generation_1/cp-0028.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.1094\n",
      "Epoch 29/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0998\n",
      "Epoch 00029: saving model to training_text_generation_1/cp-0029.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.1001\n",
      "Epoch 30/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0879\n",
      "Epoch 00030: saving model to training_text_generation_1/cp-0030.ckpt\n",
      "172/172 [==============================] - 23s 133ms/step - loss: 1.0880\n",
      "Epoch 31/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0798\n",
      "Epoch 00031: saving model to training_text_generation_1/cp-0031.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0800\n",
      "Epoch 32/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0642\n",
      "Epoch 00032: saving model to training_text_generation_1/cp-0032.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0644\n",
      "Epoch 33/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0558\n",
      "Epoch 00033: saving model to training_text_generation_1/cp-0033.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0559\n",
      "Epoch 34/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0450\n",
      "Epoch 00034: saving model to training_text_generation_1/cp-0034.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0452\n",
      "Epoch 35/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0364\n",
      "Epoch 00035: saving model to training_text_generation_1/cp-0035.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 1.0366\n",
      "Epoch 36/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0278\n",
      "Epoch 00036: saving model to training_text_generation_1/cp-0036.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0279\n",
      "Epoch 37/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0209\n",
      "Epoch 00037: saving model to training_text_generation_1/cp-0037.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 1.0211\n",
      "Epoch 38/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0110\n",
      "Epoch 00038: saving model to training_text_generation_1/cp-0038.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0111\n",
      "Epoch 39/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0038\n",
      "Epoch 00039: saving model to training_text_generation_1/cp-0039.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0040\n",
      "Epoch 40/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9946\n",
      "Epoch 00040: saving model to training_text_generation_1/cp-0040.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9950\n",
      "Epoch 41/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9941\n",
      "Epoch 00041: saving model to training_text_generation_1/cp-0041.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9940\n",
      "Epoch 42/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9852\n",
      "Epoch 00042: saving model to training_text_generation_1/cp-0042.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 0.9854\n",
      "Epoch 43/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9802\n",
      "Epoch 00043: saving model to training_text_generation_1/cp-0043.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 0.9805\n",
      "Epoch 44/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9744\n",
      "Epoch 00044: saving model to training_text_generation_1/cp-0044.ckpt\n",
      "172/172 [==============================] - 23s 133ms/step - loss: 0.9746\n",
      "Epoch 45/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9690\n",
      "Epoch 00045: saving model to training_text_generation_1/cp-0045.ckpt\n",
      "172/172 [==============================] - 23s 133ms/step - loss: 0.9692\n",
      "Epoch 46/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9701\n",
      "Epoch 00046: saving model to training_text_generation_1/cp-0046.ckpt\n",
      "172/172 [==============================] - 23s 134ms/step - loss: 0.9701\n",
      "Epoch 47/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9651\n",
      "Epoch 00047: saving model to training_text_generation_1/cp-0047.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9653\n",
      "Epoch 48/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9618\n",
      "Epoch 00048: saving model to training_text_generation_1/cp-0048.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9620\n",
      "Epoch 49/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9587\n",
      "Epoch 00049: saving model to training_text_generation_1/cp-0049.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 0.9588\n",
      "Epoch 50/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9560\n",
      "Epoch 00050: saving model to training_text_generation_1/cp-0050.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9561\n",
      "Epoch 51/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9531\n",
      "Epoch 00051: saving model to training_text_generation_1/cp-0051.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9531\n",
      "Epoch 52/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9538\n",
      "Epoch 00052: saving model to training_text_generation_1/cp-0052.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9540\n",
      "Epoch 53/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9525\n",
      "Epoch 00053: saving model to training_text_generation_1/cp-0053.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9528\n",
      "Epoch 54/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9529\n",
      "Epoch 00054: saving model to training_text_generation_1/cp-0054.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9531\n",
      "Epoch 55/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9488\n",
      "Epoch 00055: saving model to training_text_generation_1/cp-0055.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9491\n",
      "Epoch 56/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9496\n",
      "Epoch 00056: saving model to training_text_generation_1/cp-0056.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9496\n",
      "Epoch 57/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9505\n",
      "Epoch 00057: saving model to training_text_generation_1/cp-0057.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9509\n",
      "Epoch 58/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9504\n",
      "Epoch 00058: saving model to training_text_generation_1/cp-0058.ckpt\n",
      "172/172 [==============================] - 23s 135ms/step - loss: 0.9506\n",
      "Epoch 59/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9510\n",
      "Epoch 00059: saving model to training_text_generation_1/cp-0059.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9513\n",
      "Epoch 60/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9522\n",
      "Epoch 00060: saving model to training_text_generation_1/cp-0060.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 0.9523\n",
      "Epoch 61/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9545\n",
      "Epoch 00061: saving model to training_text_generation_1/cp-0061.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9547\n",
      "Epoch 62/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9548\n",
      "Epoch 00062: saving model to training_text_generation_1/cp-0062.ckpt\n",
      "172/172 [==============================] - 23s 133ms/step - loss: 0.9548\n",
      "Epoch 63/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9561\n",
      "Epoch 00063: saving model to training_text_generation_1/cp-0063.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9563\n",
      "Epoch 64/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9604\n",
      "Epoch 00064: saving model to training_text_generation_1/cp-0064.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9606\n",
      "Epoch 65/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9572\n",
      "Epoch 00065: saving model to training_text_generation_1/cp-0065.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9574\n",
      "Epoch 66/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9604\n",
      "Epoch 00066: saving model to training_text_generation_1/cp-0066.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9606\n",
      "Epoch 67/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9642\n",
      "Epoch 00067: saving model to training_text_generation_1/cp-0067.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9643\n",
      "Epoch 68/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9664\n",
      "Epoch 00068: saving model to training_text_generation_1/cp-0068.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 0.9664\n",
      "Epoch 69/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9690\n",
      "Epoch 00069: saving model to training_text_generation_1/cp-0069.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9691\n",
      "Epoch 70/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9671\n",
      "Epoch 00070: saving model to training_text_generation_1/cp-0070.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9672\n",
      "Epoch 71/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9758\n",
      "Epoch 00071: saving model to training_text_generation_1/cp-0071.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9761\n",
      "Epoch 72/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9735\n",
      "Epoch 00072: saving model to training_text_generation_1/cp-0072.ckpt\n",
      "172/172 [==============================] - 22s 130ms/step - loss: 0.9739\n",
      "Epoch 73/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9787\n",
      "Epoch 00073: saving model to training_text_generation_1/cp-0073.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9788\n",
      "Epoch 74/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9804\n",
      "Epoch 00074: saving model to training_text_generation_1/cp-0074.ckpt\n",
      "172/172 [==============================] - 23s 133ms/step - loss: 0.9807\n",
      "Epoch 75/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9830\n",
      "Epoch 00075: saving model to training_text_generation_1/cp-0075.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9833\n",
      "Epoch 76/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9884\n",
      "Epoch 00076: saving model to training_text_generation_1/cp-0076.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9885\n",
      "Epoch 77/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9904\n",
      "Epoch 00077: saving model to training_text_generation_1/cp-0077.ckpt\n",
      "172/172 [==============================] - 23s 133ms/step - loss: 0.9905\n",
      "Epoch 78/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.9979\n",
      "Epoch 00078: saving model to training_text_generation_1/cp-0078.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.9979\n",
      "Epoch 79/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0007\n",
      "Epoch 00079: saving model to training_text_generation_1/cp-0079.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0009\n",
      "Epoch 80/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0033\n",
      "Epoch 00080: saving model to training_text_generation_1/cp-0080.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0033\n",
      "Epoch 81/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0073\n",
      "Epoch 00081: saving model to training_text_generation_1/cp-0081.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0074\n",
      "Epoch 82/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0098\n",
      "Epoch 00082: saving model to training_text_generation_1/cp-0082.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0097\n",
      "Epoch 83/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0108\n",
      "Epoch 00083: saving model to training_text_generation_1/cp-0083.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 1.0110\n",
      "Epoch 84/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0192\n",
      "Epoch 00084: saving model to training_text_generation_1/cp-0084.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 1.0192\n",
      "Epoch 85/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0287\n",
      "Epoch 00085: saving model to training_text_generation_1/cp-0085.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0288\n",
      "Epoch 86/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0308\n",
      "Epoch 00086: saving model to training_text_generation_1/cp-0086.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0311\n",
      "Epoch 87/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0340\n",
      "Epoch 00087: saving model to training_text_generation_1/cp-0087.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 1.0342\n",
      "Epoch 88/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0355\n",
      "Epoch 00088: saving model to training_text_generation_1/cp-0088.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0357\n",
      "Epoch 89/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0384\n",
      "Epoch 00089: saving model to training_text_generation_1/cp-0089.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0385\n",
      "Epoch 90/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0443\n",
      "Epoch 00090: saving model to training_text_generation_1/cp-0090.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0443\n",
      "Epoch 91/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0472\n",
      "Epoch 00091: saving model to training_text_generation_1/cp-0091.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 1.0474\n",
      "Epoch 92/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0549\n",
      "Epoch 00092: saving model to training_text_generation_1/cp-0092.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0551\n",
      "Epoch 93/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0629\n",
      "Epoch 00093: saving model to training_text_generation_1/cp-0093.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 1.0628\n",
      "Epoch 94/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0620\n",
      "Epoch 00094: saving model to training_text_generation_1/cp-0094.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 1.0621\n",
      "Epoch 95/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0670\n",
      "Epoch 00095: saving model to training_text_generation_1/cp-0095.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0671\n",
      "Epoch 96/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0784\n",
      "Epoch 00096: saving model to training_text_generation_1/cp-0096.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0785\n",
      "Epoch 97/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0741\n",
      "Epoch 00097: saving model to training_text_generation_1/cp-0097.ckpt\n",
      "172/172 [==============================] - 22s 131ms/step - loss: 1.0740\n",
      "Epoch 98/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0846\n",
      "Epoch 00098: saving model to training_text_generation_1/cp-0098.ckpt\n",
      "172/172 [==============================] - 22s 131ms/step - loss: 1.0847\n",
      "Epoch 99/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0810\n",
      "Epoch 00099: saving model to training_text_generation_1/cp-0099.ckpt\n",
      "172/172 [==============================] - 23s 131ms/step - loss: 1.0811\n",
      "Epoch 100/100\n",
      "171/172 [============================>.] - ETA: 0s - loss: 1.0953\n",
      "Epoch 00100: saving model to training_text_generation_1/cp-0100.ckpt\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 1.0954\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"training_text_generation_1/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback_mc = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                        save_weights_only=True,\n",
    "                                                        #save_best_only=True,\n",
    "                                                        #monitor='val_loss',\n",
    "                                                        mode='min',\n",
    "                                                        verbose=1)\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if(latest != None):\n",
    "    model.load_weights(latest).expect_partial()\n",
    "\n",
    "epochs = 100\n",
    "history = model.fit(seq_dataset, epochs = epochs, callbacks = [cp_callback_mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4193,
     "status": "ok",
     "timestamp": 1576599229057,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "Xp3U-BKYaA0P",
    "outputId": "507161f6-e172-4efd-9ade-806647e5caa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (1, None, 1024)           1311744   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 1,395,009\n",
      "Trainable params: 1,395,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model(vocab_size, embedding_dim, rnn_units, batch_size = 1)\n",
    "\n",
    "model2.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model2.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8151,
     "status": "ok",
     "timestamp": 1576601180065,
     "user": {
      "displayName": "judge light",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAbBKnMf61yxumCoV0lkDACkCfKKlRDbYywoxlJ=s64",
      "userId": "12258727883552654132"
     },
     "user_tz": -480
    },
    "id": "Op2rgIzFtiV9",
    "outputId": "1a237828-5999-49d3-8b51-bbae489b0ca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: bulthalithayorelad akede. brena ththerst s,\n",
      "AUSin borame\n",
      "AR' na se ere m Y; l herulerugu ALOLI icooby.\n",
      "USonowedis anthowhut ancupth afif wilourcicanema llomurat bugile' ais th he mo he ky, torcomaimed tyous le ee?\n",
      "MULI thorciou t yowhe wlis th, chak.\n",
      "STwhyblorge the ckesilit bea nth IENI:\n",
      "Ande g,\n",
      "\n",
      "\n",
      "Pl tuse,\n",
      "sty rod ir torome\n",
      "Wispom wheanos thispr micoo hove s se ond halleanelesthas cke esombomedr?\n",
      "NThe ts thasw if l l ounge IIstlus,\n",
      "K:\n",
      "\n",
      "ICKEngin ind, mu, t.\n",
      "Thaise my the fus fany.\n",
      "\n",
      "\n",
      "\n",
      "Hoffanowed culonthanoust ge s pen thered f s u angurs IER:\n",
      "F stht thery, llthour'LOf h Yoce y.\n",
      "IUS:\n",
      "Shalerir, m\n",
      "pl, pr s IO:\n",
      "Thake RWh wat ofyo gin?\n",
      "AULo sorainovirsel, t than.\n",
      "TEYOHEThyor th honu man'Thowiss ban, the m hoo this m t tase poche pledurs fll ge SIOut y home;\n",
      "FRGK:\n",
      "CANI hanthamonall sown the bimou thim'st:\n",
      "Vint,\n",
      "MER: INI anan sance, an: he t.\n",
      "O:\n",
      "Thaur al then RINULAR:\n",
      "He ntyos'lont, here anors ds ais igomanok abur\n",
      "Henet h your' ithise bisulenf sththe INNad t felle an:\n",
      "\n",
      "\n",
      "\n",
      "ASUKE: t iche thend is\n"
     ]
    }
   ],
   "source": [
    "# 文本生成流程\n",
    "# start ch sequence A,\n",
    "# A -> model -> b\n",
    "# A.append(b) -> B\n",
    "# B(Ab) -> model -> c\n",
    "# B.append(c) -> C\n",
    "# C(Abc) -> model -> ...\n",
    "\n",
    "def generate_text(model, start_string, num_generate = 1000):\n",
    "    input_eval = [char2idx[ch] for ch in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)     # 输入的句子(idx格式)\n",
    "    \n",
    "    text_generated = []    # 生成的句子\n",
    "    model.reset_states()\n",
    "    \n",
    "    for _ in range(num_generate):\n",
    "        # 1. model inferrence -> predictions\n",
    "        # 2. sample -> ch -> text_generated\n",
    "        # 3. update input_eval\n",
    "        \n",
    "        # predictions : [batch_size, input_eval_len, vocab_size]\n",
    "        predictions = model(input_eval)\n",
    "        # predictions : [input_eval_len, vocab_size]\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # predicted_ids: [input_eval_len, 1]\n",
    "        # a b c -> b c d\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1, 0].numpy()\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        # s, x -> rnn -> s', y\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    return start_string + ''.join(text_generated)\n",
    "\n",
    "new_text = generate_text(model2, \"All: \")\n",
    "print(new_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
