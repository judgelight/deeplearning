{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset ted_hrlr_translate (124.94 MiB) to C:\\Users\\vexz_\\tensorflow_datasets\\ted_hrlr_translate\\pt_to_en\\0.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6aec3479f0442498abd2d99b6a81c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2feb3e15321432da4221c84426850fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dbadf8cc0441668f7e5907ce8896c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Shuffling...', max=1.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\program files\\python\\python37-64\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\program files\\python\\python37-64\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Reading...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Writing...', max=51785.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Shuffling...', max=1.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Reading...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Writing...', max=1193.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Shuffling...', max=1.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Reading...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Writing...', max=1803.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[1mDataset ted_hrlr_translate downloaded and prepared to C:\\Users\\vexz_\\tensorflow_datasets\\ted_hrlr_translate\\pt_to_en\\0.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从训练数据集创建自定义子词分词器（subwords tokenizer）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "# 如果单词不在词典中，则分词器（tokenizer）通过将单词分解为子词来对字符串进行编码\n",
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将开始和结束标记（token）添加到输入和目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为了使本示例较小且相对较快，删除长度大于40个标记的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ".map() 内部的操作以图模式（graph mode）运行，.map() 接收一个不具有\n",
    "numpy 属性的图张量（graph tensor）。该分词器（tokenizer）需要将一个\n",
    "字符串或 Unicode 符号，编码成整数。因此，您需要在 tf.py_function \n",
    "内部运行编码过程，tf.py_function 接收一个 eager 张量，该 eager 张量\n",
    "有一个包含字符串值的numpy 属性。\n",
    "\"\"\"\n",
    "def tf_encode(pt, en):\n",
    "  return tf.py_function(encode, [pt, en], [tf.int64, tf.int64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# 将数据集缓存到内存中以加快读取速度。\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([-1], [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=207714, shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8214, 1259,    5, ...,    0,    0,    0],\n",
       "        [8214,  299,   13, ...,    0,    0,    0],\n",
       "        [8214,   59,    8, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8214,   95,    3, ...,    0,    0,    0],\n",
       "        [8214, 5157,    1, ...,    0,    0,    0],\n",
       "        [8214, 4479, 7990, ...,    0,    0,    0]], dtype=int64)>,\n",
       " <tf.Tensor: id=207715, shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8087,   18,   12, ...,    0,    0,    0],\n",
       "        [8087,  634,   30, ...,    0,    0,    0],\n",
       "        [8087,   16,   13, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8087,   12,   20, ...,    0,    0,    0],\n",
       "        [8087,   17, 4981, ...,    0,    0,    0],\n",
       "        [8087,   12, 5453, ...,    0,    0,    0]], dtype=int64)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 位置编码（Positional encoding）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为该模型并不包括任何的循环（recurrence）或卷积，所以模型添加了位置编码，为模型提供一些关于单词在句子中相对位置的信息。\n",
    "\n",
    "位置编码向量被加到嵌入（embedding）向量中。嵌入表示一个 d 维空间的标记，在 d 维空间中有着相似含义的标记会离彼此更近。但是，嵌入并没有对在一句话中的词的相对位置进行编码。因此，当加上位置编码后，词将基于它们含义的相似度以及它们在句子中的位置，在 d 维空间中离彼此更近。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # 将 sin 应用于数组中的偶数索引（indices）；2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # 将 cos 应用于数组中的奇数索引；2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 遮挡（Masking）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遮挡一批序列中所有的填充标记（pad tokens）。这确保了模型不会将填充作为输入。该 mask 表明填充值 0 出现的位置：在这些位置 mask 输出 1，否则输出 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=207729, shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # 添加额外的维度来将填充加到\n",
    "  # 注意力对数（logits）。\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前瞻遮挡（look-ahead mask）用于遮挡一个序列中的后续标记（future tokens）。换句话说，该 mask 表明了不应该使用的条目。\n",
    "\n",
    "这意味着要预测第三个词，将仅使用第一个和第二个词。与此类似，预测第四个词，仅使用第一个，第二个和第三个词，依此类推。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=305302, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)\n",
    "\n",
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按比缩放的点积注意力（Scaled dot product attention）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 使用的注意力函数有三个输入：Q（请求（query））、K（主键（key））、V（数值（value））。\n",
    "\n",
    "点积注意力被缩小了深度的平方根倍。这样做是因为对于较大的深度值，点积的大小会增大，从而推动 softmax 函数往仅有很小的梯度的方向靠拢，导致了一种很硬的（hard）softmax。\n",
    "\n",
    "例如，假设 Q 和 K 的均值为0，方差为1。它们的矩阵乘积将有均值为0，方差为 dk。因此，dk 的平方根被用于缩放（而非其他数值），因为，Q 和 K 的矩阵乘积的均值本应该为 0，方差本应该为1，这样会获得一个更平缓的 softmax。\n",
    "\n",
    "遮挡（mask）与 -1e9（接近于负无穷）相乘。这样做是因为遮挡与缩放的 Q 和 K 的矩阵乘积相加，并在 softmax 之前立即应用。目标是将这些单元归零，因为 softmax 的较大负数输入在输出中接近于零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"计算注意力权重。\n",
    "  q, k, v 必须具有匹配的前置维度。\n",
    "  k, v 必须有匹配的倒数第二个维度，例如：seq_len_k = seq_len_v。\n",
    "  虽然 mask 根据其类型（填充或前瞻）有不同的形状，\n",
    "  但是 mask 必须能进行广播转换以便求和。\n",
    "  \n",
    "  参数:\n",
    "    q: 请求的形状 == (..., seq_len_q, depth)\n",
    "    k: 主键的形状 == (..., seq_len_k, depth)\n",
    "    v: 数值的形状 == (..., seq_len_v, depth_v)\n",
    "    mask: Float 张量，其形状能转换成\n",
    "          (..., seq_len_q, seq_len_k)。默认为None。\n",
    "    \n",
    "  返回值:\n",
    "    输出，注意力权重\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # 缩放 matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # 将 mask 加入到缩放的张量上。\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax 在最后一个轴（seq_len_k）上归一化，因此分数\n",
    "  # 相加等于1。\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当 softmax 在 K 上进行归一化后，它的值决定了分配到 Q 的重要程度。\n",
    "\n",
    "输出表示注意力权重和 V（数值）向量的乘积。这确保了要关注的词保持原样，而无关的词将被清除掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# 这条 `请求（query）符合第二个`主键（key）`，\n",
    "# 因此返回了第二个`数值（value）`。\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 这条请求符合重复出现的主键（第三第四个），\n",
    "# 因此，对所有的相关数值取了平均。\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 这条请求符合第一和第二条主键，\n",
    "# 因此，对它们的数值去了平均。\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 将所有请求一起传递。\n",
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多头注意力（Multi-head attention）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "头注意力由四部分组成：\n",
    "\n",
    "* 线性层并分拆成多头。\n",
    "* 按比缩放的点积注意力。\n",
    "* 多头及联。\n",
    "* 最后一层线性层。  \n",
    "每个多头注意力块有三个输入：Q（请求）、K（主键）、V（数值）。这些输入经过线性（Dense）层，并分拆成多头。\n",
    "\n",
    "将上面定义的 scaled_dot_product_attention 函数应用于每个头（进行了广播（broadcasted）以提高效率）。注意力这步必须使用一个恰当的 mask。然后将每个头的注意力输出连接起来（用tf.transpose 和 tf.reshape），并放入最后的 Dense 层。\n",
    "\n",
    "Q、K、和 V 被拆分到了多个头，而非单个的注意力头，因为多头允许模型共同注意来自不同表示空间的不同位置的信息。在分拆后，每个头部的维度减少，因此总的计算成本与有着全部维度的单个注意力头相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"分拆最后一个维度到 (num_heads, depth).\n",
    "    转置结果使得形状为 (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个 MultiHeadAttention 层进行尝试。在序列中的每个位置 y，MultiHeadAttention 在序列中的所有其他位置运行所有8个注意力头，在每个位置y，返回一个新的同样长度的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 点式前馈网络（Point wise feed forward network）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 点式前馈网络由两层全联接层组成，两层之间有一个 ReLU 激活函数。\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])\n",
    "\n",
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 编码与解码（Encoder and decoder）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 模型与标准的具有注意力机制的序列到序列模型（sequence to sequence with attention model），遵循相同的一般模式。\n",
    "\n",
    "  * 输入语句经过 N 个编码器层，为序列中的每个词/标记生成一个输出。\n",
    "  * 解码器关注编码器的输出以及它自身的输入（自注意力）来预测下一个词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 编码器层（Encoder layer）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个编码器层包括以下子层：\n",
    "\n",
    "多头注意力（有填充遮挡）\n",
    "  1. 点式前馈网络（Point wise feed forward networks）。\n",
    "  2. 每个子层在其周围有一个残差连接，然后进行层归一化。残差连接有助于避免深度网络中的梯度消失问题。\n",
    "\n",
    "每个子层的输出是 LayerNorm(x + Sublayer(x))。归一化是在 d_model（最后一个）维度完成的。Transformer 中有 N 个编码器层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 解码器层（Decoder layer）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个解码器层包括以下子层：\n",
    "\n",
    "  1. 遮挡的多头注意力（前瞻遮挡和填充遮挡）\n",
    "  2. 多头注意力（用填充遮挡）。V（数值）和 K（主键）接收编码器输出作为输入。Q（请求）接收遮挡的多头注意力子层的输出。\n",
    "  3. 点式前馈网络\n",
    "每个子层在其周围有一个残差连接，然后进行层归一化。每个子层的输出是 LayerNorm(x + Sublayer(x))。归一化是在 d_model（最后一个）维度完成的。\n",
    "\n",
    "Transformer 中共有 N 个解码器层。\n",
    "\n",
    "当 Q 接收到解码器的第一个注意力块的输出，并且 K 接收到编码器的输出时，注意力权重表示根据编码器的输出赋予解码器输入的重要性。换一种说法，解码器通过查看编码器输出和对其自身输出的自注意力，预测下一个词。参看按比缩放的点积注意力部分的演示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 编码器（Encoder）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编码器 包括：\n",
    "\n",
    "  1. 输入嵌入（Input Embedding）\n",
    "  2. 位置编码（Positional Encoding）\n",
    "  3. N 个编码器层（encoder layers）\n",
    "输入经过嵌入（embedding）后，该嵌入与位置编码相加。该加法结果的输出是编码器层的输入。编码器的输出是解码器的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # 将嵌入和位置编码相加。\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "\n",
    "sample_encoder_output = sample_encoder(tf.random.uniform((64, 62)), \n",
    "                                       training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解码器（Decoder）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解码器包括：\n",
    "\n",
    "  1. 输出嵌入（Output Embedding）\n",
    "  2. 位置编码（Positional Encoding）\n",
    "  3. N 个解码器层（decoder layers）\n",
    "目标（target）经过一个嵌入后，该嵌入和位置编码相加。该加法结果是解码器层的输入。解码器的输出是最后的线性层的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "\n",
    "output, attn = sample_decoder(tf.random.uniform((64, 26)), \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False, look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建 Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 包括编码器，解码器和最后的线性层。解码器的输出是线性层的输入，返回线性层的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 26, 8000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 62))\n",
    "temp_target = tf.random.uniform((64, 26))\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 配置超参数（hyperparameters）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了让本示例小且相对较快，已经减小了num_layers、 d_model 和 dff 的值。\n",
    "\n",
    "Transformer 的基础模型使用的数值为：num_layers=6，d_model = 512，dff = 2048。关于所有其他版本的 Transformer，请查阅论文。\n",
    "\n",
    "Note：通过改变以下数值，您可以获得在许多任务上达到最先进水平的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 优化器（Optimizer）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据论文中的公式，将 Adam 优化器与自定义的学习速率调度程序（scheduler）配合使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 损失函数与指标（Loss and metrics）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于目标序列是填充（padded）过的，因此在计算损失函数时，应用填充遮挡非常重要。\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_mean(loss_)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练与检查点（Training and checkpointing）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # 编码器填充遮挡\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # 在解码器的第二个注意力模块使用。\n",
    "  # 该填充遮挡用于遮挡编码器的输出。\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # 在解码器的第一个注意力模块使用。\n",
    "  # 用于填充（pad）和遮挡（mask）解码器获取到的输入的后续标记（future tokens）。\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建检查点的路径和检查点管理器（manager）。这将用于在每 n 个周期（epochs）保存检查点。\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 如果检查点存在，则恢复最新的检查点。\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标（target）被分成了 tar_inp 和 tar_real。tar_inp 作为输入传递到解码器。tar_real 是位移了 1 的同一个输入：在 tar_inp 中的每个位置，tar_real 包含了应该被预测到的下一个标记（token）。\n",
    "\n",
    "例如，sentence = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "tar_inp = \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "tar_real = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "Transformer 是一个自回归（auto-regressive）模型：它一次作一个部分的预测，然后使用到目前为止的自身的输出来决定下一步要做什么。\n",
    "\n",
    "在训练过程中，本示例使用了 teacher-forcing 的方法（就像文本生成教程中一样）。无论模型在当前时间步骤下预测出什么，teacher-forcing 方法都会将真实的输出传递到下一个时间步骤上。\n",
    "\n",
    "当 transformer 预测每个词时，自注意力（self-attention）功能使它能够查看输入序列中前面的单词，从而更好地预测下一个单词。\n",
    "\n",
    "为了防止模型在期望的输出上达到峰值，模型使用了前瞻遮挡（look-ahead mask）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# 该 @tf.function 将追踪-编译 train_step 到 TF 图中，以便更快地\n",
    "# 执行。该函数专用于参数张量的精确形状。为了避免由于可变序列长度或可变\n",
    "# 批次大小（最后一批次较小）导致的再追踪，使用 input_signature 指定\n",
    "# 更多的通用形状。\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.9521 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 4.2896 Accuracy 0.0014\n",
      "Epoch 1 Batch 100 Loss 4.2056 Accuracy 0.0136\n",
      "Epoch 1 Batch 150 Loss 4.1432 Accuracy 0.0180\n",
      "Epoch 1 Batch 200 Loss 4.0778 Accuracy 0.0202\n",
      "Epoch 1 Batch 250 Loss 4.0132 Accuracy 0.0216\n",
      "Epoch 1 Batch 300 Loss 3.9335 Accuracy 0.0227\n",
      "Epoch 1 Batch 350 Loss 3.8457 Accuracy 0.0260\n",
      "Epoch 1 Batch 400 Loss 3.7582 Accuracy 0.0298\n",
      "Epoch 1 Batch 450 Loss 3.6761 Accuracy 0.0333\n",
      "Epoch 1 Batch 500 Loss 3.6048 Accuracy 0.0366\n",
      "Epoch 1 Batch 550 Loss 3.5382 Accuracy 0.0402\n",
      "Epoch 1 Batch 600 Loss 3.4787 Accuracy 0.0441\n",
      "Epoch 1 Batch 650 Loss 3.4211 Accuracy 0.0476\n",
      "Epoch 1 Batch 700 Loss 3.3664 Accuracy 0.0511\n",
      "Epoch 1 Loss 3.3644 Accuracy 0.0512\n",
      "Time taken for 1 epoch: 732.9534883499146 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.6089 Accuracy 0.1071\n",
      "Epoch 2 Batch 50 Loss 2.5596 Accuracy 0.1019\n",
      "Epoch 2 Batch 100 Loss 2.5658 Accuracy 0.1045\n",
      "Epoch 2 Batch 150 Loss 2.5345 Accuracy 0.1066\n",
      "Epoch 2 Batch 200 Loss 2.5006 Accuracy 0.1085\n",
      "Epoch 2 Batch 250 Loss 2.4891 Accuracy 0.1107\n",
      "Epoch 2 Batch 300 Loss 2.4752 Accuracy 0.1128\n",
      "Epoch 2 Batch 350 Loss 2.4611 Accuracy 0.1143\n",
      "Epoch 2 Batch 400 Loss 2.4409 Accuracy 0.1159\n",
      "Epoch 2 Batch 450 Loss 2.4303 Accuracy 0.1175\n",
      "Epoch 2 Batch 500 Loss 2.4159 Accuracy 0.1190\n",
      "Epoch 2 Batch 550 Loss 2.4028 Accuracy 0.1202\n",
      "Epoch 2 Batch 600 Loss 2.3889 Accuracy 0.1215\n",
      "Epoch 2 Batch 650 Loss 2.3749 Accuracy 0.1227\n",
      "Epoch 2 Batch 700 Loss 2.3620 Accuracy 0.1240\n",
      "Epoch 2 Loss 2.3620 Accuracy 0.1241\n",
      "Time taken for 1 epoch: 694.8617131710052 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.3687 Accuracy 0.1402\n",
      "Epoch 3 Batch 50 Loss 2.2041 Accuracy 0.1426\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-58c39b106717>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[1;31m# inp -> portuguese, tar -> english\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\program files\\python\\python37-64\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\program files\\python\\python37-64\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    492\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32me:\\program files\\python\\python37-64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\program files\\python\\python37-64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\program files\\python\\python37-64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\program files\\python\\python37-64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32me:\\program files\\python\\python37-64\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 葡萄牙语作为输入语言，英语为目标语言。、\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型的保存与载入 tokenizer 的保存与载入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights(\"transformer_pt2en.h5\")\n",
    "\n",
    "filename_prefix_en = 'tokenizer_en'\n",
    "filename_prefix_pt = 'tokenizer_pt'\n",
    "# 保存 tokenizer\n",
    "tokenizer_en.save_to_file(filename_prefix_en)\n",
    "tokenizer_pt.save_to_file(filename_prefix_pt)\n",
    "\n",
    "# 导入模型参数\n",
    "# transformer.load_weights(\"transformer_pt2en.h5\")\n",
    "\n",
    "# 导入 tokenizer\n",
    "#tokenizer_en = tfds.features.text.SubwordTextEncoder.load_from_file(filename_prefix_en)\n",
    "#tokenizer_pt = tfds.features.text.SubwordTextEncoder.load_from_file(filename_prefix_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 评估（Evaluate）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下步骤用于评估：\n",
    "\n",
    "  1. 用葡萄牙语分词器（tokenizer_pt）编码输入语句。此外，添加开始和结束标记，这样输入就与模型训练的内容相同。这是编码器输入。\n",
    "  2. 解码器输入为 start token == tokenizer_en.vocab_size。\n",
    "  3. 计算填充遮挡和前瞻遮挡。\n",
    "  4. 解码器通过查看编码器输出和它自身的输出（自注意力）给出预测。\n",
    "  5. 选择最后一个词并计算它的 argmax。\n",
    "  6. 将预测的词连接到解码器输入，然后传递给解码器。\n",
    "  7. 在这种方法中，解码器根据它预测的之前的词预测下一个。\n",
    "Note：这里使用的模型具有较小的能力以保持相对较快，因此预测可能不太正确。要复现论文中的结果，请使用全部数据集，并通过修改上述超参数来使用基础 transformer 模型或者 transformer XL。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "  \n",
    "  # 输入语句是葡萄牙语，增加开始和结束标记\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # 因为目标是英语，输入 transformer 的第一个词应该是\n",
    "  # 英语的开始标记。\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # 从 seq_len 维度选择最后一个词\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # 如果 predicted_id 等于结束标记，就返回结果\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # 连接 predicted_id 与输出，作为解码器的输入传递到解码器。\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = tokenizer_pt.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # 画出注意力权重\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                        if i < tokenizer_en.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 您可以为 plot 参数传递不同的层和解码器的注意力模块。\n",
    "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
