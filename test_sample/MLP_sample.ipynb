{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTLoader():\n",
    "    def __init__(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "        # MNIST中的图像默认为uint8（0-255的数字）。以下代码将其归一化到0-1之间的浮点数，并在最后增加一维作为颜色通道\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)   #[60000, 28, 28, 1]\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)   #[10000, 28, 28, 1]\n",
    "        self.train_label = self.train_label.astype(np.int32)  #[60000]\n",
    "        self.test_label = self.test_label.astype(np.int32)   #[10000]\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        # 从数据集中随机取出batch_size个元素并返回\n",
    "        index = np.random.randint(0, np.shape(self.train_data)[0], size=batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]\n",
    "\n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=200, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax)\n",
    "  \n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        x = self.dense1(x)\n",
    "        output = self.dense2(x)\n",
    "        return output\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "def train():\n",
    "    model = MLP()\n",
    "    data_loader = MNISTLoader()\n",
    "    \n",
    "    summary_writer = tf.summary.create_file_writer('./tensorboard')     # 训练过程可视化，参数为记录文件所保存的目录\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    checkpoint = tf.train.Checkpoint(myAwesomeModel=model)\n",
    "    # 使用tf.train.CheckpointManager管理Checkpoint\n",
    "    manager = tf.train.CheckpointManager(checkpoint, directory='./save', max_to_keep=3)\n",
    "    sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()  #正确率评估\n",
    "    \n",
    "    num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "    for batch_index in range(num_batches):\n",
    "        X, y = data_loader.get_batch(batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            sparse_categorical_accuracy.update_state(y_true=y, y_pred=y_pred)\n",
    "            print(\"batch %d: loss %f accuracy: %f\" % (batch_index, loss.numpy(), sparse_categorical_accuracy.result()))\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        \n",
    "        \n",
    "        with summary_writer.as_default():                               # 希望使用的记录器\n",
    "            tf.summary.scalar(\"loss\", loss, step=batch_index)\n",
    "            tf.summary.scalar(\"accuracy\", sparse_categorical_accuracy.result(), step=batch_index)\n",
    "            #tf.summary.scalar(\"MyScalar\", my_scalar, step=batch_index)  # 还可以添加其他自定义的变量\n",
    "        \n",
    "        if batch_index % 100 == 0:\n",
    "            # 使用CheckpointManager保存模型参数到文件并自定义编号\n",
    "            path = manager.save(checkpoint_number=batch_index)         \n",
    "            print(\"model saved to %s\" % path)\n",
    "\n",
    "def test():\n",
    "    model_to_be_restored = MLP()\n",
    "    data_loader = MNISTLoader()\n",
    "    checkpoint = tf.train.Checkpoint(myAwesomeModel=model_to_be_restored)      \n",
    "    checkpoint.restore(tf.train.latest_checkpoint('./save'))\n",
    "    sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    num_batches = int(data_loader.num_test_data // batch_size)\n",
    "    for batch_index in range(num_batches):\n",
    "        start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "        y_pred = model_to_be_restored.predict(data_loader.test_data[start_index: end_index])\n",
    "        sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)\n",
    "    print(\"test accuracy: %f\" % sparse_categorical_accuracy.result()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们要对训练过程可视化时，在代码目录打开终端（如需要的话进入 TensorFlow 的 conda 环境），运行:\n",
    "\n",
    "tensorboard --logdir=./tensorboard\n",
    "\n",
    "然后使用浏览器访问命令行程序所输出的网址（一般是 http:// 计算机名称：6006），即可访问 TensorBoard 的可视界面\n",
    "\n",
    "如果需要重新训练，需要删除掉记录文件夹内的信息并重启 TensorBoard（或者建立一个新的记录文件夹并开启 TensorBoard， --logdir 参数设置为新建立的文件夹）；\n",
    "\n",
    "记录文件夹目录保持全英文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: loss 2.425844 accuracy: 0.055000\n",
      "model saved to ./save\\ckpt-0\n",
      "batch 1: loss 2.225153 accuracy: 0.130000\n",
      "batch 2: loss 1.994172 accuracy: 0.215000\n",
      "batch 3: loss 1.877686 accuracy: 0.283750\n",
      "batch 4: loss 1.778287 accuracy: 0.345000\n",
      "batch 5: loss 1.588717 accuracy: 0.405833\n",
      "batch 6: loss 1.555903 accuracy: 0.451429\n",
      "batch 7: loss 1.393481 accuracy: 0.484375\n",
      "batch 8: loss 1.335056 accuracy: 0.512222\n",
      "batch 9: loss 1.300263 accuracy: 0.532000\n",
      "batch 10: loss 1.129956 accuracy: 0.553636\n",
      "batch 11: loss 1.116520 accuracy: 0.570417\n",
      "batch 12: loss 1.093734 accuracy: 0.583077\n",
      "batch 13: loss 0.995653 accuracy: 0.596786\n",
      "batch 14: loss 1.018828 accuracy: 0.608667\n",
      "batch 15: loss 0.929597 accuracy: 0.619687\n",
      "batch 16: loss 0.862407 accuracy: 0.628529\n",
      "batch 17: loss 0.872835 accuracy: 0.638056\n",
      "batch 18: loss 0.734545 accuracy: 0.649211\n",
      "batch 19: loss 0.674300 accuracy: 0.660250\n",
      "batch 20: loss 0.674223 accuracy: 0.669524\n",
      "batch 21: loss 0.627961 accuracy: 0.677500\n",
      "batch 22: loss 0.581243 accuracy: 0.684783\n",
      "batch 23: loss 0.617385 accuracy: 0.692708\n",
      "batch 24: loss 0.576266 accuracy: 0.699200\n",
      "batch 25: loss 0.556311 accuracy: 0.705577\n",
      "batch 26: loss 0.528218 accuracy: 0.711296\n",
      "batch 27: loss 0.600369 accuracy: 0.715536\n",
      "batch 28: loss 0.576668 accuracy: 0.719828\n",
      "batch 29: loss 0.510718 accuracy: 0.724833\n",
      "batch 30: loss 0.534968 accuracy: 0.728871\n",
      "batch 31: loss 0.458926 accuracy: 0.733437\n",
      "batch 32: loss 0.538213 accuracy: 0.736667\n",
      "batch 33: loss 0.648774 accuracy: 0.740147\n",
      "batch 34: loss 0.498493 accuracy: 0.743571\n",
      "batch 35: loss 0.416491 accuracy: 0.747917\n",
      "batch 36: loss 0.527475 accuracy: 0.751216\n",
      "batch 37: loss 0.428467 accuracy: 0.754737\n",
      "batch 38: loss 0.383925 accuracy: 0.758077\n",
      "batch 39: loss 0.445977 accuracy: 0.761000\n",
      "batch 40: loss 0.432758 accuracy: 0.763780\n",
      "batch 41: loss 0.371302 accuracy: 0.766667\n",
      "batch 42: loss 0.497906 accuracy: 0.769186\n",
      "batch 43: loss 0.345844 accuracy: 0.772727\n",
      "batch 44: loss 0.367283 accuracy: 0.775889\n",
      "batch 45: loss 0.382930 accuracy: 0.779022\n",
      "batch 46: loss 0.350830 accuracy: 0.781383\n",
      "batch 47: loss 0.450037 accuracy: 0.782812\n",
      "batch 48: loss 0.329427 accuracy: 0.785510\n",
      "batch 49: loss 0.386425 accuracy: 0.787400\n",
      "batch 50: loss 0.371154 accuracy: 0.789510\n",
      "batch 51: loss 0.347066 accuracy: 0.792115\n",
      "batch 52: loss 0.359899 accuracy: 0.794057\n",
      "batch 53: loss 0.535856 accuracy: 0.795370\n",
      "batch 54: loss 0.355558 accuracy: 0.797273\n",
      "batch 55: loss 0.308598 accuracy: 0.799464\n",
      "batch 56: loss 0.340885 accuracy: 0.801491\n",
      "batch 57: loss 0.358272 accuracy: 0.803103\n",
      "batch 58: loss 0.374229 accuracy: 0.804915\n",
      "batch 59: loss 0.366638 accuracy: 0.806500\n",
      "batch 60: loss 0.351665 accuracy: 0.807951\n",
      "batch 61: loss 0.378151 accuracy: 0.809516\n",
      "batch 62: loss 0.412094 accuracy: 0.810476\n",
      "batch 63: loss 0.445656 accuracy: 0.811250\n",
      "batch 64: loss 0.406528 accuracy: 0.812154\n",
      "batch 65: loss 0.341495 accuracy: 0.813409\n",
      "batch 66: loss 0.312295 accuracy: 0.814701\n",
      "batch 67: loss 0.409683 accuracy: 0.815662\n",
      "batch 68: loss 0.353937 accuracy: 0.816594\n",
      "batch 69: loss 0.355815 accuracy: 0.818071\n",
      "batch 70: loss 0.456948 accuracy: 0.818732\n",
      "batch 71: loss 0.358514 accuracy: 0.819722\n",
      "batch 72: loss 0.336441 accuracy: 0.820479\n",
      "batch 73: loss 0.312840 accuracy: 0.821419\n",
      "batch 74: loss 0.284705 accuracy: 0.822667\n",
      "batch 75: loss 0.415929 accuracy: 0.823553\n",
      "batch 76: loss 0.287277 accuracy: 0.825130\n",
      "batch 77: loss 0.331816 accuracy: 0.826154\n",
      "batch 78: loss 0.447734 accuracy: 0.826772\n",
      "batch 79: loss 0.303463 accuracy: 0.827875\n",
      "batch 80: loss 0.376217 accuracy: 0.828580\n",
      "batch 81: loss 0.301997 accuracy: 0.829817\n",
      "batch 82: loss 0.400679 accuracy: 0.830663\n",
      "batch 83: loss 0.479457 accuracy: 0.830833\n",
      "batch 84: loss 0.441515 accuracy: 0.831471\n",
      "batch 85: loss 0.353859 accuracy: 0.832209\n",
      "batch 86: loss 0.356216 accuracy: 0.832989\n",
      "batch 87: loss 0.312405 accuracy: 0.833864\n",
      "batch 88: loss 0.341997 accuracy: 0.834494\n",
      "batch 89: loss 0.272603 accuracy: 0.835500\n",
      "batch 90: loss 0.220593 accuracy: 0.836593\n",
      "batch 91: loss 0.218085 accuracy: 0.837609\n",
      "batch 92: loss 0.364648 accuracy: 0.838280\n",
      "batch 93: loss 0.254802 accuracy: 0.839096\n",
      "batch 94: loss 0.347444 accuracy: 0.839842\n",
      "batch 95: loss 0.329019 accuracy: 0.840573\n",
      "batch 96: loss 0.437242 accuracy: 0.841134\n",
      "batch 97: loss 0.266234 accuracy: 0.842041\n",
      "batch 98: loss 0.230315 accuracy: 0.842879\n",
      "batch 99: loss 0.347306 accuracy: 0.843350\n",
      "batch 100: loss 0.286247 accuracy: 0.844109\n",
      "model saved to ./save\\ckpt-100\n",
      "batch 101: loss 0.268731 accuracy: 0.844853\n",
      "batch 102: loss 0.318043 accuracy: 0.845680\n",
      "batch 103: loss 0.347979 accuracy: 0.846298\n",
      "batch 104: loss 0.255597 accuracy: 0.847095\n",
      "batch 105: loss 0.286941 accuracy: 0.847783\n",
      "batch 106: loss 0.374405 accuracy: 0.848084\n",
      "batch 107: loss 0.278533 accuracy: 0.848750\n",
      "batch 108: loss 0.317889 accuracy: 0.849358\n",
      "batch 109: loss 0.442361 accuracy: 0.849682\n",
      "batch 110: loss 0.263220 accuracy: 0.850496\n",
      "batch 111: loss 0.346276 accuracy: 0.850848\n",
      "batch 112: loss 0.231459 accuracy: 0.851549\n",
      "batch 113: loss 0.280036 accuracy: 0.852105\n",
      "batch 114: loss 0.296316 accuracy: 0.852913\n",
      "batch 115: loss 0.306097 accuracy: 0.853534\n",
      "batch 116: loss 0.143427 accuracy: 0.854530\n",
      "batch 117: loss 0.245808 accuracy: 0.855297\n",
      "batch 118: loss 0.259228 accuracy: 0.855798\n",
      "batch 119: loss 0.307898 accuracy: 0.856208\n",
      "batch 120: loss 0.292400 accuracy: 0.856777\n",
      "batch 121: loss 0.342597 accuracy: 0.857254\n",
      "batch 122: loss 0.303515 accuracy: 0.857764\n",
      "batch 123: loss 0.242067 accuracy: 0.858427\n",
      "batch 124: loss 0.361772 accuracy: 0.858840\n",
      "batch 125: loss 0.188000 accuracy: 0.859524\n",
      "batch 126: loss 0.292175 accuracy: 0.860000\n",
      "batch 127: loss 0.198720 accuracy: 0.860703\n",
      "batch 128: loss 0.287632 accuracy: 0.861163\n",
      "batch 129: loss 0.277416 accuracy: 0.861731\n",
      "batch 130: loss 0.306013 accuracy: 0.862176\n",
      "batch 131: loss 0.316063 accuracy: 0.862424\n",
      "batch 132: loss 0.305608 accuracy: 0.862895\n",
      "batch 133: loss 0.429062 accuracy: 0.863060\n",
      "batch 134: loss 0.317118 accuracy: 0.863222\n",
      "batch 135: loss 0.231330 accuracy: 0.863640\n",
      "batch 136: loss 0.156956 accuracy: 0.864270\n",
      "batch 137: loss 0.231227 accuracy: 0.864710\n",
      "batch 138: loss 0.274933 accuracy: 0.865144\n",
      "batch 139: loss 0.261279 accuracy: 0.865536\n",
      "batch 140: loss 0.278976 accuracy: 0.866099\n",
      "batch 141: loss 0.284248 accuracy: 0.866514\n",
      "batch 142: loss 0.218885 accuracy: 0.867098\n",
      "batch 143: loss 0.318759 accuracy: 0.867535\n",
      "batch 144: loss 0.290531 accuracy: 0.867759\n",
      "batch 145: loss 0.307167 accuracy: 0.868185\n",
      "batch 146: loss 0.312771 accuracy: 0.868401\n",
      "batch 147: loss 0.266982 accuracy: 0.868818\n",
      "batch 148: loss 0.238475 accuracy: 0.869262\n",
      "batch 149: loss 0.235695 accuracy: 0.869833\n",
      "batch 150: loss 0.243302 accuracy: 0.870166\n",
      "batch 151: loss 0.192548 accuracy: 0.870658\n",
      "batch 152: loss 0.342196 accuracy: 0.870817\n",
      "batch 153: loss 0.190249 accuracy: 0.871266\n",
      "batch 154: loss 0.311623 accuracy: 0.871484\n",
      "batch 155: loss 0.214667 accuracy: 0.871923\n",
      "batch 156: loss 0.153186 accuracy: 0.872452\n",
      "batch 157: loss 0.271122 accuracy: 0.872816\n",
      "batch 158: loss 0.287791 accuracy: 0.873208\n",
      "batch 159: loss 0.226961 accuracy: 0.873563\n",
      "batch 160: loss 0.224503 accuracy: 0.874037\n",
      "batch 161: loss 0.254660 accuracy: 0.874414\n",
      "batch 162: loss 0.231442 accuracy: 0.874755\n",
      "batch 163: loss 0.233078 accuracy: 0.875031\n",
      "batch 164: loss 0.285778 accuracy: 0.875273\n",
      "batch 165: loss 0.157164 accuracy: 0.875843\n",
      "batch 166: loss 0.254735 accuracy: 0.876228\n",
      "batch 167: loss 0.265293 accuracy: 0.876577\n",
      "batch 168: loss 0.219982 accuracy: 0.876894\n",
      "batch 169: loss 0.278658 accuracy: 0.877206\n",
      "batch 170: loss 0.288364 accuracy: 0.877427\n",
      "batch 171: loss 0.186707 accuracy: 0.877878\n",
      "batch 172: loss 0.209489 accuracy: 0.878295\n",
      "batch 173: loss 0.213090 accuracy: 0.878764\n",
      "batch 174: loss 0.245419 accuracy: 0.879114\n",
      "batch 175: loss 0.297891 accuracy: 0.879261\n",
      "batch 176: loss 0.258080 accuracy: 0.879492\n",
      "batch 177: loss 0.227163 accuracy: 0.879916\n",
      "batch 178: loss 0.281670 accuracy: 0.880140\n",
      "batch 179: loss 0.291173 accuracy: 0.880361\n",
      "batch 180: loss 0.211677 accuracy: 0.880746\n",
      "batch 181: loss 0.307548 accuracy: 0.880962\n",
      "batch 182: loss 0.254998 accuracy: 0.881175\n",
      "batch 183: loss 0.300107 accuracy: 0.881386\n",
      "batch 184: loss 0.197552 accuracy: 0.881622\n",
      "batch 185: loss 0.194640 accuracy: 0.881962\n",
      "batch 186: loss 0.309662 accuracy: 0.882032\n",
      "batch 187: loss 0.178473 accuracy: 0.882500\n",
      "batch 188: loss 0.178291 accuracy: 0.882857\n",
      "batch 189: loss 0.248640 accuracy: 0.883132\n",
      "batch 190: loss 0.227442 accuracy: 0.883403\n",
      "batch 191: loss 0.317590 accuracy: 0.883698\n",
      "batch 192: loss 0.334738 accuracy: 0.883834\n",
      "batch 193: loss 0.200719 accuracy: 0.884072\n",
      "batch 194: loss 0.305515 accuracy: 0.884333\n",
      "batch 195: loss 0.248264 accuracy: 0.884745\n",
      "batch 196: loss 0.234788 accuracy: 0.885000\n",
      "batch 197: loss 0.256578 accuracy: 0.885202\n",
      "batch 198: loss 0.151485 accuracy: 0.885553\n",
      "batch 199: loss 0.247648 accuracy: 0.885775\n",
      "batch 200: loss 0.271413 accuracy: 0.885920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to ./save\\ckpt-200\n",
      "batch 201: loss 0.232207 accuracy: 0.886139\n",
      "batch 202: loss 0.146546 accuracy: 0.886552\n",
      "batch 203: loss 0.178664 accuracy: 0.886887\n",
      "batch 204: loss 0.269100 accuracy: 0.887146\n",
      "batch 205: loss 0.205735 accuracy: 0.887427\n",
      "batch 206: loss 0.199788 accuracy: 0.887681\n",
      "batch 207: loss 0.303717 accuracy: 0.887812\n",
      "batch 208: loss 0.205603 accuracy: 0.888110\n",
      "batch 209: loss 0.254111 accuracy: 0.888357\n",
      "batch 210: loss 0.221384 accuracy: 0.888602\n",
      "batch 211: loss 0.193473 accuracy: 0.888868\n",
      "batch 212: loss 0.256235 accuracy: 0.889061\n",
      "batch 213: loss 0.185653 accuracy: 0.889346\n",
      "batch 214: loss 0.159521 accuracy: 0.889721\n",
      "batch 215: loss 0.172696 accuracy: 0.890000\n",
      "batch 216: loss 0.186394 accuracy: 0.890276\n",
      "batch 217: loss 0.197353 accuracy: 0.890505\n",
      "batch 218: loss 0.124629 accuracy: 0.890868\n",
      "batch 219: loss 0.261852 accuracy: 0.891000\n",
      "batch 220: loss 0.180052 accuracy: 0.891267\n",
      "batch 221: loss 0.299382 accuracy: 0.891306\n",
      "batch 222: loss 0.283187 accuracy: 0.891502\n",
      "batch 223: loss 0.174374 accuracy: 0.891741\n",
      "batch 224: loss 0.185346 accuracy: 0.891956\n",
      "batch 225: loss 0.180841 accuracy: 0.892257\n",
      "batch 226: loss 0.175896 accuracy: 0.892533\n",
      "batch 227: loss 0.211962 accuracy: 0.892763\n",
      "batch 228: loss 0.274128 accuracy: 0.892926\n",
      "batch 229: loss 0.237809 accuracy: 0.893109\n",
      "batch 230: loss 0.221190 accuracy: 0.893290\n",
      "batch 231: loss 0.194777 accuracy: 0.893534\n",
      "batch 232: loss 0.205420 accuracy: 0.893777\n",
      "batch 233: loss 0.230731 accuracy: 0.893974\n",
      "batch 234: loss 0.208350 accuracy: 0.894128\n",
      "batch 235: loss 0.193747 accuracy: 0.894322\n",
      "batch 236: loss 0.215589 accuracy: 0.894473\n",
      "batch 237: loss 0.225343 accuracy: 0.894664\n",
      "batch 238: loss 0.289558 accuracy: 0.894770\n",
      "batch 239: loss 0.184511 accuracy: 0.894979\n",
      "batch 240: loss 0.162212 accuracy: 0.895228\n",
      "batch 241: loss 0.217855 accuracy: 0.895393\n",
      "batch 242: loss 0.284419 accuracy: 0.895535\n",
      "batch 243: loss 0.214200 accuracy: 0.895697\n",
      "batch 244: loss 0.222019 accuracy: 0.895918\n",
      "batch 245: loss 0.191706 accuracy: 0.896138\n",
      "batch 246: loss 0.304599 accuracy: 0.896174\n",
      "batch 247: loss 0.212560 accuracy: 0.896290\n",
      "batch 248: loss 0.195224 accuracy: 0.896466\n",
      "batch 249: loss 0.172640 accuracy: 0.896700\n",
      "batch 250: loss 0.265027 accuracy: 0.896833\n",
      "batch 251: loss 0.234335 accuracy: 0.896984\n",
      "batch 252: loss 0.182743 accuracy: 0.897174\n",
      "batch 253: loss 0.210381 accuracy: 0.897323\n",
      "batch 254: loss 0.278516 accuracy: 0.897490\n",
      "batch 255: loss 0.166020 accuracy: 0.897715\n",
      "batch 256: loss 0.163097 accuracy: 0.897957\n",
      "batch 257: loss 0.153387 accuracy: 0.898256\n",
      "batch 258: loss 0.185486 accuracy: 0.898475\n",
      "batch 259: loss 0.229726 accuracy: 0.898673\n",
      "batch 260: loss 0.139004 accuracy: 0.898946\n",
      "batch 261: loss 0.180979 accuracy: 0.899160\n",
      "batch 262: loss 0.282568 accuracy: 0.899297\n",
      "batch 263: loss 0.232470 accuracy: 0.899432\n",
      "batch 264: loss 0.203130 accuracy: 0.899547\n",
      "batch 265: loss 0.129693 accuracy: 0.899756\n",
      "batch 266: loss 0.225642 accuracy: 0.899850\n",
      "batch 267: loss 0.267520 accuracy: 0.900019\n",
      "batch 268: loss 0.273641 accuracy: 0.900093\n",
      "batch 269: loss 0.194895 accuracy: 0.900278\n",
      "batch 270: loss 0.210923 accuracy: 0.900461\n",
      "batch 271: loss 0.202183 accuracy: 0.900588\n",
      "batch 272: loss 0.210187 accuracy: 0.900733\n",
      "batch 273: loss 0.131236 accuracy: 0.900985\n",
      "batch 274: loss 0.176591 accuracy: 0.901236\n",
      "batch 275: loss 0.169266 accuracy: 0.901431\n",
      "batch 276: loss 0.205481 accuracy: 0.901588\n",
      "batch 277: loss 0.232885 accuracy: 0.901709\n",
      "batch 278: loss 0.283079 accuracy: 0.901792\n",
      "batch 279: loss 0.198713 accuracy: 0.901911\n",
      "batch 280: loss 0.143057 accuracy: 0.902117\n",
      "batch 281: loss 0.262121 accuracy: 0.902216\n",
      "batch 282: loss 0.133290 accuracy: 0.902403\n",
      "batch 283: loss 0.199707 accuracy: 0.902553\n",
      "batch 284: loss 0.213595 accuracy: 0.902754\n",
      "batch 285: loss 0.217914 accuracy: 0.902902\n",
      "batch 286: loss 0.147872 accuracy: 0.903136\n",
      "batch 287: loss 0.254941 accuracy: 0.903247\n",
      "batch 288: loss 0.122966 accuracy: 0.903460\n",
      "batch 289: loss 0.207854 accuracy: 0.903603\n",
      "batch 290: loss 0.122723 accuracy: 0.903814\n",
      "batch 291: loss 0.096837 accuracy: 0.904058\n",
      "batch 292: loss 0.125733 accuracy: 0.904266\n",
      "batch 293: loss 0.170389 accuracy: 0.904405\n",
      "batch 294: loss 0.204106 accuracy: 0.904593\n",
      "batch 295: loss 0.212935 accuracy: 0.904645\n",
      "batch 296: loss 0.169491 accuracy: 0.904815\n",
      "batch 297: loss 0.179708 accuracy: 0.905000\n",
      "batch 298: loss 0.144564 accuracy: 0.905184\n",
      "batch 299: loss 0.296473 accuracy: 0.905233\n",
      "batch 300: loss 0.164489 accuracy: 0.905399\n",
      "model saved to ./save\\ckpt-300\n",
      "batch 301: loss 0.216215 accuracy: 0.905497\n",
      "batch 302: loss 0.160691 accuracy: 0.905660\n",
      "batch 303: loss 0.185854 accuracy: 0.905806\n",
      "batch 304: loss 0.213669 accuracy: 0.905902\n",
      "batch 305: loss 0.240737 accuracy: 0.905997\n",
      "batch 306: loss 0.238543 accuracy: 0.906091\n",
      "batch 307: loss 0.240066 accuracy: 0.906039\n",
      "batch 308: loss 0.282794 accuracy: 0.906052\n",
      "batch 309: loss 0.291469 accuracy: 0.906226\n",
      "batch 310: loss 0.164108 accuracy: 0.906334\n",
      "batch 311: loss 0.150872 accuracy: 0.906490\n",
      "batch 312: loss 0.162424 accuracy: 0.906629\n",
      "batch 313: loss 0.197224 accuracy: 0.906815\n",
      "batch 314: loss 0.174302 accuracy: 0.906952\n",
      "batch 315: loss 0.253547 accuracy: 0.906994\n",
      "batch 316: loss 0.174977 accuracy: 0.907114\n",
      "batch 317: loss 0.172923 accuracy: 0.907233\n",
      "batch 318: loss 0.189455 accuracy: 0.907367\n",
      "batch 319: loss 0.205880 accuracy: 0.907422\n",
      "batch 320: loss 0.168676 accuracy: 0.907555\n",
      "batch 321: loss 0.159828 accuracy: 0.907671\n",
      "batch 322: loss 0.208944 accuracy: 0.907817\n",
      "batch 323: loss 0.208459 accuracy: 0.907886\n",
      "batch 324: loss 0.124751 accuracy: 0.908031\n",
      "batch 325: loss 0.166233 accuracy: 0.908129\n",
      "batch 326: loss 0.137019 accuracy: 0.908272\n",
      "batch 327: loss 0.154912 accuracy: 0.908399\n",
      "batch 328: loss 0.136428 accuracy: 0.908587\n",
      "batch 329: loss 0.219585 accuracy: 0.908697\n",
      "batch 330: loss 0.174633 accuracy: 0.908837\n",
      "batch 331: loss 0.170993 accuracy: 0.908976\n",
      "batch 332: loss 0.193921 accuracy: 0.909054\n",
      "batch 333: loss 0.152912 accuracy: 0.909207\n",
      "batch 334: loss 0.200512 accuracy: 0.909284\n",
      "batch 335: loss 0.279444 accuracy: 0.909301\n",
      "batch 336: loss 0.160029 accuracy: 0.909436\n",
      "batch 337: loss 0.195080 accuracy: 0.909571\n",
      "batch 338: loss 0.164455 accuracy: 0.909690\n",
      "batch 339: loss 0.162142 accuracy: 0.909779\n",
      "batch 340: loss 0.175326 accuracy: 0.909912\n",
      "batch 341: loss 0.244744 accuracy: 0.910000\n",
      "batch 342: loss 0.232585 accuracy: 0.910044\n",
      "batch 343: loss 0.188122 accuracy: 0.910160\n",
      "batch 344: loss 0.182966 accuracy: 0.910333\n",
      "batch 345: loss 0.156094 accuracy: 0.910491\n",
      "batch 346: loss 0.128465 accuracy: 0.910605\n",
      "batch 347: loss 0.182489 accuracy: 0.910704\n",
      "batch 348: loss 0.163770 accuracy: 0.910845\n",
      "batch 349: loss 0.177715 accuracy: 0.910929\n",
      "batch 350: loss 0.205039 accuracy: 0.910997\n",
      "batch 351: loss 0.186884 accuracy: 0.911080\n",
      "batch 352: loss 0.184556 accuracy: 0.911161\n",
      "batch 353: loss 0.138968 accuracy: 0.911356\n",
      "batch 354: loss 0.194395 accuracy: 0.911423\n",
      "batch 355: loss 0.217055 accuracy: 0.911475\n",
      "batch 356: loss 0.197072 accuracy: 0.911597\n",
      "batch 357: loss 0.268752 accuracy: 0.911648\n",
      "batch 358: loss 0.124676 accuracy: 0.911783\n",
      "batch 359: loss 0.288143 accuracy: 0.911806\n",
      "batch 360: loss 0.172700 accuracy: 0.911911\n",
      "batch 361: loss 0.178636 accuracy: 0.912017\n",
      "batch 362: loss 0.204393 accuracy: 0.912149\n",
      "batch 363: loss 0.099370 accuracy: 0.912308\n",
      "batch 364: loss 0.226668 accuracy: 0.912425\n",
      "batch 365: loss 0.131488 accuracy: 0.912555\n",
      "batch 366: loss 0.288720 accuracy: 0.912616\n",
      "batch 367: loss 0.144589 accuracy: 0.912704\n",
      "batch 368: loss 0.201847 accuracy: 0.912751\n",
      "batch 369: loss 0.187769 accuracy: 0.912797\n",
      "batch 370: loss 0.168642 accuracy: 0.912925\n",
      "batch 371: loss 0.244817 accuracy: 0.912997\n",
      "batch 372: loss 0.134173 accuracy: 0.913110\n",
      "batch 373: loss 0.122795 accuracy: 0.913289\n",
      "batch 374: loss 0.216248 accuracy: 0.913347\n",
      "batch 375: loss 0.242514 accuracy: 0.913338\n",
      "batch 376: loss 0.099917 accuracy: 0.913528\n",
      "batch 377: loss 0.196406 accuracy: 0.913638\n",
      "batch 378: loss 0.149570 accuracy: 0.913760\n",
      "batch 379: loss 0.168300 accuracy: 0.913829\n",
      "batch 380: loss 0.217888 accuracy: 0.913924\n",
      "batch 381: loss 0.131215 accuracy: 0.914058\n",
      "batch 382: loss 0.126128 accuracy: 0.914217\n",
      "batch 383: loss 0.182476 accuracy: 0.914323\n",
      "batch 384: loss 0.156816 accuracy: 0.914390\n",
      "batch 385: loss 0.148991 accuracy: 0.914521\n",
      "batch 386: loss 0.192605 accuracy: 0.914599\n",
      "batch 387: loss 0.123682 accuracy: 0.914691\n",
      "batch 388: loss 0.204701 accuracy: 0.914794\n",
      "batch 389: loss 0.119944 accuracy: 0.914949\n",
      "batch 390: loss 0.168769 accuracy: 0.915038\n",
      "batch 391: loss 0.150801 accuracy: 0.915140\n",
      "batch 392: loss 0.156485 accuracy: 0.915229\n",
      "batch 393: loss 0.170420 accuracy: 0.915343\n",
      "batch 394: loss 0.204254 accuracy: 0.915430\n",
      "batch 395: loss 0.201687 accuracy: 0.915505\n",
      "batch 396: loss 0.197128 accuracy: 0.915567\n",
      "batch 397: loss 0.188039 accuracy: 0.915628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 398: loss 0.242758 accuracy: 0.915689\n",
      "batch 399: loss 0.142628 accuracy: 0.915775\n",
      "batch 400: loss 0.161036 accuracy: 0.915835\n",
      "model saved to ./save\\ckpt-400\n",
      "batch 401: loss 0.127148 accuracy: 0.915958\n",
      "batch 402: loss 0.213275 accuracy: 0.916042\n",
      "batch 403: loss 0.072643 accuracy: 0.916213\n",
      "batch 404: loss 0.134382 accuracy: 0.916321\n",
      "batch 405: loss 0.163977 accuracy: 0.916367\n",
      "batch 406: loss 0.109140 accuracy: 0.916523\n",
      "batch 407: loss 0.184764 accuracy: 0.916581\n",
      "batch 408: loss 0.255500 accuracy: 0.916626\n",
      "batch 409: loss 0.213414 accuracy: 0.916695\n",
      "batch 410: loss 0.193755 accuracy: 0.916764\n",
      "batch 411: loss 0.234134 accuracy: 0.916796\n",
      "batch 412: loss 0.165643 accuracy: 0.916913\n",
      "batch 413: loss 0.132165 accuracy: 0.917053\n",
      "batch 414: loss 0.133691 accuracy: 0.917157\n",
      "batch 415: loss 0.096855 accuracy: 0.917308\n",
      "batch 416: loss 0.183356 accuracy: 0.917398\n",
      "batch 417: loss 0.102575 accuracy: 0.917548\n",
      "batch 418: loss 0.273568 accuracy: 0.917578\n",
      "batch 419: loss 0.174450 accuracy: 0.917690\n",
      "batch 420: loss 0.193256 accuracy: 0.917743\n",
      "batch 421: loss 0.222827 accuracy: 0.917796\n",
      "batch 422: loss 0.198092 accuracy: 0.917837\n",
      "batch 423: loss 0.099872 accuracy: 0.917960\n",
      "batch 424: loss 0.156718 accuracy: 0.918059\n",
      "batch 425: loss 0.165040 accuracy: 0.918146\n",
      "batch 426: loss 0.162728 accuracy: 0.918232\n",
      "batch 427: loss 0.251031 accuracy: 0.918283\n",
      "batch 428: loss 0.166704 accuracy: 0.918380\n",
      "batch 429: loss 0.146914 accuracy: 0.918465\n",
      "batch 430: loss 0.155379 accuracy: 0.918538\n",
      "batch 431: loss 0.173213 accuracy: 0.918646\n",
      "batch 432: loss 0.213546 accuracy: 0.918684\n",
      "batch 433: loss 0.207669 accuracy: 0.918721\n",
      "batch 434: loss 0.173363 accuracy: 0.918736\n",
      "batch 435: loss 0.154084 accuracy: 0.918830\n",
      "batch 436: loss 0.139882 accuracy: 0.918913\n",
      "batch 437: loss 0.232571 accuracy: 0.918961\n",
      "batch 438: loss 0.179241 accuracy: 0.918998\n",
      "batch 439: loss 0.174098 accuracy: 0.919068\n",
      "batch 440: loss 0.140478 accuracy: 0.919195\n",
      "batch 441: loss 0.142608 accuracy: 0.919287\n",
      "batch 442: loss 0.156320 accuracy: 0.919368\n",
      "batch 443: loss 0.169222 accuracy: 0.919448\n",
      "batch 444: loss 0.146399 accuracy: 0.919528\n",
      "batch 445: loss 0.176219 accuracy: 0.919608\n",
      "batch 446: loss 0.133482 accuracy: 0.919698\n",
      "batch 447: loss 0.191961 accuracy: 0.919710\n",
      "batch 448: loss 0.153413 accuracy: 0.919788\n",
      "batch 449: loss 0.074133 accuracy: 0.919944\n",
      "batch 450: loss 0.119145 accuracy: 0.920055\n",
      "batch 451: loss 0.184956 accuracy: 0.920066\n",
      "batch 452: loss 0.090502 accuracy: 0.920188\n",
      "batch 453: loss 0.203506 accuracy: 0.920220\n",
      "batch 454: loss 0.143187 accuracy: 0.920319\n",
      "batch 455: loss 0.123584 accuracy: 0.920395\n",
      "batch 456: loss 0.184013 accuracy: 0.920438\n",
      "batch 457: loss 0.111863 accuracy: 0.920546\n",
      "batch 458: loss 0.159188 accuracy: 0.920599\n",
      "batch 459: loss 0.202596 accuracy: 0.920674\n",
      "batch 460: loss 0.164507 accuracy: 0.920748\n",
      "batch 461: loss 0.142822 accuracy: 0.920833\n",
      "batch 462: loss 0.119133 accuracy: 0.920929\n",
      "batch 463: loss 0.163809 accuracy: 0.920991\n",
      "batch 464: loss 0.179241 accuracy: 0.921064\n",
      "batch 465: loss 0.120528 accuracy: 0.921180\n",
      "batch 466: loss 0.128929 accuracy: 0.921253\n",
      "batch 467: loss 0.200681 accuracy: 0.921325\n",
      "batch 468: loss 0.128235 accuracy: 0.921407\n",
      "batch 469: loss 0.100240 accuracy: 0.921500\n",
      "batch 470: loss 0.160391 accuracy: 0.921561\n",
      "batch 471: loss 0.108561 accuracy: 0.921695\n",
      "batch 472: loss 0.138937 accuracy: 0.921765\n",
      "batch 473: loss 0.097134 accuracy: 0.921867\n",
      "batch 474: loss 0.124585 accuracy: 0.921947\n",
      "batch 475: loss 0.100366 accuracy: 0.922069\n",
      "batch 476: loss 0.161876 accuracy: 0.922170\n",
      "batch 477: loss 0.203542 accuracy: 0.922186\n",
      "batch 478: loss 0.199804 accuracy: 0.922213\n",
      "batch 479: loss 0.168013 accuracy: 0.922260\n",
      "batch 480: loss 0.164738 accuracy: 0.922328\n",
      "batch 481: loss 0.211301 accuracy: 0.922355\n",
      "batch 482: loss 0.154824 accuracy: 0.922422\n",
      "batch 483: loss 0.163270 accuracy: 0.922500\n",
      "batch 484: loss 0.146534 accuracy: 0.922557\n",
      "batch 485: loss 0.092880 accuracy: 0.922665\n",
      "batch 486: loss 0.150034 accuracy: 0.922741\n",
      "batch 487: loss 0.218346 accuracy: 0.922766\n",
      "batch 488: loss 0.166612 accuracy: 0.922832\n",
      "batch 489: loss 0.107592 accuracy: 0.922918\n",
      "batch 490: loss 0.167413 accuracy: 0.922994\n",
      "batch 491: loss 0.102437 accuracy: 0.923110\n",
      "batch 492: loss 0.140107 accuracy: 0.923215\n",
      "batch 493: loss 0.171133 accuracy: 0.923269\n",
      "batch 494: loss 0.224838 accuracy: 0.923323\n",
      "batch 495: loss 0.110455 accuracy: 0.923417\n",
      "batch 496: loss 0.128936 accuracy: 0.923471\n",
      "batch 497: loss 0.160026 accuracy: 0.923504\n",
      "batch 498: loss 0.150803 accuracy: 0.923577\n",
      "batch 499: loss 0.141632 accuracy: 0.923650\n",
      "batch 500: loss 0.158171 accuracy: 0.923713\n",
      "model saved to ./save\\ckpt-500\n",
      "batch 501: loss 0.168825 accuracy: 0.923765\n",
      "batch 502: loss 0.136970 accuracy: 0.923817\n",
      "batch 503: loss 0.114609 accuracy: 0.923909\n",
      "batch 504: loss 0.120904 accuracy: 0.924010\n",
      "batch 505: loss 0.078289 accuracy: 0.924111\n",
      "batch 506: loss 0.240306 accuracy: 0.924172\n",
      "batch 507: loss 0.135389 accuracy: 0.924262\n",
      "batch 508: loss 0.131382 accuracy: 0.924342\n",
      "batch 509: loss 0.079080 accuracy: 0.924471\n",
      "batch 510: loss 0.150640 accuracy: 0.924550\n",
      "batch 511: loss 0.151231 accuracy: 0.924600\n",
      "batch 512: loss 0.136718 accuracy: 0.924659\n",
      "batch 513: loss 0.157705 accuracy: 0.924650\n",
      "batch 514: loss 0.159298 accuracy: 0.924718\n",
      "batch 515: loss 0.138180 accuracy: 0.924767\n",
      "batch 516: loss 0.076940 accuracy: 0.924855\n",
      "batch 517: loss 0.098397 accuracy: 0.924942\n",
      "batch 518: loss 0.198334 accuracy: 0.924981\n",
      "batch 519: loss 0.107660 accuracy: 0.925029\n",
      "batch 520: loss 0.140610 accuracy: 0.925096\n",
      "batch 521: loss 0.097584 accuracy: 0.925182\n",
      "batch 522: loss 0.107679 accuracy: 0.925268\n",
      "batch 523: loss 0.142511 accuracy: 0.925334\n",
      "batch 524: loss 0.132906 accuracy: 0.925400\n",
      "batch 525: loss 0.181140 accuracy: 0.925399\n",
      "batch 526: loss 0.138637 accuracy: 0.925474\n",
      "batch 527: loss 0.182298 accuracy: 0.925540\n",
      "batch 528: loss 0.147883 accuracy: 0.925558\n",
      "batch 529: loss 0.142632 accuracy: 0.925594\n",
      "batch 530: loss 0.104007 accuracy: 0.925659\n",
      "batch 531: loss 0.152680 accuracy: 0.925714\n",
      "batch 532: loss 0.138459 accuracy: 0.925788\n",
      "batch 533: loss 0.235861 accuracy: 0.925805\n",
      "batch 534: loss 0.150760 accuracy: 0.925869\n",
      "batch 535: loss 0.142934 accuracy: 0.925924\n",
      "batch 536: loss 0.136549 accuracy: 0.926024\n",
      "batch 537: loss 0.100892 accuracy: 0.926115\n",
      "batch 538: loss 0.079424 accuracy: 0.926187\n",
      "batch 539: loss 0.182992 accuracy: 0.926222\n",
      "batch 540: loss 0.099994 accuracy: 0.926322\n",
      "batch 541: loss 0.121091 accuracy: 0.926365\n",
      "batch 542: loss 0.178117 accuracy: 0.926400\n",
      "batch 543: loss 0.160569 accuracy: 0.926471\n",
      "batch 544: loss 0.118636 accuracy: 0.926532\n",
      "batch 545: loss 0.128974 accuracy: 0.926593\n",
      "batch 546: loss 0.100424 accuracy: 0.926664\n",
      "batch 547: loss 0.156944 accuracy: 0.926697\n",
      "batch 548: loss 0.155291 accuracy: 0.926776\n",
      "batch 549: loss 0.093411 accuracy: 0.926864\n",
      "batch 550: loss 0.190461 accuracy: 0.926915\n",
      "batch 551: loss 0.112414 accuracy: 0.926975\n",
      "batch 552: loss 0.194318 accuracy: 0.927016\n",
      "batch 553: loss 0.209174 accuracy: 0.927004\n",
      "batch 554: loss 0.165407 accuracy: 0.927045\n",
      "batch 555: loss 0.136301 accuracy: 0.927086\n",
      "batch 556: loss 0.126588 accuracy: 0.927110\n",
      "batch 557: loss 0.117113 accuracy: 0.927168\n",
      "batch 558: loss 0.206035 accuracy: 0.927245\n",
      "batch 559: loss 0.143229 accuracy: 0.927304\n",
      "batch 560: loss 0.225801 accuracy: 0.927326\n",
      "batch 561: loss 0.176614 accuracy: 0.927349\n",
      "batch 562: loss 0.164499 accuracy: 0.927371\n",
      "batch 563: loss 0.119394 accuracy: 0.927438\n",
      "batch 564: loss 0.094172 accuracy: 0.927513\n",
      "batch 565: loss 0.092270 accuracy: 0.927606\n",
      "batch 566: loss 0.141407 accuracy: 0.927646\n",
      "batch 567: loss 0.184392 accuracy: 0.927667\n",
      "batch 568: loss 0.178924 accuracy: 0.927733\n",
      "batch 569: loss 0.123654 accuracy: 0.927807\n",
      "batch 570: loss 0.118553 accuracy: 0.927863\n",
      "batch 571: loss 0.145125 accuracy: 0.927920\n",
      "batch 572: loss 0.181182 accuracy: 0.927949\n",
      "batch 573: loss 0.134992 accuracy: 0.928023\n",
      "batch 574: loss 0.252742 accuracy: 0.928061\n",
      "batch 575: loss 0.116074 accuracy: 0.928116\n",
      "batch 576: loss 0.110881 accuracy: 0.928189\n",
      "batch 577: loss 0.167374 accuracy: 0.928227\n",
      "batch 578: loss 0.130212 accuracy: 0.928264\n",
      "batch 579: loss 0.182008 accuracy: 0.928302\n",
      "batch 580: loss 0.117883 accuracy: 0.928356\n",
      "batch 581: loss 0.135753 accuracy: 0.928402\n",
      "batch 582: loss 0.185119 accuracy: 0.928439\n",
      "batch 583: loss 0.121064 accuracy: 0.928519\n",
      "batch 584: loss 0.132398 accuracy: 0.928590\n",
      "batch 585: loss 0.117132 accuracy: 0.928652\n",
      "batch 586: loss 0.104433 accuracy: 0.928748\n",
      "batch 587: loss 0.170717 accuracy: 0.928793\n",
      "batch 588: loss 0.092010 accuracy: 0.928862\n",
      "batch 589: loss 0.167478 accuracy: 0.928932\n",
      "batch 590: loss 0.123307 accuracy: 0.928976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 591: loss 0.127288 accuracy: 0.929029\n",
      "batch 592: loss 0.137808 accuracy: 0.929089\n",
      "batch 593: loss 0.231446 accuracy: 0.929066\n",
      "batch 594: loss 0.116334 accuracy: 0.929118\n",
      "batch 595: loss 0.124516 accuracy: 0.929178\n",
      "batch 596: loss 0.106653 accuracy: 0.929238\n",
      "batch 597: loss 0.155653 accuracy: 0.929273\n",
      "batch 598: loss 0.097893 accuracy: 0.929357\n",
      "batch 599: loss 0.187984 accuracy: 0.929400\n",
      "batch 600: loss 0.147797 accuracy: 0.929443\n",
      "model saved to ./save\\ckpt-600\n",
      "batch 601: loss 0.163069 accuracy: 0.929485\n",
      "batch 602: loss 0.185491 accuracy: 0.929502\n",
      "batch 603: loss 0.129574 accuracy: 0.929545\n",
      "batch 604: loss 0.153001 accuracy: 0.929595\n",
      "batch 605: loss 0.193126 accuracy: 0.929629\n",
      "batch 606: loss 0.092847 accuracy: 0.929703\n",
      "batch 607: loss 0.231845 accuracy: 0.929712\n",
      "batch 608: loss 0.109923 accuracy: 0.929762\n",
      "batch 609: loss 0.169788 accuracy: 0.929820\n",
      "batch 610: loss 0.135825 accuracy: 0.929861\n",
      "batch 611: loss 0.111354 accuracy: 0.929926\n",
      "batch 612: loss 0.078509 accuracy: 0.930008\n",
      "batch 613: loss 0.092848 accuracy: 0.930081\n",
      "batch 614: loss 0.171956 accuracy: 0.930114\n",
      "batch 615: loss 0.094810 accuracy: 0.930179\n",
      "batch 616: loss 0.143853 accuracy: 0.930219\n",
      "batch 617: loss 0.152651 accuracy: 0.930267\n",
      "batch 618: loss 0.085830 accuracy: 0.930331\n",
      "batch 619: loss 0.185905 accuracy: 0.930379\n",
      "batch 620: loss 0.156568 accuracy: 0.930419\n",
      "batch 621: loss 0.164611 accuracy: 0.930482\n",
      "batch 622: loss 0.127142 accuracy: 0.930554\n",
      "batch 623: loss 0.166362 accuracy: 0.930593\n",
      "batch 624: loss 0.098702 accuracy: 0.930672\n",
      "batch 625: loss 0.085589 accuracy: 0.930735\n",
      "batch 626: loss 0.105225 accuracy: 0.930797\n",
      "batch 627: loss 0.107725 accuracy: 0.930868\n",
      "batch 628: loss 0.167224 accuracy: 0.930890\n",
      "batch 629: loss 0.116145 accuracy: 0.930960\n",
      "batch 630: loss 0.133421 accuracy: 0.930998\n",
      "batch 631: loss 0.137605 accuracy: 0.931052\n",
      "batch 632: loss 0.114078 accuracy: 0.931114\n",
      "batch 633: loss 0.092957 accuracy: 0.931191\n",
      "batch 634: loss 0.150692 accuracy: 0.931252\n",
      "batch 635: loss 0.138210 accuracy: 0.931289\n",
      "batch 636: loss 0.134688 accuracy: 0.931358\n",
      "batch 637: loss 0.166500 accuracy: 0.931411\n",
      "batch 638: loss 0.098292 accuracy: 0.931495\n",
      "batch 639: loss 0.159092 accuracy: 0.931539\n",
      "batch 640: loss 0.139834 accuracy: 0.931583\n",
      "batch 641: loss 0.141212 accuracy: 0.931628\n",
      "batch 642: loss 0.146257 accuracy: 0.931664\n",
      "batch 643: loss 0.114393 accuracy: 0.931708\n",
      "batch 644: loss 0.142754 accuracy: 0.931760\n",
      "batch 645: loss 0.155114 accuracy: 0.931788\n",
      "batch 646: loss 0.129930 accuracy: 0.931808\n",
      "batch 647: loss 0.119982 accuracy: 0.931860\n",
      "batch 648: loss 0.098014 accuracy: 0.931926\n",
      "batch 649: loss 0.118510 accuracy: 0.931969\n",
      "batch 650: loss 0.111482 accuracy: 0.932012\n",
      "batch 651: loss 0.121931 accuracy: 0.932063\n",
      "batch 652: loss 0.113887 accuracy: 0.932106\n",
      "batch 653: loss 0.107859 accuracy: 0.932156\n",
      "batch 654: loss 0.141246 accuracy: 0.932183\n",
      "batch 655: loss 0.151861 accuracy: 0.932210\n",
      "batch 656: loss 0.158649 accuracy: 0.932230\n",
      "batch 657: loss 0.079527 accuracy: 0.932295\n",
      "batch 658: loss 0.125249 accuracy: 0.932344\n",
      "batch 659: loss 0.082852 accuracy: 0.932409\n",
      "batch 660: loss 0.088488 accuracy: 0.932474\n",
      "batch 661: loss 0.073371 accuracy: 0.932553\n",
      "batch 662: loss 0.116587 accuracy: 0.932609\n",
      "batch 663: loss 0.085253 accuracy: 0.932681\n",
      "batch 664: loss 0.135870 accuracy: 0.932722\n",
      "batch 665: loss 0.138601 accuracy: 0.932785\n",
      "batch 666: loss 0.064009 accuracy: 0.932856\n",
      "batch 667: loss 0.086582 accuracy: 0.932919\n",
      "batch 668: loss 0.137679 accuracy: 0.932960\n",
      "batch 669: loss 0.128265 accuracy: 0.932978\n",
      "batch 670: loss 0.121542 accuracy: 0.933010\n",
      "batch 671: loss 0.146199 accuracy: 0.933073\n",
      "batch 672: loss 0.110186 accuracy: 0.933120\n",
      "batch 673: loss 0.090700 accuracy: 0.933182\n",
      "batch 674: loss 0.092316 accuracy: 0.933259\n",
      "batch 675: loss 0.126831 accuracy: 0.933291\n",
      "batch 676: loss 0.120764 accuracy: 0.933353\n",
      "batch 677: loss 0.125067 accuracy: 0.933414\n",
      "batch 678: loss 0.095192 accuracy: 0.933461\n",
      "batch 679: loss 0.095303 accuracy: 0.933515\n",
      "batch 680: loss 0.145881 accuracy: 0.933576\n",
      "batch 681: loss 0.082094 accuracy: 0.933651\n",
      "batch 682: loss 0.278167 accuracy: 0.933631\n",
      "batch 683: loss 0.112944 accuracy: 0.933684\n",
      "batch 684: loss 0.107428 accuracy: 0.933745\n",
      "batch 685: loss 0.133493 accuracy: 0.933761\n",
      "batch 686: loss 0.077882 accuracy: 0.933821\n",
      "batch 687: loss 0.130444 accuracy: 0.933852\n",
      "batch 688: loss 0.156861 accuracy: 0.933882\n",
      "batch 689: loss 0.167320 accuracy: 0.933913\n",
      "batch 690: loss 0.165869 accuracy: 0.933936\n",
      "batch 691: loss 0.136291 accuracy: 0.933974\n",
      "batch 692: loss 0.059024 accuracy: 0.934048\n",
      "batch 693: loss 0.095077 accuracy: 0.934092\n",
      "batch 694: loss 0.090547 accuracy: 0.934144\n",
      "batch 695: loss 0.149866 accuracy: 0.934152\n",
      "batch 696: loss 0.108921 accuracy: 0.934211\n",
      "batch 697: loss 0.099221 accuracy: 0.934255\n",
      "batch 698: loss 0.085294 accuracy: 0.934313\n",
      "batch 699: loss 0.130819 accuracy: 0.934364\n",
      "batch 700: loss 0.101328 accuracy: 0.934422\n",
      "model saved to ./save\\ckpt-700\n",
      "batch 701: loss 0.093030 accuracy: 0.934494\n",
      "batch 702: loss 0.135645 accuracy: 0.934531\n",
      "batch 703: loss 0.167468 accuracy: 0.934531\n",
      "batch 704: loss 0.101549 accuracy: 0.934589\n",
      "batch 705: loss 0.080069 accuracy: 0.934660\n",
      "batch 706: loss 0.102294 accuracy: 0.934731\n",
      "batch 707: loss 0.097355 accuracy: 0.934774\n",
      "batch 708: loss 0.133026 accuracy: 0.934803\n",
      "batch 709: loss 0.128266 accuracy: 0.934838\n",
      "batch 710: loss 0.134285 accuracy: 0.934895\n",
      "batch 711: loss 0.071491 accuracy: 0.934965\n",
      "batch 712: loss 0.126434 accuracy: 0.934993\n",
      "batch 713: loss 0.101760 accuracy: 0.935049\n",
      "batch 714: loss 0.124035 accuracy: 0.935084\n",
      "batch 715: loss 0.114526 accuracy: 0.935119\n",
      "batch 716: loss 0.112122 accuracy: 0.935160\n",
      "batch 717: loss 0.108621 accuracy: 0.935202\n",
      "batch 718: loss 0.052451 accuracy: 0.935285\n",
      "batch 719: loss 0.121464 accuracy: 0.935340\n",
      "batch 720: loss 0.071947 accuracy: 0.935402\n",
      "batch 721: loss 0.090953 accuracy: 0.935450\n",
      "batch 722: loss 0.080934 accuracy: 0.935519\n",
      "batch 723: loss 0.140164 accuracy: 0.935546\n",
      "batch 724: loss 0.107260 accuracy: 0.935593\n",
      "batch 725: loss 0.119541 accuracy: 0.935647\n",
      "batch 726: loss 0.068729 accuracy: 0.935722\n",
      "batch 727: loss 0.161202 accuracy: 0.935749\n",
      "batch 728: loss 0.153234 accuracy: 0.935782\n",
      "batch 729: loss 0.132924 accuracy: 0.935808\n",
      "batch 730: loss 0.160016 accuracy: 0.935834\n",
      "batch 731: loss 0.112952 accuracy: 0.935874\n",
      "batch 732: loss 0.095686 accuracy: 0.935935\n",
      "batch 733: loss 0.136648 accuracy: 0.935981\n",
      "batch 734: loss 0.076440 accuracy: 0.936041\n",
      "batch 735: loss 0.043814 accuracy: 0.936121\n",
      "batch 736: loss 0.139501 accuracy: 0.936160\n",
      "batch 737: loss 0.115779 accuracy: 0.936192\n",
      "batch 738: loss 0.055648 accuracy: 0.936265\n",
      "batch 739: loss 0.087512 accuracy: 0.936331\n",
      "batch 740: loss 0.105589 accuracy: 0.936370\n",
      "batch 741: loss 0.108617 accuracy: 0.936415\n",
      "batch 742: loss 0.118407 accuracy: 0.936460\n",
      "batch 743: loss 0.165282 accuracy: 0.936485\n",
      "batch 744: loss 0.145765 accuracy: 0.936530\n",
      "batch 745: loss 0.086866 accuracy: 0.936588\n",
      "batch 746: loss 0.111369 accuracy: 0.936633\n",
      "batch 747: loss 0.139320 accuracy: 0.936664\n",
      "batch 748: loss 0.081263 accuracy: 0.936729\n",
      "batch 749: loss 0.110327 accuracy: 0.936773\n",
      "batch 750: loss 0.087346 accuracy: 0.936824\n",
      "batch 751: loss 0.062184 accuracy: 0.936888\n",
      "batch 752: loss 0.076370 accuracy: 0.936946\n",
      "batch 753: loss 0.116156 accuracy: 0.936983\n",
      "batch 754: loss 0.093567 accuracy: 0.937027\n",
      "batch 755: loss 0.055392 accuracy: 0.937103\n",
      "batch 756: loss 0.099998 accuracy: 0.937147\n",
      "batch 757: loss 0.164188 accuracy: 0.937164\n",
      "batch 758: loss 0.106397 accuracy: 0.937220\n",
      "batch 759: loss 0.105553 accuracy: 0.937250\n",
      "batch 760: loss 0.098651 accuracy: 0.937300\n",
      "batch 761: loss 0.138963 accuracy: 0.937329\n",
      "batch 762: loss 0.083800 accuracy: 0.937379\n",
      "batch 763: loss 0.058067 accuracy: 0.937435\n",
      "batch 764: loss 0.180320 accuracy: 0.937451\n",
      "batch 765: loss 0.113458 accuracy: 0.937500\n",
      "batch 766: loss 0.085825 accuracy: 0.937549\n",
      "batch 767: loss 0.117057 accuracy: 0.937598\n",
      "batch 768: loss 0.078429 accuracy: 0.937653\n",
      "batch 769: loss 0.110388 accuracy: 0.937695\n",
      "batch 770: loss 0.126540 accuracy: 0.937711\n",
      "batch 771: loss 0.099088 accuracy: 0.937772\n",
      "batch 772: loss 0.067566 accuracy: 0.937814\n",
      "batch 773: loss 0.093756 accuracy: 0.937855\n",
      "batch 774: loss 0.075061 accuracy: 0.937910\n",
      "batch 775: loss 0.109897 accuracy: 0.937951\n",
      "batch 776: loss 0.107356 accuracy: 0.937999\n",
      "batch 777: loss 0.112551 accuracy: 0.938033\n",
      "batch 778: loss 0.116627 accuracy: 0.938074\n",
      "batch 779: loss 0.062484 accuracy: 0.938122\n",
      "batch 780: loss 0.076564 accuracy: 0.938169\n",
      "batch 781: loss 0.048925 accuracy: 0.938235\n",
      "batch 782: loss 0.069251 accuracy: 0.938282\n",
      "batch 783: loss 0.122004 accuracy: 0.938304\n",
      "batch 784: loss 0.180232 accuracy: 0.938331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 785: loss 0.117611 accuracy: 0.938384\n",
      "batch 786: loss 0.121138 accuracy: 0.938443\n",
      "batch 787: loss 0.112191 accuracy: 0.938464\n",
      "batch 788: loss 0.134518 accuracy: 0.938498\n",
      "batch 789: loss 0.133463 accuracy: 0.938525\n",
      "batch 790: loss 0.092494 accuracy: 0.938571\n",
      "batch 791: loss 0.129171 accuracy: 0.938599\n",
      "batch 792: loss 0.126356 accuracy: 0.938632\n",
      "batch 793: loss 0.079046 accuracy: 0.938671\n",
      "batch 794: loss 0.068989 accuracy: 0.938730\n",
      "batch 795: loss 0.063515 accuracy: 0.938800\n",
      "batch 796: loss 0.081106 accuracy: 0.938852\n",
      "batch 797: loss 0.091618 accuracy: 0.938897\n",
      "batch 798: loss 0.157626 accuracy: 0.938917\n",
      "batch 799: loss 0.110318 accuracy: 0.938950\n",
      "batch 800: loss 0.073858 accuracy: 0.938995\n",
      "model saved to ./save\\ckpt-800\n",
      "batch 801: loss 0.086016 accuracy: 0.939046\n",
      "batch 802: loss 0.074149 accuracy: 0.939091\n",
      "batch 803: loss 0.087893 accuracy: 0.939136\n",
      "batch 804: loss 0.132895 accuracy: 0.939155\n",
      "batch 805: loss 0.117861 accuracy: 0.939175\n",
      "batch 806: loss 0.061822 accuracy: 0.939238\n",
      "batch 807: loss 0.075089 accuracy: 0.939288\n",
      "batch 808: loss 0.104563 accuracy: 0.939332\n",
      "batch 809: loss 0.162387 accuracy: 0.939364\n",
      "batch 810: loss 0.114536 accuracy: 0.939402\n",
      "batch 811: loss 0.148380 accuracy: 0.939427\n",
      "batch 812: loss 0.157844 accuracy: 0.939453\n",
      "batch 813: loss 0.098424 accuracy: 0.939490\n",
      "batch 814: loss 0.127762 accuracy: 0.939521\n",
      "batch 815: loss 0.054776 accuracy: 0.939571\n",
      "batch 816: loss 0.086612 accuracy: 0.939602\n",
      "batch 817: loss 0.140014 accuracy: 0.939633\n",
      "batch 818: loss 0.092594 accuracy: 0.939683\n",
      "batch 819: loss 0.127493 accuracy: 0.939707\n",
      "batch 820: loss 0.086428 accuracy: 0.939750\n",
      "batch 821: loss 0.061678 accuracy: 0.939805\n",
      "batch 822: loss 0.074136 accuracy: 0.939860\n",
      "batch 823: loss 0.156619 accuracy: 0.939891\n",
      "batch 824: loss 0.075032 accuracy: 0.939927\n",
      "batch 825: loss 0.100193 accuracy: 0.939964\n",
      "batch 826: loss 0.134345 accuracy: 0.939988\n",
      "batch 827: loss 0.120718 accuracy: 0.940030\n",
      "batch 828: loss 0.048929 accuracy: 0.940090\n",
      "batch 829: loss 0.111097 accuracy: 0.940120\n",
      "batch 830: loss 0.139897 accuracy: 0.940138\n",
      "batch 831: loss 0.096218 accuracy: 0.940186\n",
      "batch 832: loss 0.111997 accuracy: 0.940228\n",
      "batch 833: loss 0.040222 accuracy: 0.940294\n",
      "batch 834: loss 0.091928 accuracy: 0.940329\n",
      "batch 835: loss 0.065265 accuracy: 0.940389\n",
      "batch 836: loss 0.104753 accuracy: 0.940430\n",
      "batch 837: loss 0.119751 accuracy: 0.940442\n",
      "batch 838: loss 0.067735 accuracy: 0.940489\n",
      "batch 839: loss 0.084874 accuracy: 0.940536\n",
      "batch 840: loss 0.117946 accuracy: 0.940571\n",
      "batch 841: loss 0.120492 accuracy: 0.940606\n",
      "batch 842: loss 0.063023 accuracy: 0.940647\n",
      "batch 843: loss 0.105294 accuracy: 0.940681\n",
      "batch 844: loss 0.082553 accuracy: 0.940728\n",
      "batch 845: loss 0.087081 accuracy: 0.940768\n",
      "batch 846: loss 0.090093 accuracy: 0.940809\n",
      "batch 847: loss 0.156251 accuracy: 0.940814\n",
      "batch 848: loss 0.091595 accuracy: 0.940866\n",
      "batch 849: loss 0.096832 accuracy: 0.940894\n",
      "batch 850: loss 0.113352 accuracy: 0.940928\n",
      "batch 851: loss 0.107166 accuracy: 0.940962\n",
      "batch 852: loss 0.128434 accuracy: 0.940985\n",
      "batch 853: loss 0.089302 accuracy: 0.941019\n",
      "batch 854: loss 0.101400 accuracy: 0.941053\n",
      "batch 855: loss 0.052300 accuracy: 0.941116\n",
      "batch 856: loss 0.098176 accuracy: 0.941132\n",
      "batch 857: loss 0.110735 accuracy: 0.941160\n",
      "batch 858: loss 0.165617 accuracy: 0.941176\n",
      "batch 859: loss 0.135021 accuracy: 0.941198\n",
      "batch 860: loss 0.124376 accuracy: 0.941225\n",
      "batch 861: loss 0.080818 accuracy: 0.941276\n",
      "batch 862: loss 0.071505 accuracy: 0.941315\n",
      "batch 863: loss 0.098662 accuracy: 0.941348\n",
      "batch 864: loss 0.090304 accuracy: 0.941393\n",
      "batch 865: loss 0.064878 accuracy: 0.941443\n",
      "batch 866: loss 0.113381 accuracy: 0.941476\n",
      "batch 867: loss 0.143407 accuracy: 0.941486\n",
      "batch 868: loss 0.118382 accuracy: 0.941496\n",
      "batch 869: loss 0.074634 accuracy: 0.941529\n",
      "batch 870: loss 0.086368 accuracy: 0.941567\n",
      "batch 871: loss 0.117332 accuracy: 0.941606\n",
      "batch 872: loss 0.084412 accuracy: 0.941655\n",
      "batch 873: loss 0.135772 accuracy: 0.941682\n",
      "batch 874: loss 0.108640 accuracy: 0.941714\n",
      "batch 875: loss 0.112283 accuracy: 0.941752\n",
      "batch 876: loss 0.089939 accuracy: 0.941796\n",
      "batch 877: loss 0.086548 accuracy: 0.941834\n",
      "batch 878: loss 0.082951 accuracy: 0.941889\n",
      "batch 879: loss 0.100213 accuracy: 0.941926\n",
      "batch 880: loss 0.158129 accuracy: 0.941941\n",
      "batch 881: loss 0.179691 accuracy: 0.941950\n",
      "batch 882: loss 0.096883 accuracy: 0.941993\n",
      "batch 883: loss 0.084406 accuracy: 0.942031\n",
      "batch 884: loss 0.091910 accuracy: 0.942056\n",
      "batch 885: loss 0.093521 accuracy: 0.942082\n",
      "batch 886: loss 0.079702 accuracy: 0.942125\n",
      "batch 887: loss 0.159563 accuracy: 0.942151\n",
      "batch 888: loss 0.100930 accuracy: 0.942165\n",
      "batch 889: loss 0.090695 accuracy: 0.942191\n",
      "batch 890: loss 0.061803 accuracy: 0.942239\n",
      "batch 891: loss 0.073543 accuracy: 0.942281\n",
      "batch 892: loss 0.073100 accuracy: 0.942324\n",
      "batch 893: loss 0.087626 accuracy: 0.942360\n",
      "batch 894: loss 0.180562 accuracy: 0.942369\n",
      "batch 895: loss 0.108792 accuracy: 0.942394\n",
      "batch 896: loss 0.082189 accuracy: 0.942425\n",
      "batch 897: loss 0.084364 accuracy: 0.942461\n",
      "batch 898: loss 0.087654 accuracy: 0.942503\n",
      "batch 899: loss 0.100322 accuracy: 0.942533\n",
      "batch 900: loss 0.094452 accuracy: 0.942564\n",
      "model saved to ./save\\ckpt-900\n",
      "batch 901: loss 0.120131 accuracy: 0.942583\n",
      "batch 902: loss 0.061368 accuracy: 0.942619\n",
      "batch 903: loss 0.159754 accuracy: 0.942644\n",
      "batch 904: loss 0.093540 accuracy: 0.942674\n",
      "batch 905: loss 0.152918 accuracy: 0.942682\n",
      "batch 906: loss 0.069429 accuracy: 0.942734\n",
      "batch 907: loss 0.080316 accuracy: 0.942781\n",
      "batch 908: loss 0.141407 accuracy: 0.942783\n",
      "batch 909: loss 0.101989 accuracy: 0.942808\n",
      "batch 910: loss 0.096877 accuracy: 0.942827\n",
      "batch 911: loss 0.081096 accuracy: 0.942856\n",
      "batch 912: loss 0.087928 accuracy: 0.942908\n",
      "batch 913: loss 0.053055 accuracy: 0.942960\n",
      "batch 914: loss 0.121701 accuracy: 0.942984\n",
      "batch 915: loss 0.067488 accuracy: 0.943024\n",
      "batch 916: loss 0.090849 accuracy: 0.943064\n",
      "batch 917: loss 0.135999 accuracy: 0.943072\n",
      "batch 918: loss 0.121481 accuracy: 0.943090\n",
      "batch 919: loss 0.083907 accuracy: 0.943136\n",
      "batch 920: loss 0.118806 accuracy: 0.943170\n",
      "batch 921: loss 0.090420 accuracy: 0.943205\n",
      "batch 922: loss 0.080192 accuracy: 0.943234\n",
      "batch 923: loss 0.091684 accuracy: 0.943268\n",
      "batch 924: loss 0.108562 accuracy: 0.943281\n",
      "batch 925: loss 0.100076 accuracy: 0.943315\n",
      "batch 926: loss 0.081894 accuracy: 0.943366\n",
      "batch 927: loss 0.118849 accuracy: 0.943389\n",
      "batch 928: loss 0.058661 accuracy: 0.943434\n",
      "batch 929: loss 0.091603 accuracy: 0.943462\n",
      "batch 930: loss 0.095462 accuracy: 0.943502\n",
      "batch 931: loss 0.103799 accuracy: 0.943530\n",
      "batch 932: loss 0.088746 accuracy: 0.943564\n",
      "batch 933: loss 0.074411 accuracy: 0.943608\n",
      "batch 934: loss 0.081450 accuracy: 0.943647\n",
      "batch 935: loss 0.126398 accuracy: 0.943665\n",
      "batch 936: loss 0.091627 accuracy: 0.943687\n",
      "batch 937: loss 0.111446 accuracy: 0.943726\n",
      "batch 938: loss 0.130508 accuracy: 0.943759\n",
      "batch 939: loss 0.122054 accuracy: 0.943793\n",
      "batch 940: loss 0.077048 accuracy: 0.943831\n",
      "batch 941: loss 0.111256 accuracy: 0.943853\n",
      "batch 942: loss 0.071065 accuracy: 0.943897\n",
      "batch 943: loss 0.096865 accuracy: 0.943930\n",
      "batch 944: loss 0.066719 accuracy: 0.943974\n",
      "batch 945: loss 0.083771 accuracy: 0.944001\n",
      "batch 946: loss 0.112740 accuracy: 0.944018\n",
      "batch 947: loss 0.117723 accuracy: 0.944045\n",
      "batch 948: loss 0.077558 accuracy: 0.944073\n",
      "batch 949: loss 0.059889 accuracy: 0.944121\n",
      "batch 950: loss 0.112030 accuracy: 0.944154\n",
      "batch 951: loss 0.117532 accuracy: 0.944160\n",
      "batch 952: loss 0.071233 accuracy: 0.944203\n",
      "batch 953: loss 0.103039 accuracy: 0.944235\n",
      "batch 954: loss 0.067067 accuracy: 0.944288\n",
      "batch 955: loss 0.061385 accuracy: 0.944331\n",
      "batch 956: loss 0.116214 accuracy: 0.944363\n",
      "batch 957: loss 0.107311 accuracy: 0.944374\n",
      "batch 958: loss 0.195853 accuracy: 0.944385\n",
      "batch 959: loss 0.091650 accuracy: 0.944406\n",
      "batch 960: loss 0.071179 accuracy: 0.944448\n",
      "batch 961: loss 0.122318 accuracy: 0.944475\n",
      "batch 962: loss 0.110393 accuracy: 0.944507\n",
      "batch 963: loss 0.071644 accuracy: 0.944549\n",
      "batch 964: loss 0.092043 accuracy: 0.944570\n",
      "batch 965: loss 0.086352 accuracy: 0.944591\n",
      "batch 966: loss 0.081530 accuracy: 0.944612\n",
      "batch 967: loss 0.081304 accuracy: 0.944644\n",
      "batch 968: loss 0.063737 accuracy: 0.944675\n",
      "batch 969: loss 0.126999 accuracy: 0.944696\n",
      "batch 970: loss 0.091545 accuracy: 0.944717\n",
      "batch 971: loss 0.070361 accuracy: 0.944753\n",
      "batch 972: loss 0.079322 accuracy: 0.944789\n",
      "batch 973: loss 0.107855 accuracy: 0.944815\n",
      "batch 974: loss 0.110145 accuracy: 0.944831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 975: loss 0.174408 accuracy: 0.944836\n",
      "batch 976: loss 0.142685 accuracy: 0.944857\n",
      "batch 977: loss 0.112458 accuracy: 0.944872\n",
      "batch 978: loss 0.069996 accuracy: 0.944903\n",
      "batch 979: loss 0.067574 accuracy: 0.944939\n",
      "batch 980: loss 0.090019 accuracy: 0.944964\n",
      "batch 981: loss 0.102499 accuracy: 0.944995\n",
      "batch 982: loss 0.102165 accuracy: 0.945015\n",
      "batch 983: loss 0.181732 accuracy: 0.945015\n",
      "batch 984: loss 0.078422 accuracy: 0.945051\n",
      "batch 985: loss 0.131170 accuracy: 0.945076\n",
      "batch 986: loss 0.095394 accuracy: 0.945101\n",
      "batch 987: loss 0.088739 accuracy: 0.945137\n",
      "batch 988: loss 0.074552 accuracy: 0.945172\n",
      "batch 989: loss 0.130882 accuracy: 0.945197\n",
      "batch 990: loss 0.117233 accuracy: 0.945217\n",
      "batch 991: loss 0.036637 accuracy: 0.945272\n",
      "batch 992: loss 0.054961 accuracy: 0.945317\n",
      "batch 993: loss 0.049432 accuracy: 0.945367\n",
      "batch 994: loss 0.105822 accuracy: 0.945387\n",
      "batch 995: loss 0.105989 accuracy: 0.945422\n",
      "batch 996: loss 0.124365 accuracy: 0.945431\n",
      "batch 997: loss 0.060662 accuracy: 0.945461\n",
      "batch 998: loss 0.053481 accuracy: 0.945500\n",
      "batch 999: loss 0.076100 accuracy: 0.945530\n",
      "batch 1000: loss 0.075149 accuracy: 0.945569\n",
      "model saved to ./save\\ckpt-1000\n",
      "batch 1001: loss 0.098527 accuracy: 0.945589\n",
      "batch 1002: loss 0.071080 accuracy: 0.945623\n",
      "batch 1003: loss 0.125206 accuracy: 0.945632\n",
      "batch 1004: loss 0.061581 accuracy: 0.945682\n",
      "batch 1005: loss 0.066267 accuracy: 0.945716\n",
      "batch 1006: loss 0.062761 accuracy: 0.945750\n",
      "batch 1007: loss 0.077536 accuracy: 0.945784\n",
      "batch 1008: loss 0.110720 accuracy: 0.945798\n",
      "batch 1009: loss 0.097553 accuracy: 0.945817\n",
      "batch 1010: loss 0.050614 accuracy: 0.945861\n",
      "batch 1011: loss 0.061255 accuracy: 0.945899\n",
      "batch 1012: loss 0.131447 accuracy: 0.945913\n",
      "batch 1013: loss 0.106836 accuracy: 0.945932\n",
      "batch 1014: loss 0.060691 accuracy: 0.945966\n",
      "batch 1015: loss 0.074736 accuracy: 0.946004\n",
      "batch 1016: loss 0.133292 accuracy: 0.946018\n",
      "batch 1017: loss 0.079315 accuracy: 0.946051\n",
      "batch 1018: loss 0.065357 accuracy: 0.946084\n",
      "batch 1019: loss 0.048715 accuracy: 0.946123\n",
      "batch 1020: loss 0.132065 accuracy: 0.946141\n",
      "batch 1021: loss 0.162327 accuracy: 0.946150\n",
      "batch 1022: loss 0.122701 accuracy: 0.946163\n",
      "batch 1023: loss 0.071308 accuracy: 0.946191\n",
      "batch 1024: loss 0.139262 accuracy: 0.946195\n",
      "batch 1025: loss 0.092182 accuracy: 0.946228\n",
      "batch 1026: loss 0.062199 accuracy: 0.946256\n",
      "batch 1027: loss 0.054588 accuracy: 0.946284\n",
      "batch 1028: loss 0.051064 accuracy: 0.946327\n",
      "batch 1029: loss 0.058322 accuracy: 0.946369\n",
      "batch 1030: loss 0.074283 accuracy: 0.946406\n",
      "batch 1031: loss 0.053772 accuracy: 0.946444\n",
      "batch 1032: loss 0.115576 accuracy: 0.946462\n",
      "batch 1033: loss 0.074673 accuracy: 0.946494\n",
      "batch 1034: loss 0.100451 accuracy: 0.946527\n",
      "batch 1035: loss 0.106961 accuracy: 0.946544\n",
      "batch 1036: loss 0.063068 accuracy: 0.946586\n",
      "batch 1037: loss 0.069736 accuracy: 0.946614\n",
      "batch 1038: loss 0.088592 accuracy: 0.946631\n",
      "batch 1039: loss 0.046884 accuracy: 0.946668\n",
      "batch 1040: loss 0.135649 accuracy: 0.946691\n",
      "batch 1041: loss 0.036391 accuracy: 0.946742\n",
      "batch 1042: loss 0.099518 accuracy: 0.946774\n",
      "batch 1043: loss 0.110686 accuracy: 0.946791\n",
      "batch 1044: loss 0.094036 accuracy: 0.946813\n",
      "batch 1045: loss 0.068467 accuracy: 0.946850\n",
      "batch 1046: loss 0.077989 accuracy: 0.946882\n",
      "batch 1047: loss 0.093241 accuracy: 0.946904\n",
      "batch 1048: loss 0.069146 accuracy: 0.946935\n",
      "batch 1049: loss 0.116269 accuracy: 0.946948\n",
      "batch 1050: loss 0.060903 accuracy: 0.946970\n",
      "batch 1051: loss 0.127705 accuracy: 0.946987\n",
      "batch 1052: loss 0.062430 accuracy: 0.947023\n",
      "batch 1053: loss 0.034774 accuracy: 0.947064\n",
      "batch 1054: loss 0.078048 accuracy: 0.947085\n",
      "batch 1055: loss 0.067848 accuracy: 0.947126\n",
      "batch 1056: loss 0.059612 accuracy: 0.947167\n",
      "batch 1057: loss 0.110232 accuracy: 0.947188\n",
      "batch 1058: loss 0.047328 accuracy: 0.947233\n",
      "batch 1059: loss 0.089807 accuracy: 0.947259\n",
      "batch 1060: loss 0.072869 accuracy: 0.947290\n",
      "batch 1061: loss 0.140515 accuracy: 0.947307\n",
      "batch 1062: loss 0.051503 accuracy: 0.947342\n",
      "batch 1063: loss 0.045895 accuracy: 0.947383\n",
      "batch 1064: loss 0.050944 accuracy: 0.947423\n",
      "batch 1065: loss 0.097506 accuracy: 0.947439\n",
      "batch 1066: loss 0.086709 accuracy: 0.947460\n",
      "batch 1067: loss 0.121194 accuracy: 0.947481\n",
      "batch 1068: loss 0.120323 accuracy: 0.947493\n",
      "batch 1069: loss 0.040243 accuracy: 0.947537\n",
      "batch 1070: loss 0.050479 accuracy: 0.947572\n",
      "batch 1071: loss 0.075961 accuracy: 0.947593\n",
      "batch 1072: loss 0.062493 accuracy: 0.947633\n",
      "batch 1073: loss 0.087746 accuracy: 0.947654\n",
      "batch 1074: loss 0.110022 accuracy: 0.947674\n",
      "batch 1075: loss 0.048842 accuracy: 0.947709\n",
      "batch 1076: loss 0.054907 accuracy: 0.947748\n",
      "batch 1077: loss 0.105869 accuracy: 0.947769\n",
      "batch 1078: loss 0.078633 accuracy: 0.947799\n",
      "batch 1079: loss 0.088768 accuracy: 0.947824\n",
      "batch 1080: loss 0.078838 accuracy: 0.947854\n",
      "batch 1081: loss 0.052254 accuracy: 0.947888\n",
      "batch 1082: loss 0.052211 accuracy: 0.947927\n",
      "batch 1083: loss 0.039008 accuracy: 0.947961\n",
      "batch 1084: loss 0.034689 accuracy: 0.948005\n",
      "batch 1085: loss 0.068025 accuracy: 0.948034\n",
      "batch 1086: loss 0.093953 accuracy: 0.948059\n",
      "batch 1087: loss 0.103657 accuracy: 0.948065\n",
      "batch 1088: loss 0.064910 accuracy: 0.948099\n",
      "batch 1089: loss 0.030343 accuracy: 0.948147\n",
      "batch 1090: loss 0.052917 accuracy: 0.948181\n",
      "batch 1091: loss 0.060756 accuracy: 0.948219\n",
      "batch 1092: loss 0.043195 accuracy: 0.948262\n",
      "batch 1093: loss 0.064509 accuracy: 0.948291\n",
      "batch 1094: loss 0.095461 accuracy: 0.948315\n",
      "batch 1095: loss 0.117208 accuracy: 0.948330\n",
      "batch 1096: loss 0.061057 accuracy: 0.948359\n",
      "batch 1097: loss 0.107453 accuracy: 0.948370\n",
      "batch 1098: loss 0.134219 accuracy: 0.948376\n",
      "batch 1099: loss 0.093029 accuracy: 0.948405\n",
      "batch 1100: loss 0.048046 accuracy: 0.948438\n",
      "model saved to ./save\\ckpt-1100\n",
      "batch 1101: loss 0.071502 accuracy: 0.948475\n",
      "batch 1102: loss 0.064812 accuracy: 0.948495\n",
      "batch 1103: loss 0.102857 accuracy: 0.948510\n",
      "batch 1104: loss 0.090653 accuracy: 0.948520\n",
      "batch 1105: loss 0.092602 accuracy: 0.948531\n",
      "batch 1106: loss 0.105902 accuracy: 0.948559\n",
      "batch 1107: loss 0.056856 accuracy: 0.948592\n",
      "batch 1108: loss 0.081633 accuracy: 0.948616\n",
      "batch 1109: loss 0.113218 accuracy: 0.948644\n",
      "batch 1110: loss 0.094026 accuracy: 0.948663\n",
      "batch 1111: loss 0.053232 accuracy: 0.948692\n",
      "batch 1112: loss 0.060620 accuracy: 0.948724\n",
      "batch 1113: loss 0.041073 accuracy: 0.948761\n",
      "batch 1114: loss 0.096833 accuracy: 0.948780\n",
      "batch 1115: loss 0.055125 accuracy: 0.948813\n",
      "batch 1116: loss 0.077051 accuracy: 0.948845\n",
      "batch 1117: loss 0.091986 accuracy: 0.948864\n",
      "batch 1118: loss 0.070794 accuracy: 0.948892\n",
      "batch 1119: loss 0.054694 accuracy: 0.948920\n",
      "batch 1120: loss 0.055796 accuracy: 0.948961\n",
      "batch 1121: loss 0.064238 accuracy: 0.948993\n",
      "batch 1122: loss 0.098845 accuracy: 0.949007\n",
      "batch 1123: loss 0.039641 accuracy: 0.949044\n",
      "batch 1124: loss 0.140314 accuracy: 0.949049\n",
      "batch 1125: loss 0.092261 accuracy: 0.949072\n",
      "batch 1126: loss 0.110158 accuracy: 0.949082\n",
      "batch 1127: loss 0.050595 accuracy: 0.949118\n",
      "batch 1128: loss 0.064930 accuracy: 0.949145\n",
      "batch 1129: loss 0.076522 accuracy: 0.949177\n",
      "batch 1130: loss 0.067370 accuracy: 0.949209\n",
      "batch 1131: loss 0.100375 accuracy: 0.949236\n",
      "batch 1132: loss 0.083860 accuracy: 0.949250\n",
      "batch 1133: loss 0.073377 accuracy: 0.949273\n",
      "batch 1134: loss 0.062201 accuracy: 0.949304\n",
      "batch 1135: loss 0.073914 accuracy: 0.949335\n",
      "batch 1136: loss 0.038786 accuracy: 0.949371\n",
      "batch 1137: loss 0.068029 accuracy: 0.949389\n",
      "batch 1138: loss 0.043362 accuracy: 0.949429\n",
      "batch 1139: loss 0.105918 accuracy: 0.949443\n",
      "batch 1140: loss 0.048321 accuracy: 0.949479\n",
      "batch 1141: loss 0.066648 accuracy: 0.949497\n",
      "batch 1142: loss 0.088393 accuracy: 0.949514\n",
      "batch 1143: loss 0.100486 accuracy: 0.949519\n",
      "batch 1144: loss 0.090072 accuracy: 0.949546\n",
      "batch 1145: loss 0.026682 accuracy: 0.949590\n",
      "batch 1146: loss 0.091326 accuracy: 0.949616\n",
      "batch 1147: loss 0.049533 accuracy: 0.949647\n",
      "batch 1148: loss 0.061277 accuracy: 0.949682\n",
      "batch 1149: loss 0.072685 accuracy: 0.949709\n",
      "batch 1150: loss 0.059273 accuracy: 0.949735\n",
      "batch 1151: loss 0.066818 accuracy: 0.949757\n",
      "batch 1152: loss 0.033013 accuracy: 0.949796\n",
      "batch 1153: loss 0.116981 accuracy: 0.949792\n",
      "batch 1154: loss 0.079986 accuracy: 0.949814\n",
      "batch 1155: loss 0.058322 accuracy: 0.949844\n",
      "batch 1156: loss 0.060701 accuracy: 0.949875\n",
      "batch 1157: loss 0.036238 accuracy: 0.949909\n",
      "batch 1158: loss 0.061701 accuracy: 0.949948\n",
      "batch 1159: loss 0.089263 accuracy: 0.949970\n",
      "batch 1160: loss 0.111058 accuracy: 0.949983\n",
      "batch 1161: loss 0.039887 accuracy: 0.950017\n",
      "batch 1162: loss 0.036286 accuracy: 0.950052\n",
      "batch 1163: loss 0.062065 accuracy: 0.950073\n",
      "batch 1164: loss 0.073096 accuracy: 0.950094\n",
      "batch 1165: loss 0.049401 accuracy: 0.950129\n",
      "batch 1166: loss 0.081537 accuracy: 0.950154\n",
      "batch 1167: loss 0.043224 accuracy: 0.950188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1168: loss 0.065324 accuracy: 0.950222\n",
      "batch 1169: loss 0.047178 accuracy: 0.950256\n",
      "batch 1170: loss 0.101459 accuracy: 0.950278\n",
      "batch 1171: loss 0.068737 accuracy: 0.950299\n",
      "batch 1172: loss 0.070118 accuracy: 0.950324\n",
      "batch 1173: loss 0.065756 accuracy: 0.950349\n",
      "batch 1174: loss 0.136714 accuracy: 0.950357\n",
      "batch 1175: loss 0.074204 accuracy: 0.950383\n",
      "batch 1176: loss 0.035948 accuracy: 0.950416\n",
      "batch 1177: loss 0.036008 accuracy: 0.950454\n",
      "batch 1178: loss 0.117352 accuracy: 0.950462\n",
      "batch 1179: loss 0.182692 accuracy: 0.950466\n",
      "batch 1180: loss 0.037728 accuracy: 0.950508\n",
      "batch 1181: loss 0.053923 accuracy: 0.950541\n",
      "batch 1182: loss 0.094742 accuracy: 0.950554\n",
      "batch 1183: loss 0.040337 accuracy: 0.950587\n",
      "batch 1184: loss 0.063800 accuracy: 0.950608\n",
      "batch 1185: loss 0.092292 accuracy: 0.950628\n",
      "batch 1186: loss 0.060728 accuracy: 0.950653\n",
      "batch 1187: loss 0.050576 accuracy: 0.950682\n",
      "batch 1188: loss 0.078309 accuracy: 0.950711\n",
      "batch 1189: loss 0.033684 accuracy: 0.950748\n",
      "batch 1190: loss 0.065457 accuracy: 0.950772\n",
      "batch 1191: loss 0.077830 accuracy: 0.950793\n",
      "batch 1192: loss 0.037465 accuracy: 0.950830\n",
      "batch 1193: loss 0.071230 accuracy: 0.950846\n",
      "batch 1194: loss 0.108960 accuracy: 0.950870\n",
      "batch 1195: loss 0.147636 accuracy: 0.950874\n",
      "batch 1196: loss 0.055581 accuracy: 0.950898\n",
      "batch 1197: loss 0.127104 accuracy: 0.950906\n",
      "batch 1198: loss 0.087506 accuracy: 0.950917\n",
      "batch 1199: loss 0.033267 accuracy: 0.950954\n",
      "batch 1200: loss 0.086957 accuracy: 0.950966\n",
      "model saved to ./save\\ckpt-1200\n",
      "batch 1201: loss 0.086164 accuracy: 0.950990\n",
      "batch 1202: loss 0.134762 accuracy: 0.951002\n",
      "batch 1203: loss 0.075173 accuracy: 0.951017\n",
      "batch 1204: loss 0.072494 accuracy: 0.951046\n",
      "batch 1205: loss 0.080783 accuracy: 0.951074\n",
      "batch 1206: loss 0.074431 accuracy: 0.951094\n",
      "batch 1207: loss 0.094993 accuracy: 0.951113\n",
      "batch 1208: loss 0.063002 accuracy: 0.951133\n",
      "batch 1209: loss 0.066968 accuracy: 0.951153\n",
      "batch 1210: loss 0.047391 accuracy: 0.951185\n",
      "batch 1211: loss 0.070158 accuracy: 0.951196\n",
      "batch 1212: loss 0.093383 accuracy: 0.951220\n",
      "batch 1213: loss 0.066640 accuracy: 0.951256\n",
      "batch 1214: loss 0.047906 accuracy: 0.951288\n",
      "batch 1215: loss 0.078736 accuracy: 0.951308\n",
      "batch 1216: loss 0.088764 accuracy: 0.951323\n",
      "batch 1217: loss 0.067214 accuracy: 0.951346\n",
      "batch 1218: loss 0.123587 accuracy: 0.951354\n",
      "batch 1219: loss 0.049835 accuracy: 0.951389\n",
      "batch 1220: loss 0.053774 accuracy: 0.951417\n",
      "batch 1221: loss 0.075401 accuracy: 0.951436\n",
      "batch 1222: loss 0.061549 accuracy: 0.951455\n",
      "batch 1223: loss 0.059116 accuracy: 0.951483\n",
      "batch 1224: loss 0.062987 accuracy: 0.951510\n",
      "batch 1225: loss 0.064444 accuracy: 0.951533\n",
      "batch 1226: loss 0.045248 accuracy: 0.951565\n",
      "batch 1227: loss 0.112221 accuracy: 0.951576\n",
      "batch 1228: loss 0.084681 accuracy: 0.951603\n",
      "batch 1229: loss 0.061187 accuracy: 0.951622\n",
      "batch 1230: loss 0.032308 accuracy: 0.951653\n",
      "batch 1231: loss 0.063209 accuracy: 0.951680\n",
      "batch 1232: loss 0.096662 accuracy: 0.951691\n",
      "batch 1233: loss 0.061357 accuracy: 0.951718\n",
      "batch 1234: loss 0.063779 accuracy: 0.951741\n",
      "batch 1235: loss 0.061625 accuracy: 0.951764\n",
      "batch 1236: loss 0.073387 accuracy: 0.951783\n",
      "batch 1237: loss 0.117152 accuracy: 0.951801\n",
      "batch 1238: loss 0.080638 accuracy: 0.951824\n",
      "batch 1239: loss 0.097314 accuracy: 0.951835\n",
      "batch 1240: loss 0.046498 accuracy: 0.951857\n",
      "batch 1241: loss 0.101433 accuracy: 0.951876\n",
      "batch 1242: loss 0.032718 accuracy: 0.951915\n",
      "batch 1243: loss 0.088685 accuracy: 0.951937\n",
      "batch 1244: loss 0.051957 accuracy: 0.951968\n",
      "batch 1245: loss 0.052497 accuracy: 0.951998\n",
      "batch 1246: loss 0.048686 accuracy: 0.952029\n",
      "batch 1247: loss 0.104366 accuracy: 0.952039\n",
      "batch 1248: loss 0.060280 accuracy: 0.952070\n",
      "batch 1249: loss 0.046540 accuracy: 0.952100\n",
      "batch 1250: loss 0.043706 accuracy: 0.952130\n",
      "batch 1251: loss 0.053454 accuracy: 0.952153\n",
      "batch 1252: loss 0.062834 accuracy: 0.952171\n",
      "batch 1253: loss 0.041471 accuracy: 0.952193\n",
      "batch 1254: loss 0.032460 accuracy: 0.952223\n",
      "batch 1255: loss 0.118019 accuracy: 0.952229\n",
      "batch 1256: loss 0.076539 accuracy: 0.952247\n",
      "batch 1257: loss 0.035301 accuracy: 0.952281\n",
      "batch 1258: loss 0.071643 accuracy: 0.952303\n",
      "batch 1259: loss 0.058215 accuracy: 0.952329\n",
      "batch 1260: loss 0.114687 accuracy: 0.952335\n",
      "batch 1261: loss 0.048820 accuracy: 0.952357\n",
      "batch 1262: loss 0.073216 accuracy: 0.952383\n",
      "batch 1263: loss 0.067690 accuracy: 0.952397\n",
      "batch 1264: loss 0.092310 accuracy: 0.952415\n",
      "batch 1265: loss 0.050519 accuracy: 0.952441\n",
      "batch 1266: loss 0.050231 accuracy: 0.952466\n",
      "batch 1267: loss 0.052154 accuracy: 0.952488\n",
      "batch 1268: loss 0.105972 accuracy: 0.952494\n",
      "batch 1269: loss 0.090005 accuracy: 0.952500\n",
      "batch 1270: loss 0.078421 accuracy: 0.952514\n",
      "batch 1271: loss 0.082661 accuracy: 0.952528\n",
      "batch 1272: loss 0.026669 accuracy: 0.952565\n",
      "batch 1273: loss 0.058305 accuracy: 0.952590\n",
      "batch 1274: loss 0.107191 accuracy: 0.952604\n",
      "batch 1275: loss 0.048592 accuracy: 0.952629\n",
      "batch 1276: loss 0.098806 accuracy: 0.952647\n",
      "batch 1277: loss 0.056336 accuracy: 0.952672\n",
      "batch 1278: loss 0.028096 accuracy: 0.952701\n",
      "batch 1279: loss 0.048188 accuracy: 0.952730\n",
      "batch 1280: loss 0.065861 accuracy: 0.952748\n",
      "batch 1281: loss 0.064722 accuracy: 0.952769\n",
      "batch 1282: loss 0.025104 accuracy: 0.952806\n",
      "batch 1283: loss 0.072332 accuracy: 0.952831\n",
      "batch 1284: loss 0.074550 accuracy: 0.952844\n",
      "batch 1285: loss 0.084840 accuracy: 0.952865\n",
      "batch 1286: loss 0.046642 accuracy: 0.952894\n",
      "batch 1287: loss 0.118672 accuracy: 0.952911\n",
      "batch 1288: loss 0.034693 accuracy: 0.952940\n",
      "batch 1289: loss 0.057775 accuracy: 0.952957\n",
      "batch 1290: loss 0.065833 accuracy: 0.952978\n",
      "batch 1291: loss 0.027885 accuracy: 0.953011\n",
      "batch 1292: loss 0.064211 accuracy: 0.953024\n",
      "batch 1293: loss 0.093553 accuracy: 0.953022\n",
      "batch 1294: loss 0.076861 accuracy: 0.953031\n",
      "batch 1295: loss 0.068023 accuracy: 0.953052\n",
      "batch 1296: loss 0.067721 accuracy: 0.953076\n",
      "batch 1297: loss 0.061122 accuracy: 0.953101\n",
      "batch 1298: loss 0.040027 accuracy: 0.953129\n",
      "batch 1299: loss 0.079354 accuracy: 0.953150\n",
      "batch 1300: loss 0.070248 accuracy: 0.953171\n",
      "model saved to ./save\\ckpt-1300\n",
      "batch 1301: loss 0.031388 accuracy: 0.953207\n",
      "batch 1302: loss 0.124926 accuracy: 0.953219\n",
      "batch 1303: loss 0.066101 accuracy: 0.953244\n",
      "batch 1304: loss 0.066126 accuracy: 0.953261\n",
      "batch 1305: loss 0.080468 accuracy: 0.953281\n",
      "batch 1306: loss 0.106345 accuracy: 0.953301\n",
      "batch 1307: loss 0.069502 accuracy: 0.953330\n",
      "batch 1308: loss 0.084005 accuracy: 0.953342\n",
      "batch 1309: loss 0.054396 accuracy: 0.953370\n",
      "batch 1310: loss 0.063758 accuracy: 0.953387\n",
      "batch 1311: loss 0.071770 accuracy: 0.953396\n",
      "batch 1312: loss 0.068633 accuracy: 0.953416\n",
      "batch 1313: loss 0.090947 accuracy: 0.953425\n",
      "batch 1314: loss 0.102185 accuracy: 0.953430\n",
      "batch 1315: loss 0.105854 accuracy: 0.953450\n",
      "batch 1316: loss 0.093745 accuracy: 0.953466\n",
      "batch 1317: loss 0.136468 accuracy: 0.953479\n",
      "batch 1318: loss 0.057874 accuracy: 0.953495\n",
      "batch 1319: loss 0.041068 accuracy: 0.953523\n",
      "batch 1320: loss 0.035227 accuracy: 0.953554\n",
      "batch 1321: loss 0.074348 accuracy: 0.953570\n",
      "batch 1322: loss 0.037745 accuracy: 0.953598\n",
      "batch 1323: loss 0.065463 accuracy: 0.953622\n",
      "batch 1324: loss 0.082638 accuracy: 0.953649\n",
      "batch 1325: loss 0.049033 accuracy: 0.953673\n",
      "batch 1326: loss 0.081140 accuracy: 0.953685\n",
      "batch 1327: loss 0.080393 accuracy: 0.953701\n",
      "batch 1328: loss 0.071243 accuracy: 0.953725\n",
      "batch 1329: loss 0.047686 accuracy: 0.953748\n",
      "batch 1330: loss 0.041845 accuracy: 0.953775\n",
      "batch 1331: loss 0.073226 accuracy: 0.953795\n",
      "batch 1332: loss 0.069612 accuracy: 0.953803\n",
      "batch 1333: loss 0.029538 accuracy: 0.953834\n",
      "batch 1334: loss 0.055735 accuracy: 0.953858\n",
      "batch 1335: loss 0.080613 accuracy: 0.953885\n",
      "batch 1336: loss 0.119734 accuracy: 0.953889\n",
      "batch 1337: loss 0.143143 accuracy: 0.953901\n",
      "batch 1338: loss 0.067149 accuracy: 0.953925\n",
      "batch 1339: loss 0.055293 accuracy: 0.953951\n",
      "batch 1340: loss 0.027494 accuracy: 0.953982\n",
      "batch 1341: loss 0.079978 accuracy: 0.954001\n",
      "batch 1342: loss 0.128548 accuracy: 0.954013\n",
      "batch 1343: loss 0.047123 accuracy: 0.954036\n",
      "batch 1344: loss 0.077519 accuracy: 0.954056\n",
      "batch 1345: loss 0.079821 accuracy: 0.954071\n",
      "batch 1346: loss 0.083066 accuracy: 0.954083\n",
      "batch 1347: loss 0.059445 accuracy: 0.954102\n",
      "batch 1348: loss 0.150357 accuracy: 0.954099\n",
      "batch 1349: loss 0.076040 accuracy: 0.954100\n",
      "batch 1350: loss 0.084004 accuracy: 0.954108\n",
      "batch 1351: loss 0.045341 accuracy: 0.954135\n",
      "batch 1352: loss 0.080016 accuracy: 0.954146\n",
      "batch 1353: loss 0.040527 accuracy: 0.954176\n",
      "batch 1354: loss 0.073518 accuracy: 0.954192\n",
      "batch 1355: loss 0.147489 accuracy: 0.954204\n",
      "batch 1356: loss 0.048317 accuracy: 0.954230\n",
      "batch 1357: loss 0.043850 accuracy: 0.954256\n",
      "batch 1358: loss 0.097066 accuracy: 0.954268\n",
      "batch 1359: loss 0.032580 accuracy: 0.954301\n",
      "batch 1360: loss 0.050766 accuracy: 0.954328\n",
      "batch 1361: loss 0.060896 accuracy: 0.954350\n",
      "batch 1362: loss 0.187508 accuracy: 0.954369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1363: loss 0.077636 accuracy: 0.954388\n",
      "batch 1364: loss 0.080820 accuracy: 0.954410\n",
      "batch 1365: loss 0.097793 accuracy: 0.954425\n",
      "batch 1366: loss 0.050936 accuracy: 0.954448\n",
      "batch 1367: loss 0.170661 accuracy: 0.954441\n",
      "batch 1368: loss 0.062944 accuracy: 0.954459\n",
      "batch 1369: loss 0.057789 accuracy: 0.954485\n",
      "batch 1370: loss 0.062725 accuracy: 0.954508\n",
      "batch 1371: loss 0.049198 accuracy: 0.954534\n",
      "batch 1372: loss 0.068186 accuracy: 0.954548\n",
      "batch 1373: loss 0.062504 accuracy: 0.954571\n",
      "batch 1374: loss 0.098328 accuracy: 0.954589\n",
      "batch 1375: loss 0.069779 accuracy: 0.954604\n",
      "batch 1376: loss 0.066138 accuracy: 0.954622\n",
      "batch 1377: loss 0.051782 accuracy: 0.954648\n",
      "batch 1378: loss 0.069556 accuracy: 0.954659\n",
      "batch 1379: loss 0.036129 accuracy: 0.954685\n",
      "batch 1380: loss 0.075530 accuracy: 0.954703\n",
      "batch 1381: loss 0.077270 accuracy: 0.954714\n",
      "batch 1382: loss 0.048225 accuracy: 0.954740\n",
      "batch 1383: loss 0.061576 accuracy: 0.954758\n",
      "batch 1384: loss 0.072953 accuracy: 0.954780\n",
      "batch 1385: loss 0.069440 accuracy: 0.954794\n",
      "batch 1386: loss 0.082427 accuracy: 0.954809\n",
      "batch 1387: loss 0.099976 accuracy: 0.954816\n",
      "batch 1388: loss 0.055244 accuracy: 0.954842\n",
      "batch 1389: loss 0.053692 accuracy: 0.954860\n",
      "batch 1390: loss 0.078856 accuracy: 0.954874\n",
      "batch 1391: loss 0.065366 accuracy: 0.954889\n",
      "batch 1392: loss 0.043973 accuracy: 0.954910\n",
      "batch 1393: loss 0.048974 accuracy: 0.954932\n",
      "batch 1394: loss 0.042907 accuracy: 0.954957\n",
      "batch 1395: loss 0.069558 accuracy: 0.954979\n",
      "batch 1396: loss 0.091223 accuracy: 0.954993\n",
      "batch 1397: loss 0.076643 accuracy: 0.955011\n",
      "batch 1398: loss 0.031105 accuracy: 0.955039\n",
      "batch 1399: loss 0.084529 accuracy: 0.955039\n",
      "batch 1400: loss 0.049621 accuracy: 0.955064\n",
      "model saved to ./save\\ckpt-1400\n",
      "batch 1401: loss 0.060926 accuracy: 0.955082\n",
      "batch 1402: loss 0.098184 accuracy: 0.955100\n",
      "batch 1403: loss 0.056778 accuracy: 0.955125\n",
      "batch 1404: loss 0.088973 accuracy: 0.955142\n",
      "batch 1405: loss 0.045706 accuracy: 0.955167\n",
      "batch 1406: loss 0.076325 accuracy: 0.955178\n",
      "batch 1407: loss 0.044819 accuracy: 0.955199\n",
      "batch 1408: loss 0.050016 accuracy: 0.955224\n",
      "batch 1409: loss 0.044399 accuracy: 0.955252\n",
      "batch 1410: loss 0.036675 accuracy: 0.955280\n",
      "batch 1411: loss 0.075494 accuracy: 0.955290\n",
      "batch 1412: loss 0.056102 accuracy: 0.955318\n",
      "batch 1413: loss 0.102608 accuracy: 0.955332\n",
      "batch 1414: loss 0.062651 accuracy: 0.955350\n",
      "batch 1415: loss 0.050841 accuracy: 0.955367\n",
      "batch 1416: loss 0.143096 accuracy: 0.955370\n",
      "batch 1417: loss 0.068771 accuracy: 0.955384\n",
      "batch 1418: loss 0.054452 accuracy: 0.955405\n",
      "batch 1419: loss 0.062978 accuracy: 0.955423\n",
      "batch 1420: loss 0.042539 accuracy: 0.955443\n",
      "batch 1421: loss 0.034071 accuracy: 0.955471\n",
      "batch 1422: loss 0.051912 accuracy: 0.955488\n",
      "batch 1423: loss 0.086828 accuracy: 0.955495\n",
      "batch 1424: loss 0.145163 accuracy: 0.955505\n",
      "batch 1425: loss 0.071027 accuracy: 0.955522\n",
      "batch 1426: loss 0.051053 accuracy: 0.955543\n",
      "batch 1427: loss 0.082762 accuracy: 0.955553\n",
      "batch 1428: loss 0.050355 accuracy: 0.955577\n",
      "batch 1429: loss 0.048075 accuracy: 0.955605\n",
      "batch 1430: loss 0.046665 accuracy: 0.955629\n",
      "batch 1431: loss 0.113302 accuracy: 0.955632\n",
      "batch 1432: loss 0.099481 accuracy: 0.955649\n",
      "batch 1433: loss 0.172956 accuracy: 0.955659\n",
      "batch 1434: loss 0.087331 accuracy: 0.955666\n",
      "batch 1435: loss 0.034074 accuracy: 0.955689\n",
      "batch 1436: loss 0.097884 accuracy: 0.955692\n",
      "batch 1437: loss 0.058930 accuracy: 0.955713\n",
      "batch 1438: loss 0.057770 accuracy: 0.955733\n",
      "batch 1439: loss 0.046505 accuracy: 0.955757\n",
      "batch 1440: loss 0.037981 accuracy: 0.955781\n",
      "batch 1441: loss 0.056143 accuracy: 0.955801\n",
      "batch 1442: loss 0.057238 accuracy: 0.955821\n",
      "batch 1443: loss 0.080266 accuracy: 0.955835\n",
      "batch 1444: loss 0.113471 accuracy: 0.955844\n",
      "batch 1445: loss 0.085201 accuracy: 0.955851\n",
      "batch 1446: loss 0.079774 accuracy: 0.955860\n",
      "batch 1447: loss 0.053860 accuracy: 0.955881\n",
      "batch 1448: loss 0.082051 accuracy: 0.955894\n",
      "batch 1449: loss 0.051918 accuracy: 0.955917\n",
      "batch 1450: loss 0.077325 accuracy: 0.955930\n",
      "batch 1451: loss 0.046627 accuracy: 0.955947\n",
      "batch 1452: loss 0.060155 accuracy: 0.955967\n",
      "batch 1453: loss 0.046780 accuracy: 0.955987\n",
      "batch 1454: loss 0.039066 accuracy: 0.956010\n",
      "batch 1455: loss 0.068906 accuracy: 0.956027\n",
      "batch 1456: loss 0.043168 accuracy: 0.956050\n",
      "batch 1457: loss 0.042766 accuracy: 0.956073\n",
      "batch 1458: loss 0.034764 accuracy: 0.956100\n",
      "batch 1459: loss 0.033902 accuracy: 0.956123\n",
      "batch 1460: loss 0.056288 accuracy: 0.956140\n",
      "batch 1461: loss 0.041163 accuracy: 0.956159\n",
      "batch 1462: loss 0.038245 accuracy: 0.956182\n",
      "batch 1463: loss 0.082466 accuracy: 0.956199\n",
      "batch 1464: loss 0.103525 accuracy: 0.956208\n",
      "batch 1465: loss 0.054300 accuracy: 0.956224\n",
      "batch 1466: loss 0.060920 accuracy: 0.956241\n",
      "batch 1467: loss 0.059811 accuracy: 0.956257\n",
      "batch 1468: loss 0.101882 accuracy: 0.956270\n",
      "batch 1469: loss 0.059089 accuracy: 0.956286\n",
      "batch 1470: loss 0.054830 accuracy: 0.956309\n",
      "batch 1471: loss 0.035000 accuracy: 0.956335\n",
      "batch 1472: loss 0.056366 accuracy: 0.956358\n",
      "batch 1473: loss 0.041042 accuracy: 0.956374\n",
      "batch 1474: loss 0.081109 accuracy: 0.956393\n",
      "batch 1475: loss 0.061682 accuracy: 0.956409\n",
      "batch 1476: loss 0.064129 accuracy: 0.956429\n",
      "batch 1477: loss 0.062657 accuracy: 0.956451\n",
      "batch 1478: loss 0.055896 accuracy: 0.956471\n",
      "batch 1479: loss 0.063963 accuracy: 0.956490\n",
      "batch 1480: loss 0.028836 accuracy: 0.956519\n",
      "batch 1481: loss 0.049395 accuracy: 0.956542\n",
      "batch 1482: loss 0.064062 accuracy: 0.956558\n",
      "batch 1483: loss 0.078036 accuracy: 0.956567\n",
      "batch 1484: loss 0.045988 accuracy: 0.956586\n",
      "batch 1485: loss 0.073333 accuracy: 0.956602\n",
      "batch 1486: loss 0.032587 accuracy: 0.956624\n",
      "batch 1487: loss 0.048834 accuracy: 0.956647\n",
      "batch 1488: loss 0.042734 accuracy: 0.956666\n",
      "batch 1489: loss 0.051325 accuracy: 0.956688\n",
      "batch 1490: loss 0.042048 accuracy: 0.956710\n",
      "batch 1491: loss 0.044596 accuracy: 0.956739\n",
      "batch 1492: loss 0.103773 accuracy: 0.956748\n",
      "batch 1493: loss 0.038316 accuracy: 0.956770\n",
      "batch 1494: loss 0.042843 accuracy: 0.956796\n",
      "batch 1495: loss 0.035248 accuracy: 0.956818\n",
      "batch 1496: loss 0.083834 accuracy: 0.956830\n",
      "batch 1497: loss 0.053647 accuracy: 0.956846\n",
      "batch 1498: loss 0.123540 accuracy: 0.956851\n",
      "batch 1499: loss 0.073559 accuracy: 0.956863\n",
      "batch 1500: loss 0.121007 accuracy: 0.956865\n",
      "model saved to ./save\\ckpt-1500\n",
      "batch 1501: loss 0.035822 accuracy: 0.956891\n",
      "batch 1502: loss 0.097719 accuracy: 0.956893\n",
      "batch 1503: loss 0.074710 accuracy: 0.956912\n",
      "batch 1504: loss 0.034397 accuracy: 0.956937\n",
      "batch 1505: loss 0.058324 accuracy: 0.956955\n",
      "batch 1506: loss 0.031088 accuracy: 0.956977\n",
      "batch 1507: loss 0.046989 accuracy: 0.956996\n",
      "batch 1508: loss 0.055784 accuracy: 0.957018\n",
      "batch 1509: loss 0.026657 accuracy: 0.957043\n",
      "batch 1510: loss 0.021512 accuracy: 0.957068\n",
      "batch 1511: loss 0.057598 accuracy: 0.957087\n",
      "batch 1512: loss 0.034325 accuracy: 0.957108\n",
      "batch 1513: loss 0.084824 accuracy: 0.957127\n",
      "batch 1514: loss 0.044741 accuracy: 0.957145\n",
      "batch 1515: loss 0.016680 accuracy: 0.957173\n",
      "batch 1516: loss 0.090002 accuracy: 0.957185\n",
      "batch 1517: loss 0.106534 accuracy: 0.957190\n",
      "batch 1518: loss 0.036804 accuracy: 0.957212\n",
      "batch 1519: loss 0.121145 accuracy: 0.957224\n",
      "batch 1520: loss 0.044309 accuracy: 0.957242\n",
      "batch 1521: loss 0.069992 accuracy: 0.957257\n",
      "batch 1522: loss 0.060419 accuracy: 0.957272\n",
      "batch 1523: loss 0.086267 accuracy: 0.957290\n",
      "batch 1524: loss 0.034235 accuracy: 0.957315\n",
      "batch 1525: loss 0.020954 accuracy: 0.957339\n",
      "batch 1526: loss 0.032934 accuracy: 0.957367\n",
      "batch 1527: loss 0.054055 accuracy: 0.957382\n",
      "batch 1528: loss 0.052120 accuracy: 0.957404\n",
      "batch 1529: loss 0.073871 accuracy: 0.957415\n",
      "batch 1530: loss 0.056156 accuracy: 0.957433\n",
      "batch 1531: loss 0.031093 accuracy: 0.957461\n",
      "batch 1532: loss 0.081404 accuracy: 0.957472\n",
      "batch 1533: loss 0.076429 accuracy: 0.957484\n",
      "batch 1534: loss 0.036837 accuracy: 0.957505\n",
      "batch 1535: loss 0.108501 accuracy: 0.957520\n",
      "batch 1536: loss 0.079671 accuracy: 0.957537\n",
      "batch 1537: loss 0.068646 accuracy: 0.957549\n",
      "batch 1538: loss 0.052933 accuracy: 0.957567\n",
      "batch 1539: loss 0.044326 accuracy: 0.957588\n",
      "batch 1540: loss 0.071262 accuracy: 0.957605\n",
      "batch 1541: loss 0.040905 accuracy: 0.957626\n",
      "batch 1542: loss 0.069087 accuracy: 0.957638\n",
      "batch 1543: loss 0.061570 accuracy: 0.957649\n",
      "batch 1544: loss 0.037572 accuracy: 0.957670\n",
      "batch 1545: loss 0.064629 accuracy: 0.957684\n",
      "batch 1546: loss 0.076452 accuracy: 0.957702\n",
      "batch 1547: loss 0.061140 accuracy: 0.957716\n",
      "batch 1548: loss 0.065523 accuracy: 0.957734\n",
      "batch 1549: loss 0.053718 accuracy: 0.957752\n",
      "batch 1550: loss 0.057356 accuracy: 0.957769\n",
      "batch 1551: loss 0.067000 accuracy: 0.957780\n",
      "batch 1552: loss 0.054282 accuracy: 0.957798\n",
      "batch 1553: loss 0.055369 accuracy: 0.957815\n",
      "batch 1554: loss 0.046955 accuracy: 0.957830\n",
      "batch 1555: loss 0.066917 accuracy: 0.957844\n",
      "batch 1556: loss 0.043106 accuracy: 0.957861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1557: loss 0.023694 accuracy: 0.957888\n",
      "batch 1558: loss 0.057122 accuracy: 0.957906\n",
      "batch 1559: loss 0.031095 accuracy: 0.957933\n",
      "batch 1560: loss 0.020065 accuracy: 0.957956\n",
      "batch 1561: loss 0.064214 accuracy: 0.957971\n",
      "batch 1562: loss 0.054100 accuracy: 0.957988\n",
      "batch 1563: loss 0.052733 accuracy: 0.958008\n",
      "batch 1564: loss 0.109600 accuracy: 0.958019\n",
      "batch 1565: loss 0.039136 accuracy: 0.958040\n",
      "batch 1566: loss 0.044079 accuracy: 0.958057\n",
      "batch 1567: loss 0.065403 accuracy: 0.958074\n",
      "batch 1568: loss 0.075824 accuracy: 0.958091\n",
      "batch 1569: loss 0.057189 accuracy: 0.958115\n",
      "batch 1570: loss 0.118271 accuracy: 0.958132\n",
      "batch 1571: loss 0.040408 accuracy: 0.958152\n",
      "batch 1572: loss 0.069629 accuracy: 0.958169\n",
      "batch 1573: loss 0.059524 accuracy: 0.958183\n",
      "batch 1574: loss 0.098020 accuracy: 0.958194\n",
      "batch 1575: loss 0.079860 accuracy: 0.958204\n",
      "batch 1576: loss 0.078406 accuracy: 0.958218\n",
      "batch 1577: loss 0.070942 accuracy: 0.958235\n",
      "batch 1578: loss 0.064567 accuracy: 0.958255\n",
      "batch 1579: loss 0.059854 accuracy: 0.958266\n",
      "batch 1580: loss 0.031377 accuracy: 0.958286\n",
      "batch 1581: loss 0.066565 accuracy: 0.958303\n",
      "batch 1582: loss 0.087463 accuracy: 0.958317\n",
      "batch 1583: loss 0.075136 accuracy: 0.958324\n",
      "batch 1584: loss 0.051572 accuracy: 0.958334\n",
      "batch 1585: loss 0.053384 accuracy: 0.958351\n",
      "batch 1586: loss 0.056460 accuracy: 0.958368\n",
      "batch 1587: loss 0.028294 accuracy: 0.958391\n",
      "batch 1588: loss 0.089984 accuracy: 0.958402\n",
      "batch 1589: loss 0.046730 accuracy: 0.958415\n",
      "batch 1590: loss 0.041522 accuracy: 0.958435\n",
      "batch 1591: loss 0.066066 accuracy: 0.958445\n",
      "batch 1592: loss 0.055529 accuracy: 0.958462\n",
      "batch 1593: loss 0.055394 accuracy: 0.958482\n",
      "batch 1594: loss 0.041564 accuracy: 0.958502\n",
      "batch 1595: loss 0.057018 accuracy: 0.958518\n",
      "batch 1596: loss 0.077027 accuracy: 0.958532\n",
      "batch 1597: loss 0.036931 accuracy: 0.958558\n",
      "batch 1598: loss 0.072389 accuracy: 0.958574\n",
      "batch 1599: loss 0.026550 accuracy: 0.958597\n",
      "batch 1600: loss 0.075437 accuracy: 0.958610\n",
      "model saved to ./save\\ckpt-1600\n",
      "batch 1601: loss 0.090219 accuracy: 0.958617\n",
      "batch 1602: loss 0.052898 accuracy: 0.958637\n",
      "batch 1603: loss 0.027893 accuracy: 0.958663\n",
      "batch 1604: loss 0.079279 accuracy: 0.958673\n",
      "batch 1605: loss 0.063915 accuracy: 0.958686\n",
      "batch 1606: loss 0.037132 accuracy: 0.958709\n",
      "batch 1607: loss 0.096208 accuracy: 0.958725\n",
      "batch 1608: loss 0.032504 accuracy: 0.958748\n",
      "batch 1609: loss 0.066132 accuracy: 0.958758\n",
      "batch 1610: loss 0.050144 accuracy: 0.958774\n",
      "batch 1611: loss 0.061501 accuracy: 0.958790\n",
      "batch 1612: loss 0.086728 accuracy: 0.958794\n",
      "batch 1613: loss 0.076011 accuracy: 0.958801\n",
      "batch 1614: loss 0.076366 accuracy: 0.958814\n",
      "batch 1615: loss 0.043052 accuracy: 0.958830\n",
      "batch 1616: loss 0.067933 accuracy: 0.958844\n",
      "batch 1617: loss 0.031123 accuracy: 0.958863\n",
      "batch 1618: loss 0.062804 accuracy: 0.958876\n",
      "batch 1619: loss 0.053233 accuracy: 0.958889\n",
      "batch 1620: loss 0.046940 accuracy: 0.958911\n",
      "batch 1621: loss 0.081154 accuracy: 0.958921\n",
      "batch 1622: loss 0.100081 accuracy: 0.958934\n",
      "batch 1623: loss 0.046047 accuracy: 0.958950\n",
      "batch 1624: loss 0.060301 accuracy: 0.958966\n",
      "batch 1625: loss 0.029966 accuracy: 0.958988\n",
      "batch 1626: loss 0.043969 accuracy: 0.959004\n",
      "batch 1627: loss 0.039039 accuracy: 0.959029\n",
      "batch 1628: loss 0.036303 accuracy: 0.959049\n",
      "batch 1629: loss 0.068195 accuracy: 0.959058\n",
      "batch 1630: loss 0.080918 accuracy: 0.959062\n",
      "batch 1631: loss 0.031995 accuracy: 0.959087\n",
      "batch 1632: loss 0.040023 accuracy: 0.959106\n",
      "batch 1633: loss 0.031114 accuracy: 0.959128\n",
      "batch 1634: loss 0.037274 accuracy: 0.959147\n",
      "batch 1635: loss 0.032191 accuracy: 0.959169\n",
      "batch 1636: loss 0.035132 accuracy: 0.959194\n",
      "batch 1637: loss 0.045513 accuracy: 0.959209\n",
      "batch 1638: loss 0.084849 accuracy: 0.959216\n",
      "batch 1639: loss 0.037169 accuracy: 0.959232\n",
      "batch 1640: loss 0.063053 accuracy: 0.959244\n",
      "batch 1641: loss 0.047152 accuracy: 0.959263\n",
      "batch 1642: loss 0.035406 accuracy: 0.959285\n",
      "batch 1643: loss 0.020006 accuracy: 0.959307\n",
      "batch 1644: loss 0.056272 accuracy: 0.959319\n",
      "batch 1645: loss 0.045418 accuracy: 0.959335\n",
      "batch 1646: loss 0.059820 accuracy: 0.959347\n",
      "batch 1647: loss 0.057231 accuracy: 0.959360\n",
      "batch 1648: loss 0.077454 accuracy: 0.959369\n",
      "batch 1649: loss 0.030270 accuracy: 0.959391\n",
      "batch 1650: loss 0.040372 accuracy: 0.959409\n",
      "batch 1651: loss 0.065135 accuracy: 0.959428\n",
      "batch 1652: loss 0.032339 accuracy: 0.959446\n",
      "batch 1653: loss 0.054020 accuracy: 0.959462\n",
      "batch 1654: loss 0.075236 accuracy: 0.959474\n",
      "batch 1655: loss 0.034002 accuracy: 0.959493\n",
      "batch 1656: loss 0.048205 accuracy: 0.959505\n",
      "batch 1657: loss 0.045232 accuracy: 0.959521\n",
      "batch 1658: loss 0.080066 accuracy: 0.959536\n",
      "batch 1659: loss 0.036133 accuracy: 0.959557\n",
      "batch 1660: loss 0.080274 accuracy: 0.959567\n",
      "batch 1661: loss 0.072298 accuracy: 0.959582\n",
      "batch 1662: loss 0.069090 accuracy: 0.959588\n",
      "batch 1663: loss 0.036699 accuracy: 0.959606\n",
      "batch 1664: loss 0.020389 accuracy: 0.959628\n",
      "batch 1665: loss 0.032635 accuracy: 0.959646\n",
      "batch 1666: loss 0.059245 accuracy: 0.959664\n",
      "batch 1667: loss 0.044436 accuracy: 0.959679\n",
      "batch 1668: loss 0.065680 accuracy: 0.959691\n",
      "batch 1669: loss 0.030697 accuracy: 0.959710\n",
      "batch 1670: loss 0.068441 accuracy: 0.959725\n",
      "batch 1671: loss 0.034320 accuracy: 0.959743\n",
      "batch 1672: loss 0.064084 accuracy: 0.959752\n",
      "batch 1673: loss 0.037106 accuracy: 0.959773\n",
      "batch 1674: loss 0.040362 accuracy: 0.959791\n",
      "batch 1675: loss 0.054464 accuracy: 0.959800\n",
      "batch 1676: loss 0.029209 accuracy: 0.959821\n",
      "batch 1677: loss 0.069155 accuracy: 0.959830\n",
      "batch 1678: loss 0.051341 accuracy: 0.959839\n",
      "batch 1679: loss 0.036472 accuracy: 0.959860\n",
      "batch 1680: loss 0.138719 accuracy: 0.959872\n",
      "batch 1681: loss 0.071602 accuracy: 0.959881\n",
      "batch 1682: loss 0.063013 accuracy: 0.959890\n",
      "batch 1683: loss 0.067360 accuracy: 0.959905\n",
      "batch 1684: loss 0.044238 accuracy: 0.959920\n",
      "batch 1685: loss 0.047072 accuracy: 0.959935\n",
      "batch 1686: loss 0.045404 accuracy: 0.959953\n",
      "batch 1687: loss 0.066720 accuracy: 0.959967\n",
      "batch 1688: loss 0.041215 accuracy: 0.959985\n",
      "batch 1689: loss 0.033753 accuracy: 0.960000\n",
      "batch 1690: loss 0.049016 accuracy: 0.960021\n",
      "batch 1691: loss 0.047845 accuracy: 0.960035\n",
      "batch 1692: loss 0.041978 accuracy: 0.960053\n",
      "batch 1693: loss 0.136279 accuracy: 0.960056\n",
      "batch 1694: loss 0.101285 accuracy: 0.960065\n",
      "batch 1695: loss 0.019056 accuracy: 0.960088\n",
      "batch 1696: loss 0.083461 accuracy: 0.960094\n",
      "batch 1697: loss 0.070154 accuracy: 0.960112\n",
      "batch 1698: loss 0.034699 accuracy: 0.960132\n",
      "batch 1699: loss 0.014357 accuracy: 0.960156\n",
      "batch 1700: loss 0.049069 accuracy: 0.960168\n",
      "model saved to ./save\\ckpt-1700\n",
      "batch 1701: loss 0.032321 accuracy: 0.960185\n",
      "batch 1702: loss 0.041169 accuracy: 0.960205\n",
      "batch 1703: loss 0.094444 accuracy: 0.960208\n",
      "batch 1704: loss 0.045224 accuracy: 0.960223\n",
      "batch 1705: loss 0.075429 accuracy: 0.960234\n",
      "batch 1706: loss 0.061413 accuracy: 0.960246\n",
      "batch 1707: loss 0.034325 accuracy: 0.960263\n",
      "batch 1708: loss 0.033515 accuracy: 0.960287\n",
      "batch 1709: loss 0.069507 accuracy: 0.960298\n",
      "batch 1710: loss 0.084576 accuracy: 0.960304\n",
      "batch 1711: loss 0.046413 accuracy: 0.960318\n",
      "batch 1712: loss 0.071645 accuracy: 0.960324\n",
      "batch 1713: loss 0.042215 accuracy: 0.960341\n",
      "batch 1714: loss 0.080242 accuracy: 0.960350\n",
      "batch 1715: loss 0.049940 accuracy: 0.960364\n",
      "batch 1716: loss 0.072185 accuracy: 0.960367\n",
      "batch 1717: loss 0.061293 accuracy: 0.960381\n",
      "batch 1718: loss 0.027424 accuracy: 0.960398\n",
      "batch 1719: loss 0.047922 accuracy: 0.960410\n",
      "batch 1720: loss 0.054696 accuracy: 0.960421\n",
      "batch 1721: loss 0.033331 accuracy: 0.960438\n",
      "batch 1722: loss 0.036704 accuracy: 0.960456\n",
      "batch 1723: loss 0.053025 accuracy: 0.960470\n",
      "batch 1724: loss 0.079624 accuracy: 0.960481\n",
      "batch 1725: loss 0.078592 accuracy: 0.960490\n",
      "batch 1726: loss 0.019680 accuracy: 0.960512\n",
      "batch 1727: loss 0.049374 accuracy: 0.960527\n",
      "batch 1728: loss 0.034985 accuracy: 0.960547\n",
      "batch 1729: loss 0.025581 accuracy: 0.960566\n",
      "batch 1730: loss 0.069944 accuracy: 0.960575\n",
      "batch 1731: loss 0.042406 accuracy: 0.960592\n",
      "batch 1732: loss 0.026438 accuracy: 0.960612\n",
      "batch 1733: loss 0.042573 accuracy: 0.960623\n",
      "batch 1734: loss 0.040185 accuracy: 0.960640\n",
      "batch 1735: loss 0.042891 accuracy: 0.960660\n",
      "batch 1736: loss 0.044171 accuracy: 0.960676\n",
      "batch 1737: loss 0.051787 accuracy: 0.960690\n",
      "batch 1738: loss 0.051410 accuracy: 0.960704\n",
      "batch 1739: loss 0.074376 accuracy: 0.960716\n",
      "batch 1740: loss 0.031175 accuracy: 0.960735\n",
      "batch 1741: loss 0.119564 accuracy: 0.960738\n",
      "batch 1742: loss 0.061692 accuracy: 0.960746\n",
      "batch 1743: loss 0.114284 accuracy: 0.960751\n",
      "batch 1744: loss 0.047335 accuracy: 0.960768\n",
      "batch 1745: loss 0.034389 accuracy: 0.960782\n",
      "batch 1746: loss 0.069006 accuracy: 0.960793\n",
      "batch 1747: loss 0.067094 accuracy: 0.960801\n",
      "batch 1748: loss 0.092758 accuracy: 0.960809\n",
      "batch 1749: loss 0.048334 accuracy: 0.960826\n",
      "batch 1750: loss 0.068195 accuracy: 0.960840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1751: loss 0.049230 accuracy: 0.960856\n",
      "batch 1752: loss 0.038610 accuracy: 0.960873\n",
      "batch 1753: loss 0.114798 accuracy: 0.960887\n",
      "batch 1754: loss 0.087099 accuracy: 0.960897\n",
      "batch 1755: loss 0.037213 accuracy: 0.960911\n",
      "batch 1756: loss 0.021535 accuracy: 0.960931\n",
      "batch 1757: loss 0.036631 accuracy: 0.960950\n",
      "batch 1758: loss 0.051058 accuracy: 0.960966\n",
      "batch 1759: loss 0.065499 accuracy: 0.960977\n",
      "batch 1760: loss 0.053380 accuracy: 0.960988\n",
      "batch 1761: loss 0.043286 accuracy: 0.961005\n",
      "batch 1762: loss 0.041582 accuracy: 0.961021\n",
      "batch 1763: loss 0.058101 accuracy: 0.961035\n",
      "batch 1764: loss 0.047237 accuracy: 0.961051\n",
      "batch 1765: loss 0.028175 accuracy: 0.961070\n",
      "batch 1766: loss 0.095352 accuracy: 0.961081\n",
      "batch 1767: loss 0.059824 accuracy: 0.961094\n",
      "batch 1768: loss 0.026286 accuracy: 0.961114\n",
      "batch 1769: loss 0.080974 accuracy: 0.961127\n",
      "batch 1770: loss 0.088454 accuracy: 0.961135\n",
      "batch 1771: loss 0.051008 accuracy: 0.961146\n",
      "batch 1772: loss 0.028186 accuracy: 0.961165\n",
      "batch 1773: loss 0.033350 accuracy: 0.961187\n",
      "batch 1774: loss 0.064497 accuracy: 0.961200\n",
      "batch 1775: loss 0.043325 accuracy: 0.961211\n",
      "batch 1776: loss 0.052509 accuracy: 0.961221\n",
      "batch 1777: loss 0.043004 accuracy: 0.961235\n",
      "batch 1778: loss 0.060536 accuracy: 0.961251\n",
      "batch 1779: loss 0.034587 accuracy: 0.961270\n",
      "batch 1780: loss 0.069107 accuracy: 0.961275\n",
      "batch 1781: loss 0.065855 accuracy: 0.961279\n",
      "batch 1782: loss 0.032640 accuracy: 0.961298\n",
      "batch 1783: loss 0.042872 accuracy: 0.961314\n",
      "batch 1784: loss 0.053411 accuracy: 0.961325\n",
      "batch 1785: loss 0.041606 accuracy: 0.961344\n",
      "batch 1786: loss 0.035438 accuracy: 0.961363\n",
      "batch 1787: loss 0.033711 accuracy: 0.961381\n",
      "batch 1788: loss 0.028973 accuracy: 0.961400\n",
      "batch 1789: loss 0.087109 accuracy: 0.961408\n",
      "batch 1790: loss 0.033538 accuracy: 0.961427\n",
      "batch 1791: loss 0.035573 accuracy: 0.961443\n",
      "batch 1792: loss 0.078040 accuracy: 0.961458\n",
      "batch 1793: loss 0.018615 accuracy: 0.961480\n",
      "batch 1794: loss 0.048219 accuracy: 0.961493\n",
      "batch 1795: loss 0.035553 accuracy: 0.961512\n",
      "batch 1796: loss 0.067603 accuracy: 0.961522\n",
      "batch 1797: loss 0.050898 accuracy: 0.961535\n",
      "batch 1798: loss 0.051055 accuracy: 0.961545\n",
      "batch 1799: loss 0.058324 accuracy: 0.961553\n",
      "batch 1800: loss 0.039902 accuracy: 0.961569\n",
      "model saved to ./save\\ckpt-1800\n",
      "batch 1801: loss 0.068152 accuracy: 0.961579\n",
      "batch 1802: loss 0.070109 accuracy: 0.961586\n",
      "batch 1803: loss 0.022544 accuracy: 0.961608\n",
      "batch 1804: loss 0.031510 accuracy: 0.961621\n",
      "batch 1805: loss 0.079301 accuracy: 0.961633\n",
      "batch 1806: loss 0.041125 accuracy: 0.961649\n",
      "batch 1807: loss 0.042216 accuracy: 0.961665\n",
      "batch 1808: loss 0.038763 accuracy: 0.961683\n",
      "batch 1809: loss 0.059257 accuracy: 0.961696\n",
      "batch 1810: loss 0.028688 accuracy: 0.961712\n",
      "batch 1811: loss 0.073135 accuracy: 0.961716\n",
      "batch 1812: loss 0.031478 accuracy: 0.961732\n",
      "batch 1813: loss 0.047402 accuracy: 0.961748\n",
      "batch 1814: loss 0.038748 accuracy: 0.961758\n",
      "batch 1815: loss 0.044744 accuracy: 0.961773\n",
      "batch 1816: loss 0.025174 accuracy: 0.961791\n",
      "batch 1817: loss 0.057560 accuracy: 0.961804\n",
      "batch 1818: loss 0.033324 accuracy: 0.961822\n",
      "batch 1819: loss 0.023109 accuracy: 0.961841\n",
      "batch 1820: loss 0.051109 accuracy: 0.961856\n",
      "batch 1821: loss 0.029672 accuracy: 0.961874\n",
      "batch 1822: loss 0.042963 accuracy: 0.961890\n",
      "batch 1823: loss 0.059405 accuracy: 0.961900\n",
      "batch 1824: loss 0.100442 accuracy: 0.961907\n",
      "batch 1825: loss 0.020460 accuracy: 0.961928\n",
      "batch 1826: loss 0.062269 accuracy: 0.961935\n",
      "batch 1827: loss 0.028310 accuracy: 0.961953\n",
      "batch 1828: loss 0.036427 accuracy: 0.961966\n",
      "batch 1829: loss 0.067768 accuracy: 0.961975\n",
      "batch 1830: loss 0.028459 accuracy: 0.961993\n",
      "batch 1831: loss 0.044741 accuracy: 0.962009\n",
      "batch 1832: loss 0.045809 accuracy: 0.962024\n",
      "batch 1833: loss 0.046812 accuracy: 0.962039\n",
      "batch 1834: loss 0.046404 accuracy: 0.962052\n",
      "batch 1835: loss 0.020612 accuracy: 0.962072\n",
      "batch 1836: loss 0.055920 accuracy: 0.962085\n",
      "batch 1837: loss 0.044331 accuracy: 0.962097\n",
      "batch 1838: loss 0.037879 accuracy: 0.962115\n",
      "batch 1839: loss 0.025486 accuracy: 0.962133\n",
      "batch 1840: loss 0.086045 accuracy: 0.962148\n",
      "batch 1841: loss 0.040847 accuracy: 0.962158\n",
      "batch 1842: loss 0.086334 accuracy: 0.962168\n",
      "batch 1843: loss 0.045567 accuracy: 0.962185\n",
      "batch 1844: loss 0.036943 accuracy: 0.962201\n",
      "batch 1845: loss 0.104920 accuracy: 0.962205\n",
      "batch 1846: loss 0.048714 accuracy: 0.962214\n",
      "batch 1847: loss 0.026944 accuracy: 0.962229\n",
      "batch 1848: loss 0.039785 accuracy: 0.962244\n",
      "batch 1849: loss 0.042843 accuracy: 0.962262\n",
      "batch 1850: loss 0.088160 accuracy: 0.962269\n",
      "batch 1851: loss 0.071618 accuracy: 0.962273\n",
      "batch 1852: loss 0.032173 accuracy: 0.962291\n",
      "batch 1853: loss 0.057570 accuracy: 0.962303\n",
      "batch 1854: loss 0.043634 accuracy: 0.962318\n",
      "batch 1855: loss 0.053814 accuracy: 0.962333\n",
      "batch 1856: loss 0.056817 accuracy: 0.962340\n",
      "batch 1857: loss 0.111272 accuracy: 0.962341\n",
      "batch 1858: loss 0.043583 accuracy: 0.962356\n",
      "batch 1859: loss 0.036225 accuracy: 0.962371\n",
      "batch 1860: loss 0.052469 accuracy: 0.962383\n",
      "batch 1861: loss 0.070489 accuracy: 0.962393\n",
      "batch 1862: loss 0.038690 accuracy: 0.962413\n",
      "batch 1863: loss 0.047234 accuracy: 0.962428\n",
      "batch 1864: loss 0.025140 accuracy: 0.962442\n",
      "batch 1865: loss 0.059559 accuracy: 0.962454\n",
      "batch 1866: loss 0.079583 accuracy: 0.962464\n",
      "batch 1867: loss 0.033060 accuracy: 0.962479\n",
      "batch 1868: loss 0.058377 accuracy: 0.962491\n",
      "batch 1869: loss 0.023561 accuracy: 0.962508\n",
      "batch 1870: loss 0.084248 accuracy: 0.962509\n",
      "batch 1871: loss 0.098631 accuracy: 0.962519\n",
      "batch 1872: loss 0.059808 accuracy: 0.962536\n",
      "batch 1873: loss 0.097551 accuracy: 0.962545\n",
      "batch 1874: loss 0.048290 accuracy: 0.962560\n",
      "batch 1875: loss 0.037813 accuracy: 0.962577\n",
      "batch 1876: loss 0.063285 accuracy: 0.962584\n",
      "batch 1877: loss 0.053025 accuracy: 0.962601\n",
      "batch 1878: loss 0.076618 accuracy: 0.962610\n",
      "batch 1879: loss 0.047931 accuracy: 0.962617\n",
      "batch 1880: loss 0.018564 accuracy: 0.962637\n",
      "batch 1881: loss 0.053653 accuracy: 0.962651\n",
      "batch 1882: loss 0.034456 accuracy: 0.962669\n",
      "batch 1883: loss 0.041849 accuracy: 0.962683\n",
      "batch 1884: loss 0.043026 accuracy: 0.962695\n",
      "batch 1885: loss 0.025295 accuracy: 0.962712\n",
      "batch 1886: loss 0.046283 accuracy: 0.962724\n",
      "batch 1887: loss 0.057509 accuracy: 0.962736\n",
      "batch 1888: loss 0.041921 accuracy: 0.962748\n",
      "batch 1889: loss 0.044540 accuracy: 0.962765\n",
      "batch 1890: loss 0.050649 accuracy: 0.962779\n",
      "batch 1891: loss 0.055858 accuracy: 0.962788\n",
      "batch 1892: loss 0.047129 accuracy: 0.962800\n",
      "batch 1893: loss 0.050656 accuracy: 0.962812\n",
      "batch 1894: loss 0.021202 accuracy: 0.962831\n",
      "batch 1895: loss 0.044693 accuracy: 0.962845\n",
      "batch 1896: loss 0.043901 accuracy: 0.962862\n",
      "batch 1897: loss 0.026935 accuracy: 0.962879\n",
      "batch 1898: loss 0.046493 accuracy: 0.962891\n",
      "batch 1899: loss 0.038117 accuracy: 0.962903\n",
      "batch 1900: loss 0.025287 accuracy: 0.962922\n",
      "model saved to ./save\\ckpt-1900\n",
      "batch 1901: loss 0.043390 accuracy: 0.962936\n",
      "batch 1902: loss 0.033503 accuracy: 0.962953\n",
      "batch 1903: loss 0.069674 accuracy: 0.962962\n",
      "batch 1904: loss 0.036985 accuracy: 0.962976\n",
      "batch 1905: loss 0.025078 accuracy: 0.962993\n",
      "batch 1906: loss 0.048287 accuracy: 0.963007\n",
      "batch 1907: loss 0.042350 accuracy: 0.963016\n",
      "batch 1908: loss 0.053455 accuracy: 0.963023\n",
      "batch 1909: loss 0.044090 accuracy: 0.963031\n",
      "batch 1910: loss 0.045757 accuracy: 0.963046\n",
      "batch 1911: loss 0.034362 accuracy: 0.963062\n",
      "batch 1912: loss 0.059741 accuracy: 0.963068\n",
      "batch 1913: loss 0.050576 accuracy: 0.963080\n",
      "batch 1914: loss 0.025175 accuracy: 0.963097\n",
      "batch 1915: loss 0.036673 accuracy: 0.963113\n",
      "batch 1916: loss 0.038239 accuracy: 0.963130\n",
      "batch 1917: loss 0.046869 accuracy: 0.963141\n",
      "batch 1918: loss 0.038145 accuracy: 0.963153\n",
      "batch 1919: loss 0.037010 accuracy: 0.963164\n",
      "batch 1920: loss 0.036457 accuracy: 0.963178\n",
      "batch 1921: loss 0.046600 accuracy: 0.963195\n",
      "batch 1922: loss 0.033249 accuracy: 0.963209\n",
      "batch 1923: loss 0.047425 accuracy: 0.963220\n",
      "batch 1924: loss 0.042714 accuracy: 0.963234\n",
      "batch 1925: loss 0.040852 accuracy: 0.963245\n",
      "batch 1926: loss 0.058266 accuracy: 0.963256\n",
      "batch 1927: loss 0.023970 accuracy: 0.963273\n",
      "batch 1928: loss 0.077505 accuracy: 0.963284\n",
      "batch 1929: loss 0.056841 accuracy: 0.963298\n",
      "batch 1930: loss 0.039622 accuracy: 0.963312\n",
      "batch 1931: loss 0.051610 accuracy: 0.963326\n",
      "batch 1932: loss 0.054468 accuracy: 0.963334\n",
      "batch 1933: loss 0.029959 accuracy: 0.963348\n",
      "batch 1934: loss 0.053975 accuracy: 0.963359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1935: loss 0.026678 accuracy: 0.963376\n",
      "batch 1936: loss 0.075272 accuracy: 0.963384\n",
      "batch 1937: loss 0.046909 accuracy: 0.963395\n",
      "batch 1938: loss 0.065484 accuracy: 0.963401\n",
      "batch 1939: loss 0.029055 accuracy: 0.963415\n",
      "batch 1940: loss 0.013918 accuracy: 0.963434\n",
      "batch 1941: loss 0.037416 accuracy: 0.963445\n",
      "batch 1942: loss 0.055036 accuracy: 0.963459\n",
      "batch 1943: loss 0.067672 accuracy: 0.963464\n",
      "batch 1944: loss 0.046524 accuracy: 0.963478\n",
      "batch 1945: loss 0.073560 accuracy: 0.963484\n",
      "batch 1946: loss 0.088080 accuracy: 0.963495\n",
      "batch 1947: loss 0.044777 accuracy: 0.963506\n",
      "batch 1948: loss 0.047389 accuracy: 0.963520\n",
      "batch 1949: loss 0.024135 accuracy: 0.963536\n",
      "batch 1950: loss 0.028923 accuracy: 0.963552\n",
      "batch 1951: loss 0.042710 accuracy: 0.963566\n",
      "batch 1952: loss 0.047341 accuracy: 0.963579\n",
      "batch 1953: loss 0.060371 accuracy: 0.963588\n",
      "batch 1954: loss 0.061292 accuracy: 0.963591\n",
      "batch 1955: loss 0.037762 accuracy: 0.963602\n",
      "batch 1956: loss 0.046884 accuracy: 0.963613\n",
      "batch 1957: loss 0.048138 accuracy: 0.963621\n",
      "batch 1958: loss 0.029298 accuracy: 0.963634\n",
      "batch 1959: loss 0.082164 accuracy: 0.963638\n",
      "batch 1960: loss 0.037191 accuracy: 0.963654\n",
      "batch 1961: loss 0.114911 accuracy: 0.963652\n",
      "batch 1962: loss 0.019064 accuracy: 0.963668\n",
      "batch 1963: loss 0.030751 accuracy: 0.963681\n",
      "batch 1964: loss 0.018963 accuracy: 0.963697\n",
      "batch 1965: loss 0.051881 accuracy: 0.963708\n",
      "batch 1966: loss 0.031931 accuracy: 0.963721\n",
      "batch 1967: loss 0.024883 accuracy: 0.963737\n",
      "batch 1968: loss 0.050722 accuracy: 0.963746\n",
      "batch 1969: loss 0.024333 accuracy: 0.963761\n",
      "batch 1970: loss 0.052894 accuracy: 0.963772\n",
      "batch 1971: loss 0.049341 accuracy: 0.963783\n",
      "batch 1972: loss 0.044103 accuracy: 0.963794\n",
      "batch 1973: loss 0.027496 accuracy: 0.963810\n",
      "batch 1974: loss 0.039701 accuracy: 0.963823\n",
      "batch 1975: loss 0.031173 accuracy: 0.963839\n",
      "batch 1976: loss 0.046916 accuracy: 0.963852\n",
      "batch 1977: loss 0.044339 accuracy: 0.963865\n",
      "batch 1978: loss 0.019667 accuracy: 0.963883\n",
      "batch 1979: loss 0.067911 accuracy: 0.963891\n",
      "batch 1980: loss 0.025585 accuracy: 0.963910\n",
      "batch 1981: loss 0.052652 accuracy: 0.963923\n",
      "batch 1982: loss 0.052477 accuracy: 0.963936\n",
      "batch 1983: loss 0.052210 accuracy: 0.963949\n",
      "batch 1984: loss 0.018993 accuracy: 0.963967\n",
      "batch 1985: loss 0.035439 accuracy: 0.963983\n",
      "batch 1986: loss 0.023220 accuracy: 0.963998\n",
      "batch 1987: loss 0.018448 accuracy: 0.964017\n",
      "batch 1988: loss 0.058739 accuracy: 0.964030\n",
      "batch 1989: loss 0.015292 accuracy: 0.964048\n",
      "batch 1990: loss 0.050752 accuracy: 0.964058\n",
      "batch 1991: loss 0.044153 accuracy: 0.964074\n",
      "batch 1992: loss 0.048070 accuracy: 0.964082\n",
      "batch 1993: loss 0.028303 accuracy: 0.964097\n",
      "batch 1994: loss 0.034725 accuracy: 0.964113\n",
      "batch 1995: loss 0.051777 accuracy: 0.964123\n",
      "batch 1996: loss 0.022855 accuracy: 0.964141\n",
      "batch 1997: loss 0.034195 accuracy: 0.964154\n",
      "batch 1998: loss 0.024069 accuracy: 0.964170\n",
      "batch 1999: loss 0.039186 accuracy: 0.964185\n",
      "batch 2000: loss 0.046710 accuracy: 0.964195\n",
      "model saved to ./save\\ckpt-2000\n",
      "batch 2001: loss 0.029129 accuracy: 0.964211\n",
      "batch 2002: loss 0.056413 accuracy: 0.964219\n",
      "batch 2003: loss 0.046721 accuracy: 0.964232\n",
      "batch 2004: loss 0.019615 accuracy: 0.964247\n",
      "batch 2005: loss 0.058841 accuracy: 0.964257\n",
      "batch 2006: loss 0.096375 accuracy: 0.964260\n",
      "batch 2007: loss 0.033278 accuracy: 0.964270\n",
      "batch 2008: loss 0.032057 accuracy: 0.964286\n",
      "batch 2009: loss 0.028956 accuracy: 0.964298\n",
      "batch 2010: loss 0.053552 accuracy: 0.964311\n",
      "batch 2011: loss 0.047234 accuracy: 0.964324\n",
      "batch 2012: loss 0.025111 accuracy: 0.964339\n",
      "batch 2013: loss 0.033626 accuracy: 0.964355\n",
      "batch 2014: loss 0.061025 accuracy: 0.964367\n",
      "batch 2015: loss 0.027566 accuracy: 0.964382\n",
      "batch 2016: loss 0.047074 accuracy: 0.964393\n",
      "batch 2017: loss 0.046087 accuracy: 0.964400\n",
      "batch 2018: loss 0.038066 accuracy: 0.964416\n",
      "batch 2019: loss 0.065956 accuracy: 0.964426\n",
      "batch 2020: loss 0.028267 accuracy: 0.964441\n",
      "batch 2021: loss 0.055303 accuracy: 0.964451\n",
      "batch 2022: loss 0.066701 accuracy: 0.964459\n",
      "batch 2023: loss 0.027263 accuracy: 0.964474\n",
      "batch 2024: loss 0.046713 accuracy: 0.964486\n",
      "batch 2025: loss 0.035466 accuracy: 0.964497\n",
      "batch 2026: loss 0.070717 accuracy: 0.964499\n",
      "batch 2027: loss 0.050282 accuracy: 0.964507\n",
      "batch 2028: loss 0.035700 accuracy: 0.964519\n",
      "batch 2029: loss 0.055132 accuracy: 0.964527\n",
      "batch 2030: loss 0.040486 accuracy: 0.964540\n",
      "batch 2031: loss 0.044154 accuracy: 0.964550\n",
      "batch 2032: loss 0.054923 accuracy: 0.964562\n",
      "batch 2033: loss 0.044127 accuracy: 0.964575\n",
      "batch 2034: loss 0.043684 accuracy: 0.964585\n",
      "batch 2035: loss 0.055681 accuracy: 0.964592\n",
      "batch 2036: loss 0.073449 accuracy: 0.964595\n",
      "batch 2037: loss 0.023278 accuracy: 0.964610\n",
      "batch 2038: loss 0.026806 accuracy: 0.964627\n",
      "batch 2039: loss 0.042631 accuracy: 0.964635\n",
      "batch 2040: loss 0.035734 accuracy: 0.964647\n",
      "batch 2041: loss 0.062631 accuracy: 0.964655\n",
      "batch 2042: loss 0.081269 accuracy: 0.964662\n",
      "batch 2043: loss 0.029047 accuracy: 0.964675\n",
      "batch 2044: loss 0.024695 accuracy: 0.964692\n",
      "batch 2045: loss 0.038409 accuracy: 0.964699\n",
      "batch 2046: loss 0.018089 accuracy: 0.964714\n",
      "batch 2047: loss 0.123834 accuracy: 0.964714\n",
      "batch 2048: loss 0.033108 accuracy: 0.964727\n",
      "batch 2049: loss 0.020817 accuracy: 0.964741\n",
      "batch 2050: loss 0.044525 accuracy: 0.964754\n",
      "batch 2051: loss 0.053323 accuracy: 0.964764\n",
      "batch 2052: loss 0.036747 accuracy: 0.964778\n",
      "batch 2053: loss 0.051229 accuracy: 0.964788\n",
      "batch 2054: loss 0.048989 accuracy: 0.964796\n",
      "batch 2055: loss 0.026854 accuracy: 0.964805\n",
      "batch 2056: loss 0.031442 accuracy: 0.964818\n",
      "batch 2057: loss 0.039928 accuracy: 0.964832\n",
      "batch 2058: loss 0.059190 accuracy: 0.964842\n",
      "batch 2059: loss 0.028927 accuracy: 0.964854\n",
      "batch 2060: loss 0.055206 accuracy: 0.964864\n",
      "batch 2061: loss 0.035244 accuracy: 0.964876\n",
      "batch 2062: loss 0.025597 accuracy: 0.964891\n",
      "batch 2063: loss 0.064621 accuracy: 0.964906\n",
      "batch 2064: loss 0.041820 accuracy: 0.964918\n",
      "batch 2065: loss 0.041469 accuracy: 0.964930\n",
      "batch 2066: loss 0.024350 accuracy: 0.964947\n",
      "batch 2067: loss 0.043012 accuracy: 0.964954\n",
      "batch 2068: loss 0.033038 accuracy: 0.964964\n",
      "batch 2069: loss 0.057500 accuracy: 0.964976\n",
      "batch 2070: loss 0.031491 accuracy: 0.964985\n",
      "batch 2071: loss 0.027664 accuracy: 0.964998\n",
      "batch 2072: loss 0.019845 accuracy: 0.965014\n",
      "batch 2073: loss 0.068039 accuracy: 0.965017\n",
      "batch 2074: loss 0.091171 accuracy: 0.965014\n",
      "batch 2075: loss 0.024253 accuracy: 0.965026\n",
      "batch 2076: loss 0.030105 accuracy: 0.965036\n",
      "batch 2077: loss 0.026723 accuracy: 0.965048\n",
      "batch 2078: loss 0.057871 accuracy: 0.965055\n",
      "batch 2079: loss 0.103534 accuracy: 0.965062\n",
      "batch 2080: loss 0.039525 accuracy: 0.965072\n",
      "batch 2081: loss 0.026763 accuracy: 0.965086\n",
      "batch 2082: loss 0.038183 accuracy: 0.965101\n",
      "batch 2083: loss 0.040546 accuracy: 0.965113\n",
      "batch 2084: loss 0.054215 accuracy: 0.965122\n",
      "batch 2085: loss 0.023172 accuracy: 0.965134\n",
      "batch 2086: loss 0.035817 accuracy: 0.965149\n",
      "batch 2087: loss 0.021332 accuracy: 0.965165\n",
      "batch 2088: loss 0.026019 accuracy: 0.965177\n",
      "batch 2089: loss 0.020404 accuracy: 0.965191\n",
      "batch 2090: loss 0.026003 accuracy: 0.965206\n",
      "batch 2091: loss 0.045526 accuracy: 0.965217\n",
      "batch 2092: loss 0.067293 accuracy: 0.965225\n",
      "batch 2093: loss 0.050204 accuracy: 0.965236\n",
      "batch 2094: loss 0.050931 accuracy: 0.965241\n",
      "batch 2095: loss 0.032884 accuracy: 0.965255\n",
      "batch 2096: loss 0.044355 accuracy: 0.965265\n",
      "batch 2097: loss 0.020179 accuracy: 0.965281\n",
      "batch 2098: loss 0.033619 accuracy: 0.965295\n",
      "batch 2099: loss 0.026795 accuracy: 0.965310\n",
      "batch 2100: loss 0.019706 accuracy: 0.965326\n",
      "model saved to ./save\\ckpt-2100\n",
      "batch 2101: loss 0.044527 accuracy: 0.965335\n",
      "batch 2102: loss 0.059836 accuracy: 0.965338\n",
      "batch 2103: loss 0.043360 accuracy: 0.965347\n",
      "batch 2104: loss 0.023633 accuracy: 0.965361\n",
      "batch 2105: loss 0.047159 accuracy: 0.965368\n",
      "batch 2106: loss 0.020083 accuracy: 0.965380\n",
      "batch 2107: loss 0.029277 accuracy: 0.965391\n",
      "batch 2108: loss 0.036419 accuracy: 0.965401\n",
      "batch 2109: loss 0.074668 accuracy: 0.965412\n",
      "batch 2110: loss 0.060061 accuracy: 0.965422\n",
      "batch 2111: loss 0.055100 accuracy: 0.965429\n",
      "batch 2112: loss 0.090764 accuracy: 0.965426\n",
      "batch 2113: loss 0.077997 accuracy: 0.965430\n",
      "batch 2114: loss 0.079288 accuracy: 0.965440\n",
      "batch 2115: loss 0.053972 accuracy: 0.965447\n",
      "batch 2116: loss 0.039245 accuracy: 0.965458\n",
      "batch 2117: loss 0.025886 accuracy: 0.965472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2118: loss 0.036139 accuracy: 0.965481\n",
      "batch 2119: loss 0.063113 accuracy: 0.965486\n",
      "batch 2120: loss 0.057145 accuracy: 0.965495\n",
      "batch 2121: loss 0.038051 accuracy: 0.965507\n",
      "batch 2122: loss 0.067198 accuracy: 0.965513\n",
      "batch 2123: loss 0.055322 accuracy: 0.965525\n",
      "batch 2124: loss 0.025585 accuracy: 0.965539\n",
      "batch 2125: loss 0.026443 accuracy: 0.965555\n",
      "batch 2126: loss 0.036526 accuracy: 0.965569\n",
      "batch 2127: loss 0.043779 accuracy: 0.965576\n",
      "batch 2128: loss 0.031241 accuracy: 0.965589\n",
      "batch 2129: loss 0.026085 accuracy: 0.965603\n",
      "batch 2130: loss 0.054211 accuracy: 0.965612\n",
      "batch 2131: loss 0.058701 accuracy: 0.965624\n",
      "batch 2132: loss 0.046767 accuracy: 0.965633\n",
      "batch 2133: loss 0.029373 accuracy: 0.965647\n",
      "batch 2134: loss 0.036630 accuracy: 0.965653\n",
      "batch 2135: loss 0.036155 accuracy: 0.965665\n",
      "batch 2136: loss 0.048306 accuracy: 0.965676\n",
      "batch 2137: loss 0.042841 accuracy: 0.965688\n",
      "batch 2138: loss 0.045127 accuracy: 0.965697\n",
      "batch 2139: loss 0.052017 accuracy: 0.965703\n",
      "batch 2140: loss 0.025422 accuracy: 0.965717\n",
      "batch 2141: loss 0.019831 accuracy: 0.965733\n",
      "batch 2142: loss 0.052419 accuracy: 0.965742\n",
      "batch 2143: loss 0.050613 accuracy: 0.965753\n",
      "batch 2144: loss 0.025503 accuracy: 0.965769\n",
      "batch 2145: loss 0.044000 accuracy: 0.965780\n",
      "batch 2146: loss 0.018457 accuracy: 0.965796\n",
      "batch 2147: loss 0.051483 accuracy: 0.965805\n",
      "batch 2148: loss 0.063136 accuracy: 0.965814\n",
      "batch 2149: loss 0.058052 accuracy: 0.965821\n",
      "batch 2150: loss 0.031644 accuracy: 0.965832\n",
      "batch 2151: loss 0.026235 accuracy: 0.965846\n",
      "batch 2152: loss 0.048780 accuracy: 0.965852\n",
      "batch 2153: loss 0.071356 accuracy: 0.965859\n",
      "batch 2154: loss 0.020030 accuracy: 0.965872\n",
      "batch 2155: loss 0.036574 accuracy: 0.965884\n",
      "batch 2156: loss 0.015410 accuracy: 0.965899\n",
      "batch 2157: loss 0.054246 accuracy: 0.965906\n",
      "batch 2158: loss 0.035207 accuracy: 0.965917\n",
      "batch 2159: loss 0.013645 accuracy: 0.965933\n",
      "batch 2160: loss 0.061511 accuracy: 0.965942\n",
      "batch 2161: loss 0.032558 accuracy: 0.965953\n",
      "batch 2162: loss 0.026342 accuracy: 0.965969\n",
      "batch 2163: loss 0.058361 accuracy: 0.965982\n",
      "batch 2164: loss 0.039334 accuracy: 0.965995\n",
      "batch 2165: loss 0.046298 accuracy: 0.966009\n",
      "batch 2166: loss 0.039244 accuracy: 0.966018\n",
      "batch 2167: loss 0.024724 accuracy: 0.966031\n",
      "batch 2168: loss 0.068824 accuracy: 0.966035\n",
      "batch 2169: loss 0.057133 accuracy: 0.966041\n",
      "batch 2170: loss 0.037096 accuracy: 0.966050\n",
      "batch 2171: loss 0.044525 accuracy: 0.966057\n",
      "batch 2172: loss 0.063178 accuracy: 0.966065\n",
      "batch 2173: loss 0.037114 accuracy: 0.966074\n",
      "batch 2174: loss 0.066909 accuracy: 0.966080\n",
      "batch 2175: loss 0.051672 accuracy: 0.966087\n",
      "batch 2176: loss 0.055265 accuracy: 0.966091\n",
      "batch 2177: loss 0.060123 accuracy: 0.966100\n",
      "batch 2178: loss 0.051788 accuracy: 0.966111\n",
      "batch 2179: loss 0.017098 accuracy: 0.966126\n",
      "batch 2180: loss 0.021837 accuracy: 0.966139\n",
      "batch 2181: loss 0.037530 accuracy: 0.966148\n",
      "batch 2182: loss 0.038706 accuracy: 0.966159\n",
      "batch 2183: loss 0.047768 accuracy: 0.966168\n",
      "batch 2184: loss 0.040826 accuracy: 0.966176\n",
      "batch 2185: loss 0.088050 accuracy: 0.966183\n",
      "batch 2186: loss 0.026273 accuracy: 0.966196\n",
      "batch 2187: loss 0.056164 accuracy: 0.966202\n",
      "batch 2188: loss 0.028544 accuracy: 0.966215\n",
      "batch 2189: loss 0.018223 accuracy: 0.966231\n",
      "batch 2190: loss 0.033799 accuracy: 0.966244\n",
      "batch 2191: loss 0.040517 accuracy: 0.966255\n",
      "batch 2192: loss 0.034038 accuracy: 0.966268\n",
      "batch 2193: loss 0.020957 accuracy: 0.966283\n",
      "batch 2194: loss 0.027315 accuracy: 0.966296\n",
      "batch 2195: loss 0.030625 accuracy: 0.966311\n",
      "batch 2196: loss 0.055081 accuracy: 0.966320\n",
      "batch 2197: loss 0.038593 accuracy: 0.966331\n",
      "batch 2198: loss 0.037902 accuracy: 0.966341\n",
      "batch 2199: loss 0.031772 accuracy: 0.966352\n",
      "batch 2200: loss 0.046534 accuracy: 0.966361\n",
      "model saved to ./save\\ckpt-2200\n",
      "batch 2201: loss 0.025979 accuracy: 0.966374\n",
      "batch 2202: loss 0.031898 accuracy: 0.966384\n",
      "batch 2203: loss 0.070449 accuracy: 0.966388\n",
      "batch 2204: loss 0.051081 accuracy: 0.966397\n",
      "batch 2205: loss 0.105866 accuracy: 0.966401\n",
      "batch 2206: loss 0.054738 accuracy: 0.966407\n",
      "batch 2207: loss 0.071442 accuracy: 0.966408\n",
      "batch 2208: loss 0.045363 accuracy: 0.966417\n",
      "batch 2209: loss 0.024055 accuracy: 0.966428\n",
      "batch 2210: loss 0.035912 accuracy: 0.966438\n",
      "batch 2211: loss 0.062770 accuracy: 0.966444\n",
      "batch 2212: loss 0.054712 accuracy: 0.966451\n",
      "batch 2213: loss 0.041656 accuracy: 0.966454\n",
      "batch 2214: loss 0.045303 accuracy: 0.966465\n",
      "batch 2215: loss 0.030047 accuracy: 0.966478\n",
      "batch 2216: loss 0.037565 accuracy: 0.966488\n",
      "batch 2217: loss 0.028373 accuracy: 0.966501\n",
      "batch 2218: loss 0.019831 accuracy: 0.966516\n",
      "batch 2219: loss 0.036897 accuracy: 0.966529\n",
      "batch 2220: loss 0.021537 accuracy: 0.966542\n",
      "batch 2221: loss 0.037862 accuracy: 0.966557\n",
      "batch 2222: loss 0.055861 accuracy: 0.966565\n",
      "batch 2223: loss 0.037638 accuracy: 0.966576\n",
      "batch 2224: loss 0.025210 accuracy: 0.966587\n",
      "batch 2225: loss 0.019651 accuracy: 0.966602\n",
      "batch 2226: loss 0.060879 accuracy: 0.966605\n",
      "batch 2227: loss 0.031409 accuracy: 0.966616\n",
      "batch 2228: loss 0.041891 accuracy: 0.966626\n",
      "batch 2229: loss 0.031070 accuracy: 0.966639\n",
      "batch 2230: loss 0.045355 accuracy: 0.966649\n",
      "batch 2231: loss 0.022225 accuracy: 0.966664\n",
      "batch 2232: loss 0.052726 accuracy: 0.966675\n",
      "batch 2233: loss 0.051840 accuracy: 0.966681\n",
      "batch 2234: loss 0.035429 accuracy: 0.966694\n",
      "batch 2235: loss 0.029431 accuracy: 0.966702\n",
      "batch 2236: loss 0.044811 accuracy: 0.966712\n",
      "batch 2237: loss 0.014532 accuracy: 0.966727\n",
      "batch 2238: loss 0.046743 accuracy: 0.966735\n",
      "batch 2239: loss 0.020359 accuracy: 0.966748\n",
      "batch 2240: loss 0.049391 accuracy: 0.966756\n",
      "batch 2241: loss 0.067850 accuracy: 0.966757\n",
      "batch 2242: loss 0.024984 accuracy: 0.966768\n",
      "batch 2243: loss 0.061898 accuracy: 0.966778\n",
      "batch 2244: loss 0.044518 accuracy: 0.966788\n",
      "batch 2245: loss 0.023128 accuracy: 0.966801\n",
      "batch 2246: loss 0.029514 accuracy: 0.966809\n",
      "batch 2247: loss 0.027310 accuracy: 0.966819\n",
      "batch 2248: loss 0.042138 accuracy: 0.966827\n",
      "batch 2249: loss 0.020953 accuracy: 0.966842\n",
      "batch 2250: loss 0.024303 accuracy: 0.966855\n",
      "batch 2251: loss 0.049311 accuracy: 0.966865\n",
      "batch 2252: loss 0.044695 accuracy: 0.966873\n",
      "batch 2253: loss 0.051546 accuracy: 0.966883\n",
      "batch 2254: loss 0.028473 accuracy: 0.966896\n",
      "batch 2255: loss 0.025394 accuracy: 0.966906\n",
      "batch 2256: loss 0.032813 accuracy: 0.966916\n",
      "batch 2257: loss 0.021826 accuracy: 0.966929\n",
      "batch 2258: loss 0.017735 accuracy: 0.966943\n",
      "batch 2259: loss 0.063259 accuracy: 0.966951\n",
      "batch 2260: loss 0.023386 accuracy: 0.966964\n",
      "batch 2261: loss 0.050709 accuracy: 0.966969\n",
      "batch 2262: loss 0.033063 accuracy: 0.966980\n",
      "batch 2263: loss 0.035794 accuracy: 0.966990\n",
      "batch 2264: loss 0.063021 accuracy: 0.966996\n",
      "batch 2265: loss 0.032735 accuracy: 0.967006\n",
      "batch 2266: loss 0.075137 accuracy: 0.967011\n",
      "batch 2267: loss 0.071732 accuracy: 0.967015\n",
      "batch 2268: loss 0.030185 accuracy: 0.967025\n",
      "batch 2269: loss 0.029280 accuracy: 0.967040\n",
      "batch 2270: loss 0.015827 accuracy: 0.967054\n",
      "batch 2271: loss 0.020276 accuracy: 0.967066\n",
      "batch 2272: loss 0.027608 accuracy: 0.967079\n",
      "batch 2273: loss 0.034448 accuracy: 0.967087\n",
      "batch 2274: loss 0.078685 accuracy: 0.967088\n",
      "batch 2275: loss 0.020666 accuracy: 0.967100\n",
      "batch 2276: loss 0.042667 accuracy: 0.967106\n",
      "batch 2277: loss 0.014835 accuracy: 0.967120\n",
      "batch 2278: loss 0.030243 accuracy: 0.967133\n",
      "batch 2279: loss 0.017489 accuracy: 0.967147\n",
      "batch 2280: loss 0.067225 accuracy: 0.967153\n",
      "batch 2281: loss 0.038314 accuracy: 0.967163\n",
      "batch 2282: loss 0.032650 accuracy: 0.967175\n",
      "batch 2283: loss 0.041529 accuracy: 0.967187\n",
      "batch 2284: loss 0.024777 accuracy: 0.967199\n",
      "batch 2285: loss 0.030748 accuracy: 0.967209\n",
      "batch 2286: loss 0.040984 accuracy: 0.967221\n",
      "batch 2287: loss 0.171203 accuracy: 0.967222\n",
      "batch 2288: loss 0.045035 accuracy: 0.967230\n",
      "batch 2289: loss 0.043860 accuracy: 0.967238\n",
      "batch 2290: loss 0.044053 accuracy: 0.967246\n",
      "batch 2291: loss 0.036361 accuracy: 0.967254\n",
      "batch 2292: loss 0.018074 accuracy: 0.967266\n",
      "batch 2293: loss 0.009585 accuracy: 0.967280\n",
      "batch 2294: loss 0.056071 accuracy: 0.967292\n",
      "batch 2295: loss 0.030926 accuracy: 0.967302\n",
      "batch 2296: loss 0.031362 accuracy: 0.967314\n",
      "batch 2297: loss 0.034024 accuracy: 0.967324\n",
      "batch 2298: loss 0.059377 accuracy: 0.967334\n",
      "batch 2299: loss 0.077190 accuracy: 0.967339\n",
      "batch 2300: loss 0.039860 accuracy: 0.967347\n",
      "model saved to ./save\\ckpt-2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2301: loss 0.033200 accuracy: 0.967357\n",
      "batch 2302: loss 0.025606 accuracy: 0.967366\n",
      "batch 2303: loss 0.034322 accuracy: 0.967374\n",
      "batch 2304: loss 0.025946 accuracy: 0.967384\n",
      "batch 2305: loss 0.022706 accuracy: 0.967396\n",
      "batch 2306: loss 0.044330 accuracy: 0.967406\n",
      "batch 2307: loss 0.020437 accuracy: 0.967418\n",
      "batch 2308: loss 0.031754 accuracy: 0.967427\n",
      "batch 2309: loss 0.035818 accuracy: 0.967437\n",
      "batch 2310: loss 0.025799 accuracy: 0.967449\n",
      "batch 2311: loss 0.022721 accuracy: 0.967463\n",
      "batch 2312: loss 0.065174 accuracy: 0.967466\n",
      "batch 2313: loss 0.020357 accuracy: 0.967478\n",
      "batch 2314: loss 0.073677 accuracy: 0.967482\n",
      "batch 2315: loss 0.044994 accuracy: 0.967494\n",
      "batch 2316: loss 0.041099 accuracy: 0.967503\n",
      "batch 2317: loss 0.019310 accuracy: 0.967515\n",
      "batch 2318: loss 0.051161 accuracy: 0.967520\n",
      "batch 2319: loss 0.026951 accuracy: 0.967532\n",
      "batch 2320: loss 0.041994 accuracy: 0.967542\n",
      "batch 2321: loss 0.074807 accuracy: 0.967547\n",
      "batch 2322: loss 0.037290 accuracy: 0.967557\n",
      "batch 2323: loss 0.030743 accuracy: 0.967569\n",
      "batch 2324: loss 0.036456 accuracy: 0.967581\n",
      "batch 2325: loss 0.025611 accuracy: 0.967590\n",
      "batch 2326: loss 0.026915 accuracy: 0.967602\n",
      "batch 2327: loss 0.014392 accuracy: 0.967616\n",
      "batch 2328: loss 0.055469 accuracy: 0.967623\n",
      "batch 2329: loss 0.024380 accuracy: 0.967631\n",
      "batch 2330: loss 0.042069 accuracy: 0.967638\n",
      "batch 2331: loss 0.020524 accuracy: 0.967652\n",
      "batch 2332: loss 0.020113 accuracy: 0.967666\n",
      "batch 2333: loss 0.052599 accuracy: 0.967674\n",
      "batch 2334: loss 0.038381 accuracy: 0.967683\n",
      "batch 2335: loss 0.028733 accuracy: 0.967695\n",
      "batch 2336: loss 0.039787 accuracy: 0.967706\n",
      "batch 2337: loss 0.020272 accuracy: 0.967720\n",
      "batch 2338: loss 0.010352 accuracy: 0.967734\n",
      "batch 2339: loss 0.039190 accuracy: 0.967741\n",
      "batch 2340: loss 0.028892 accuracy: 0.967753\n",
      "batch 2341: loss 0.040902 accuracy: 0.967760\n",
      "batch 2342: loss 0.028258 accuracy: 0.967774\n",
      "batch 2343: loss 0.098188 accuracy: 0.967779\n",
      "batch 2344: loss 0.039784 accuracy: 0.967787\n",
      "batch 2345: loss 0.056503 accuracy: 0.967792\n",
      "batch 2346: loss 0.067206 accuracy: 0.967797\n",
      "batch 2347: loss 0.060227 accuracy: 0.967807\n",
      "batch 2348: loss 0.029491 accuracy: 0.967816\n",
      "batch 2349: loss 0.021468 accuracy: 0.967828\n",
      "batch 2350: loss 0.017230 accuracy: 0.967841\n",
      "batch 2351: loss 0.023688 accuracy: 0.967853\n",
      "batch 2352: loss 0.068141 accuracy: 0.967860\n",
      "batch 2353: loss 0.048626 accuracy: 0.967870\n",
      "batch 2354: loss 0.101692 accuracy: 0.967879\n",
      "batch 2355: loss 0.034825 accuracy: 0.967891\n",
      "batch 2356: loss 0.051221 accuracy: 0.967900\n",
      "batch 2357: loss 0.031497 accuracy: 0.967909\n",
      "batch 2358: loss 0.041979 accuracy: 0.967916\n",
      "batch 2359: loss 0.023953 accuracy: 0.967930\n",
      "batch 2360: loss 0.023743 accuracy: 0.967942\n",
      "batch 2361: loss 0.085269 accuracy: 0.967947\n",
      "batch 2362: loss 0.027989 accuracy: 0.967958\n",
      "batch 2363: loss 0.032085 accuracy: 0.967970\n",
      "batch 2364: loss 0.014705 accuracy: 0.967983\n",
      "batch 2365: loss 0.012711 accuracy: 0.967997\n",
      "batch 2366: loss 0.021929 accuracy: 0.968008\n",
      "batch 2367: loss 0.047756 accuracy: 0.968017\n",
      "batch 2368: loss 0.051521 accuracy: 0.968022\n",
      "batch 2369: loss 0.022692 accuracy: 0.968032\n",
      "batch 2370: loss 0.024080 accuracy: 0.968041\n",
      "batch 2371: loss 0.060734 accuracy: 0.968046\n",
      "batch 2372: loss 0.047865 accuracy: 0.968055\n",
      "batch 2373: loss 0.057639 accuracy: 0.968067\n",
      "batch 2374: loss 0.028712 accuracy: 0.968074\n",
      "batch 2375: loss 0.026357 accuracy: 0.968085\n",
      "batch 2376: loss 0.035188 accuracy: 0.968096\n",
      "batch 2377: loss 0.028305 accuracy: 0.968106\n",
      "batch 2378: loss 0.023128 accuracy: 0.968117\n",
      "batch 2379: loss 0.022366 accuracy: 0.968128\n",
      "batch 2380: loss 0.020994 accuracy: 0.968139\n",
      "batch 2381: loss 0.056914 accuracy: 0.968147\n",
      "batch 2382: loss 0.021413 accuracy: 0.968158\n",
      "batch 2383: loss 0.025363 accuracy: 0.968171\n",
      "batch 2384: loss 0.059826 accuracy: 0.968180\n",
      "batch 2385: loss 0.014607 accuracy: 0.968194\n",
      "batch 2386: loss 0.034994 accuracy: 0.968203\n",
      "batch 2387: loss 0.037828 accuracy: 0.968214\n",
      "batch 2388: loss 0.040142 accuracy: 0.968223\n",
      "batch 2389: loss 0.043113 accuracy: 0.968230\n",
      "batch 2390: loss 0.016922 accuracy: 0.968243\n",
      "batch 2391: loss 0.014097 accuracy: 0.968257\n",
      "batch 2392: loss 0.030896 accuracy: 0.968270\n",
      "batch 2393: loss 0.022493 accuracy: 0.968279\n",
      "batch 2394: loss 0.046876 accuracy: 0.968286\n",
      "batch 2395: loss 0.034886 accuracy: 0.968295\n",
      "batch 2396: loss 0.026999 accuracy: 0.968306\n",
      "batch 2397: loss 0.020431 accuracy: 0.968319\n",
      "batch 2398: loss 0.028999 accuracy: 0.968331\n",
      "batch 2399: loss 0.088249 accuracy: 0.968333\n",
      "batch 2400: loss 0.037268 accuracy: 0.968340\n",
      "model saved to ./save\\ckpt-2400\n",
      "batch 2401: loss 0.030481 accuracy: 0.968351\n",
      "batch 2402: loss 0.031261 accuracy: 0.968362\n",
      "batch 2403: loss 0.028334 accuracy: 0.968376\n",
      "batch 2404: loss 0.031343 accuracy: 0.968383\n",
      "batch 2405: loss 0.039964 accuracy: 0.968392\n",
      "batch 2406: loss 0.047609 accuracy: 0.968396\n",
      "batch 2407: loss 0.020194 accuracy: 0.968409\n",
      "batch 2408: loss 0.039827 accuracy: 0.968418\n",
      "batch 2409: loss 0.022690 accuracy: 0.968429\n",
      "batch 2410: loss 0.032099 accuracy: 0.968440\n",
      "batch 2411: loss 0.045747 accuracy: 0.968449\n",
      "batch 2412: loss 0.054694 accuracy: 0.968456\n",
      "batch 2413: loss 0.040844 accuracy: 0.968465\n",
      "batch 2414: loss 0.034374 accuracy: 0.968474\n",
      "batch 2415: loss 0.037321 accuracy: 0.968483\n",
      "batch 2416: loss 0.045469 accuracy: 0.968486\n",
      "batch 2417: loss 0.021140 accuracy: 0.968499\n",
      "batch 2418: loss 0.016428 accuracy: 0.968512\n",
      "batch 2419: loss 0.049503 accuracy: 0.968514\n",
      "batch 2420: loss 0.025112 accuracy: 0.968523\n",
      "batch 2421: loss 0.041440 accuracy: 0.968530\n",
      "batch 2422: loss 0.027450 accuracy: 0.968539\n",
      "batch 2423: loss 0.047001 accuracy: 0.968546\n",
      "batch 2424: loss 0.031743 accuracy: 0.968551\n",
      "batch 2425: loss 0.033611 accuracy: 0.968561\n",
      "batch 2426: loss 0.026300 accuracy: 0.968572\n",
      "batch 2427: loss 0.031577 accuracy: 0.968581\n",
      "batch 2428: loss 0.116199 accuracy: 0.968586\n",
      "batch 2429: loss 0.072018 accuracy: 0.968588\n",
      "batch 2430: loss 0.028572 accuracy: 0.968597\n",
      "batch 2431: loss 0.023570 accuracy: 0.968606\n",
      "batch 2432: loss 0.037561 accuracy: 0.968613\n",
      "batch 2433: loss 0.052447 accuracy: 0.968615\n",
      "batch 2434: loss 0.012545 accuracy: 0.968628\n",
      "batch 2435: loss 0.031560 accuracy: 0.968637\n",
      "batch 2436: loss 0.055672 accuracy: 0.968642\n",
      "batch 2437: loss 0.036425 accuracy: 0.968648\n",
      "batch 2438: loss 0.029348 accuracy: 0.968659\n",
      "batch 2439: loss 0.017739 accuracy: 0.968672\n",
      "batch 2440: loss 0.032013 accuracy: 0.968683\n",
      "batch 2441: loss 0.034085 accuracy: 0.968692\n",
      "batch 2442: loss 0.023082 accuracy: 0.968702\n",
      "batch 2443: loss 0.019123 accuracy: 0.968715\n",
      "batch 2444: loss 0.011029 accuracy: 0.968728\n",
      "batch 2445: loss 0.031719 accuracy: 0.968739\n",
      "batch 2446: loss 0.035867 accuracy: 0.968745\n",
      "batch 2447: loss 0.031347 accuracy: 0.968756\n",
      "batch 2448: loss 0.021307 accuracy: 0.968769\n",
      "batch 2449: loss 0.034184 accuracy: 0.968780\n",
      "batch 2450: loss 0.035388 accuracy: 0.968790\n",
      "batch 2451: loss 0.031353 accuracy: 0.968799\n",
      "batch 2452: loss 0.046542 accuracy: 0.968808\n",
      "batch 2453: loss 0.043175 accuracy: 0.968814\n",
      "batch 2454: loss 0.050164 accuracy: 0.968823\n",
      "batch 2455: loss 0.027882 accuracy: 0.968831\n",
      "batch 2456: loss 0.032347 accuracy: 0.968840\n",
      "batch 2457: loss 0.034506 accuracy: 0.968849\n",
      "batch 2458: loss 0.063830 accuracy: 0.968853\n",
      "batch 2459: loss 0.020836 accuracy: 0.968866\n",
      "batch 2460: loss 0.017833 accuracy: 0.968879\n",
      "batch 2461: loss 0.033773 accuracy: 0.968889\n",
      "batch 2462: loss 0.048899 accuracy: 0.968892\n",
      "batch 2463: loss 0.017169 accuracy: 0.968904\n",
      "batch 2464: loss 0.023907 accuracy: 0.968913\n",
      "batch 2465: loss 0.024596 accuracy: 0.968921\n",
      "batch 2466: loss 0.035765 accuracy: 0.968932\n",
      "batch 2467: loss 0.043053 accuracy: 0.968938\n",
      "batch 2468: loss 0.025632 accuracy: 0.968949\n",
      "batch 2469: loss 0.018706 accuracy: 0.968962\n",
      "batch 2470: loss 0.014431 accuracy: 0.968974\n",
      "batch 2471: loss 0.023833 accuracy: 0.968983\n",
      "batch 2472: loss 0.040045 accuracy: 0.968991\n",
      "batch 2473: loss 0.035563 accuracy: 0.969000\n",
      "batch 2474: loss 0.033685 accuracy: 0.969010\n",
      "batch 2475: loss 0.024064 accuracy: 0.969019\n",
      "batch 2476: loss 0.018286 accuracy: 0.969031\n",
      "batch 2477: loss 0.028361 accuracy: 0.969042\n",
      "batch 2478: loss 0.031169 accuracy: 0.969050\n",
      "batch 2479: loss 0.042245 accuracy: 0.969054\n",
      "batch 2480: loss 0.047615 accuracy: 0.969059\n",
      "batch 2481: loss 0.048887 accuracy: 0.969065\n",
      "batch 2482: loss 0.030553 accuracy: 0.969076\n",
      "batch 2483: loss 0.042148 accuracy: 0.969086\n",
      "batch 2484: loss 0.019632 accuracy: 0.969097\n",
      "batch 2485: loss 0.020636 accuracy: 0.969109\n",
      "batch 2486: loss 0.020452 accuracy: 0.969119\n",
      "batch 2487: loss 0.027904 accuracy: 0.969130\n",
      "batch 2488: loss 0.022335 accuracy: 0.969138\n",
      "batch 2489: loss 0.066132 accuracy: 0.969141\n",
      "batch 2490: loss 0.020483 accuracy: 0.969153\n",
      "batch 2491: loss 0.013806 accuracy: 0.969165\n",
      "batch 2492: loss 0.039247 accuracy: 0.969172\n",
      "batch 2493: loss 0.040637 accuracy: 0.969178\n",
      "batch 2494: loss 0.020767 accuracy: 0.969188\n",
      "batch 2495: loss 0.029348 accuracy: 0.969195\n",
      "batch 2496: loss 0.044937 accuracy: 0.969201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2497: loss 0.032622 accuracy: 0.969207\n",
      "batch 2498: loss 0.041012 accuracy: 0.969216\n",
      "batch 2499: loss 0.033290 accuracy: 0.969222\n",
      "batch 2500: loss 0.075028 accuracy: 0.969226\n",
      "model saved to ./save\\ckpt-2500\n",
      "batch 2501: loss 0.034500 accuracy: 0.969235\n",
      "batch 2502: loss 0.022640 accuracy: 0.969245\n",
      "batch 2503: loss 0.022208 accuracy: 0.969253\n",
      "batch 2504: loss 0.046452 accuracy: 0.969260\n",
      "batch 2505: loss 0.026356 accuracy: 0.969270\n",
      "batch 2506: loss 0.024275 accuracy: 0.969280\n",
      "batch 2507: loss 0.092744 accuracy: 0.969284\n",
      "batch 2508: loss 0.009791 accuracy: 0.969297\n",
      "batch 2509: loss 0.059256 accuracy: 0.969305\n",
      "batch 2510: loss 0.031143 accuracy: 0.969315\n",
      "batch 2511: loss 0.049072 accuracy: 0.969325\n",
      "batch 2512: loss 0.022709 accuracy: 0.969335\n",
      "batch 2513: loss 0.016759 accuracy: 0.969348\n",
      "batch 2514: loss 0.060759 accuracy: 0.969352\n",
      "batch 2515: loss 0.022321 accuracy: 0.969362\n",
      "batch 2516: loss 0.028886 accuracy: 0.969370\n",
      "batch 2517: loss 0.032742 accuracy: 0.969378\n",
      "batch 2518: loss 0.042223 accuracy: 0.969387\n",
      "batch 2519: loss 0.051691 accuracy: 0.969391\n",
      "batch 2520: loss 0.030011 accuracy: 0.969399\n",
      "batch 2521: loss 0.064444 accuracy: 0.969405\n",
      "batch 2522: loss 0.080873 accuracy: 0.969407\n",
      "batch 2523: loss 0.025162 accuracy: 0.969418\n",
      "batch 2524: loss 0.053904 accuracy: 0.969426\n",
      "batch 2525: loss 0.029636 accuracy: 0.969432\n",
      "batch 2526: loss 0.038438 accuracy: 0.969440\n",
      "batch 2527: loss 0.032797 accuracy: 0.969448\n",
      "batch 2528: loss 0.043281 accuracy: 0.969456\n",
      "batch 2529: loss 0.028893 accuracy: 0.969460\n",
      "batch 2530: loss 0.012335 accuracy: 0.969471\n",
      "batch 2531: loss 0.016548 accuracy: 0.969483\n",
      "batch 2532: loss 0.030992 accuracy: 0.969493\n",
      "batch 2533: loss 0.021854 accuracy: 0.969501\n",
      "batch 2534: loss 0.073921 accuracy: 0.969509\n",
      "batch 2535: loss 0.128788 accuracy: 0.969513\n",
      "batch 2536: loss 0.022078 accuracy: 0.969523\n",
      "batch 2537: loss 0.021643 accuracy: 0.969533\n",
      "batch 2538: loss 0.071307 accuracy: 0.969535\n",
      "batch 2539: loss 0.040637 accuracy: 0.969541\n",
      "batch 2540: loss 0.017490 accuracy: 0.969553\n",
      "batch 2541: loss 0.023414 accuracy: 0.969565\n",
      "batch 2542: loss 0.057023 accuracy: 0.969573\n",
      "batch 2543: loss 0.051610 accuracy: 0.969579\n",
      "batch 2544: loss 0.022248 accuracy: 0.969589\n",
      "batch 2545: loss 0.024945 accuracy: 0.969599\n",
      "batch 2546: loss 0.035197 accuracy: 0.969607\n",
      "batch 2547: loss 0.029844 accuracy: 0.969615\n",
      "batch 2548: loss 0.011900 accuracy: 0.969627\n",
      "batch 2549: loss 0.020322 accuracy: 0.969635\n",
      "batch 2550: loss 0.014144 accuracy: 0.969647\n",
      "batch 2551: loss 0.024788 accuracy: 0.969659\n",
      "batch 2552: loss 0.036401 accuracy: 0.969667\n",
      "batch 2553: loss 0.028200 accuracy: 0.969677\n",
      "batch 2554: loss 0.021165 accuracy: 0.969687\n",
      "batch 2555: loss 0.033368 accuracy: 0.969695\n",
      "batch 2556: loss 0.022175 accuracy: 0.969705\n",
      "batch 2557: loss 0.031693 accuracy: 0.969713\n",
      "batch 2558: loss 0.028584 accuracy: 0.969721\n",
      "batch 2559: loss 0.015020 accuracy: 0.969732\n",
      "batch 2560: loss 0.025766 accuracy: 0.969740\n",
      "batch 2561: loss 0.021862 accuracy: 0.969752\n",
      "batch 2562: loss 0.029391 accuracy: 0.969762\n",
      "batch 2563: loss 0.031827 accuracy: 0.969768\n",
      "batch 2564: loss 0.035932 accuracy: 0.969776\n",
      "batch 2565: loss 0.011939 accuracy: 0.969788\n",
      "batch 2566: loss 0.033331 accuracy: 0.969795\n",
      "batch 2567: loss 0.025284 accuracy: 0.969805\n",
      "batch 2568: loss 0.006322 accuracy: 0.969817\n",
      "batch 2569: loss 0.042827 accuracy: 0.969827\n",
      "batch 2570: loss 0.022592 accuracy: 0.969837\n",
      "batch 2571: loss 0.024687 accuracy: 0.969846\n",
      "batch 2572: loss 0.020032 accuracy: 0.969856\n",
      "batch 2573: loss 0.047177 accuracy: 0.969862\n",
      "batch 2574: loss 0.026458 accuracy: 0.969870\n",
      "batch 2575: loss 0.029826 accuracy: 0.969880\n",
      "batch 2576: loss 0.041308 accuracy: 0.969887\n",
      "batch 2577: loss 0.013093 accuracy: 0.969899\n",
      "batch 2578: loss 0.017958 accuracy: 0.969911\n",
      "batch 2579: loss 0.026492 accuracy: 0.969921\n",
      "batch 2580: loss 0.028056 accuracy: 0.969928\n",
      "batch 2581: loss 0.052281 accuracy: 0.969936\n",
      "batch 2582: loss 0.076828 accuracy: 0.969940\n",
      "batch 2583: loss 0.011595 accuracy: 0.969952\n",
      "batch 2584: loss 0.030325 accuracy: 0.969959\n",
      "batch 2585: loss 0.025346 accuracy: 0.969969\n",
      "batch 2586: loss 0.033456 accuracy: 0.969977\n",
      "batch 2587: loss 0.017061 accuracy: 0.969986\n",
      "batch 2588: loss 0.044141 accuracy: 0.969994\n",
      "batch 2589: loss 0.020501 accuracy: 0.970004\n",
      "batch 2590: loss 0.018118 accuracy: 0.970015\n",
      "batch 2591: loss 0.060193 accuracy: 0.970019\n",
      "batch 2592: loss 0.040563 accuracy: 0.970025\n",
      "batch 2593: loss 0.014751 accuracy: 0.970037\n",
      "batch 2594: loss 0.028333 accuracy: 0.970044\n",
      "batch 2595: loss 0.045353 accuracy: 0.970050\n",
      "batch 2596: loss 0.022894 accuracy: 0.970062\n",
      "batch 2597: loss 0.062407 accuracy: 0.970071\n",
      "batch 2598: loss 0.022337 accuracy: 0.970081\n",
      "batch 2599: loss 0.033120 accuracy: 0.970088\n",
      "batch 2600: loss 0.025673 accuracy: 0.970098\n",
      "model saved to ./save\\ckpt-2600\n",
      "batch 2601: loss 0.073692 accuracy: 0.970098\n",
      "batch 2602: loss 0.020287 accuracy: 0.970106\n",
      "batch 2603: loss 0.038740 accuracy: 0.970111\n",
      "batch 2604: loss 0.025934 accuracy: 0.970119\n",
      "batch 2605: loss 0.015842 accuracy: 0.970130\n",
      "batch 2606: loss 0.014637 accuracy: 0.970140\n",
      "batch 2607: loss 0.013790 accuracy: 0.970151\n",
      "batch 2608: loss 0.066605 accuracy: 0.970153\n",
      "batch 2609: loss 0.006098 accuracy: 0.970165\n",
      "batch 2610: loss 0.036973 accuracy: 0.970170\n",
      "batch 2611: loss 0.051751 accuracy: 0.970176\n",
      "batch 2612: loss 0.033438 accuracy: 0.970184\n",
      "batch 2613: loss 0.045444 accuracy: 0.970187\n",
      "batch 2614: loss 0.016143 accuracy: 0.970197\n",
      "batch 2615: loss 0.047979 accuracy: 0.970205\n",
      "batch 2616: loss 0.022870 accuracy: 0.970214\n",
      "batch 2617: loss 0.031756 accuracy: 0.970223\n",
      "batch 2618: loss 0.034256 accuracy: 0.970231\n",
      "batch 2619: loss 0.037687 accuracy: 0.970240\n",
      "batch 2620: loss 0.060646 accuracy: 0.970244\n",
      "batch 2621: loss 0.023133 accuracy: 0.970254\n",
      "batch 2622: loss 0.054204 accuracy: 0.970261\n",
      "batch 2623: loss 0.034817 accuracy: 0.970269\n",
      "batch 2624: loss 0.031075 accuracy: 0.970274\n",
      "batch 2625: loss 0.029298 accuracy: 0.970284\n",
      "batch 2626: loss 0.041237 accuracy: 0.970289\n",
      "batch 2627: loss 0.065929 accuracy: 0.970291\n",
      "batch 2628: loss 0.028820 accuracy: 0.970299\n",
      "batch 2629: loss 0.016616 accuracy: 0.970310\n",
      "batch 2630: loss 0.038469 accuracy: 0.970315\n",
      "batch 2631: loss 0.029243 accuracy: 0.970323\n",
      "batch 2632: loss 0.046126 accuracy: 0.970325\n",
      "batch 2633: loss 0.017374 accuracy: 0.970334\n",
      "batch 2634: loss 0.040929 accuracy: 0.970340\n",
      "batch 2635: loss 0.021178 accuracy: 0.970349\n",
      "batch 2636: loss 0.033193 accuracy: 0.970356\n",
      "batch 2637: loss 0.050316 accuracy: 0.970366\n",
      "batch 2638: loss 0.025561 accuracy: 0.970373\n",
      "batch 2639: loss 0.022160 accuracy: 0.970383\n",
      "batch 2640: loss 0.026699 accuracy: 0.970390\n",
      "batch 2641: loss 0.028797 accuracy: 0.970396\n",
      "batch 2642: loss 0.022149 accuracy: 0.970405\n",
      "batch 2643: loss 0.018239 accuracy: 0.970414\n",
      "batch 2644: loss 0.027711 accuracy: 0.970422\n",
      "batch 2645: loss 0.061667 accuracy: 0.970427\n",
      "batch 2646: loss 0.058726 accuracy: 0.970433\n",
      "batch 2647: loss 0.044396 accuracy: 0.970436\n",
      "batch 2648: loss 0.057158 accuracy: 0.970445\n",
      "batch 2649: loss 0.073990 accuracy: 0.970447\n",
      "batch 2650: loss 0.029298 accuracy: 0.970455\n",
      "batch 2651: loss 0.046564 accuracy: 0.970458\n",
      "batch 2652: loss 0.032341 accuracy: 0.970465\n",
      "batch 2653: loss 0.023537 accuracy: 0.970475\n",
      "batch 2654: loss 0.045748 accuracy: 0.970482\n",
      "batch 2655: loss 0.050336 accuracy: 0.970491\n",
      "batch 2656: loss 0.028354 accuracy: 0.970499\n",
      "batch 2657: loss 0.050152 accuracy: 0.970504\n",
      "batch 2658: loss 0.040721 accuracy: 0.970513\n",
      "batch 2659: loss 0.029378 accuracy: 0.970521\n",
      "batch 2660: loss 0.040141 accuracy: 0.970526\n",
      "batch 2661: loss 0.019079 accuracy: 0.970533\n",
      "batch 2662: loss 0.036666 accuracy: 0.970541\n",
      "batch 2663: loss 0.039642 accuracy: 0.970550\n",
      "batch 2664: loss 0.030444 accuracy: 0.970557\n",
      "batch 2665: loss 0.060631 accuracy: 0.970561\n",
      "batch 2666: loss 0.058466 accuracy: 0.970564\n",
      "batch 2667: loss 0.030145 accuracy: 0.970572\n",
      "batch 2668: loss 0.027137 accuracy: 0.970581\n",
      "batch 2669: loss 0.036024 accuracy: 0.970590\n",
      "batch 2670: loss 0.054408 accuracy: 0.970597\n",
      "batch 2671: loss 0.034311 accuracy: 0.970601\n",
      "batch 2672: loss 0.032689 accuracy: 0.970606\n",
      "batch 2673: loss 0.085996 accuracy: 0.970606\n",
      "batch 2674: loss 0.050467 accuracy: 0.970613\n",
      "batch 2675: loss 0.022958 accuracy: 0.970622\n",
      "batch 2676: loss 0.018216 accuracy: 0.970633\n",
      "batch 2677: loss 0.018924 accuracy: 0.970642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2678: loss 0.022043 accuracy: 0.970651\n",
      "batch 2679: loss 0.016891 accuracy: 0.970662\n",
      "batch 2680: loss 0.026129 accuracy: 0.970673\n",
      "batch 2681: loss 0.040803 accuracy: 0.970680\n",
      "batch 2682: loss 0.017121 accuracy: 0.970690\n",
      "batch 2683: loss 0.012927 accuracy: 0.970700\n",
      "batch 2684: loss 0.022682 accuracy: 0.970711\n",
      "batch 2685: loss 0.020401 accuracy: 0.970722\n",
      "batch 2686: loss 0.023084 accuracy: 0.970731\n",
      "batch 2687: loss 0.028433 accuracy: 0.970740\n",
      "batch 2688: loss 0.033797 accuracy: 0.970746\n",
      "batch 2689: loss 0.055751 accuracy: 0.970749\n",
      "batch 2690: loss 0.050714 accuracy: 0.970753\n",
      "batch 2691: loss 0.031002 accuracy: 0.970762\n",
      "batch 2692: loss 0.023020 accuracy: 0.970769\n",
      "batch 2693: loss 0.017739 accuracy: 0.970780\n",
      "batch 2694: loss 0.044201 accuracy: 0.970787\n",
      "batch 2695: loss 0.029632 accuracy: 0.970797\n",
      "batch 2696: loss 0.038754 accuracy: 0.970805\n",
      "batch 2697: loss 0.032066 accuracy: 0.970812\n",
      "batch 2698: loss 0.019688 accuracy: 0.970821\n",
      "batch 2699: loss 0.036218 accuracy: 0.970826\n",
      "batch 2700: loss 0.019487 accuracy: 0.970837\n",
      "model saved to ./save\\ckpt-2700\n",
      "batch 2701: loss 0.036840 accuracy: 0.970844\n",
      "batch 2702: loss 0.014877 accuracy: 0.970853\n",
      "batch 2703: loss 0.030193 accuracy: 0.970862\n",
      "batch 2704: loss 0.036356 accuracy: 0.970869\n",
      "batch 2705: loss 0.020722 accuracy: 0.970878\n",
      "batch 2706: loss 0.026039 accuracy: 0.970885\n",
      "batch 2707: loss 0.034394 accuracy: 0.970890\n",
      "batch 2708: loss 0.036512 accuracy: 0.970899\n",
      "batch 2709: loss 0.025020 accuracy: 0.970908\n",
      "batch 2710: loss 0.014249 accuracy: 0.970918\n",
      "batch 2711: loss 0.014149 accuracy: 0.970929\n",
      "batch 2712: loss 0.044702 accuracy: 0.970936\n",
      "batch 2713: loss 0.034663 accuracy: 0.970943\n",
      "batch 2714: loss 0.023699 accuracy: 0.970954\n",
      "batch 2715: loss 0.021416 accuracy: 0.970965\n",
      "batch 2716: loss 0.023363 accuracy: 0.970975\n",
      "batch 2717: loss 0.041782 accuracy: 0.970982\n",
      "batch 2718: loss 0.036448 accuracy: 0.970989\n",
      "batch 2719: loss 0.033561 accuracy: 0.970994\n",
      "batch 2720: loss 0.095907 accuracy: 0.971003\n",
      "batch 2721: loss 0.018694 accuracy: 0.971014\n",
      "batch 2722: loss 0.047255 accuracy: 0.971019\n",
      "batch 2723: loss 0.022665 accuracy: 0.971028\n",
      "batch 2724: loss 0.039625 accuracy: 0.971035\n",
      "batch 2725: loss 0.018635 accuracy: 0.971045\n",
      "batch 2726: loss 0.013753 accuracy: 0.971056\n",
      "batch 2727: loss 0.034372 accuracy: 0.971065\n",
      "batch 2728: loss 0.050312 accuracy: 0.971070\n",
      "batch 2729: loss 0.033724 accuracy: 0.971077\n",
      "batch 2730: loss 0.025777 accuracy: 0.971086\n",
      "batch 2731: loss 0.039316 accuracy: 0.971091\n",
      "batch 2732: loss 0.054444 accuracy: 0.971096\n",
      "batch 2733: loss 0.043349 accuracy: 0.971101\n",
      "batch 2734: loss 0.026474 accuracy: 0.971110\n",
      "batch 2735: loss 0.034585 accuracy: 0.971115\n",
      "batch 2736: loss 0.049278 accuracy: 0.971120\n",
      "batch 2737: loss 0.046522 accuracy: 0.971125\n",
      "batch 2738: loss 0.020019 accuracy: 0.971132\n",
      "batch 2739: loss 0.023346 accuracy: 0.971139\n",
      "batch 2740: loss 0.036395 accuracy: 0.971144\n",
      "batch 2741: loss 0.017653 accuracy: 0.971154\n",
      "batch 2742: loss 0.031926 accuracy: 0.971163\n",
      "batch 2743: loss 0.020437 accuracy: 0.971173\n",
      "batch 2744: loss 0.025581 accuracy: 0.971184\n",
      "batch 2745: loss 0.049825 accuracy: 0.971191\n",
      "batch 2746: loss 0.046996 accuracy: 0.971194\n",
      "batch 2747: loss 0.031029 accuracy: 0.971203\n",
      "batch 2748: loss 0.044271 accuracy: 0.971208\n",
      "batch 2749: loss 0.017249 accuracy: 0.971216\n",
      "batch 2750: loss 0.028606 accuracy: 0.971227\n",
      "batch 2751: loss 0.025095 accuracy: 0.971237\n",
      "batch 2752: loss 0.016170 accuracy: 0.971246\n",
      "batch 2753: loss 0.026001 accuracy: 0.971255\n",
      "batch 2754: loss 0.039800 accuracy: 0.971258\n",
      "batch 2755: loss 0.026458 accuracy: 0.971265\n",
      "batch 2756: loss 0.027617 accuracy: 0.971273\n",
      "batch 2757: loss 0.025676 accuracy: 0.971280\n",
      "batch 2758: loss 0.010437 accuracy: 0.971289\n",
      "batch 2759: loss 0.014858 accuracy: 0.971299\n",
      "batch 2760: loss 0.032284 accuracy: 0.971306\n",
      "batch 2761: loss 0.025241 accuracy: 0.971312\n",
      "batch 2762: loss 0.038822 accuracy: 0.971321\n",
      "batch 2763: loss 0.027955 accuracy: 0.971330\n",
      "batch 2764: loss 0.022850 accuracy: 0.971336\n",
      "batch 2765: loss 0.027049 accuracy: 0.971343\n",
      "batch 2766: loss 0.031703 accuracy: 0.971348\n",
      "batch 2767: loss 0.035679 accuracy: 0.971351\n",
      "batch 2768: loss 0.024051 accuracy: 0.971360\n",
      "batch 2769: loss 0.020712 accuracy: 0.971370\n",
      "batch 2770: loss 0.034656 accuracy: 0.971375\n",
      "batch 2771: loss 0.014576 accuracy: 0.971383\n",
      "batch 2772: loss 0.029731 accuracy: 0.971392\n",
      "batch 2773: loss 0.037561 accuracy: 0.971399\n",
      "batch 2774: loss 0.078968 accuracy: 0.971404\n",
      "batch 2775: loss 0.025808 accuracy: 0.971412\n",
      "batch 2776: loss 0.012600 accuracy: 0.971422\n",
      "batch 2777: loss 0.019126 accuracy: 0.971431\n",
      "batch 2778: loss 0.041484 accuracy: 0.971438\n",
      "batch 2779: loss 0.028291 accuracy: 0.971446\n",
      "batch 2780: loss 0.096425 accuracy: 0.971453\n",
      "batch 2781: loss 0.048887 accuracy: 0.971456\n",
      "batch 2782: loss 0.020527 accuracy: 0.971464\n",
      "batch 2783: loss 0.021682 accuracy: 0.971473\n",
      "batch 2784: loss 0.056762 accuracy: 0.971476\n",
      "batch 2785: loss 0.032394 accuracy: 0.971481\n",
      "batch 2786: loss 0.015038 accuracy: 0.971489\n",
      "batch 2787: loss 0.030428 accuracy: 0.971494\n",
      "batch 2788: loss 0.013589 accuracy: 0.971504\n",
      "batch 2789: loss 0.082749 accuracy: 0.971511\n",
      "batch 2790: loss 0.013282 accuracy: 0.971521\n",
      "batch 2791: loss 0.092453 accuracy: 0.971526\n",
      "batch 2792: loss 0.029160 accuracy: 0.971534\n",
      "batch 2793: loss 0.096199 accuracy: 0.971541\n",
      "batch 2794: loss 0.022501 accuracy: 0.971549\n",
      "batch 2795: loss 0.042414 accuracy: 0.971554\n",
      "batch 2796: loss 0.037951 accuracy: 0.971559\n",
      "batch 2797: loss 0.056396 accuracy: 0.971562\n",
      "batch 2798: loss 0.015832 accuracy: 0.971572\n",
      "batch 2799: loss 0.035406 accuracy: 0.971579\n",
      "batch 2800: loss 0.024979 accuracy: 0.971585\n",
      "model saved to ./save\\ckpt-2800\n",
      "batch 2801: loss 0.039299 accuracy: 0.971588\n",
      "batch 2802: loss 0.015028 accuracy: 0.971598\n",
      "batch 2803: loss 0.040534 accuracy: 0.971603\n",
      "batch 2804: loss 0.011838 accuracy: 0.971613\n",
      "batch 2805: loss 0.022148 accuracy: 0.971622\n",
      "batch 2806: loss 0.031317 accuracy: 0.971628\n",
      "batch 2807: loss 0.029494 accuracy: 0.971635\n",
      "batch 2808: loss 0.008677 accuracy: 0.971645\n",
      "batch 2809: loss 0.039151 accuracy: 0.971651\n",
      "batch 2810: loss 0.018997 accuracy: 0.971661\n",
      "batch 2811: loss 0.025175 accuracy: 0.971668\n",
      "batch 2812: loss 0.052693 accuracy: 0.971673\n",
      "batch 2813: loss 0.038117 accuracy: 0.971677\n",
      "batch 2814: loss 0.017716 accuracy: 0.971687\n",
      "batch 2815: loss 0.020068 accuracy: 0.971697\n",
      "batch 2816: loss 0.020811 accuracy: 0.971706\n",
      "batch 2817: loss 0.018005 accuracy: 0.971716\n",
      "batch 2818: loss 0.030370 accuracy: 0.971724\n",
      "batch 2819: loss 0.030138 accuracy: 0.971730\n",
      "batch 2820: loss 0.057240 accuracy: 0.971735\n",
      "batch 2821: loss 0.039521 accuracy: 0.971742\n",
      "batch 2822: loss 0.011111 accuracy: 0.971752\n",
      "batch 2823: loss 0.037857 accuracy: 0.971758\n",
      "batch 2824: loss 0.021086 accuracy: 0.971768\n",
      "batch 2825: loss 0.048128 accuracy: 0.971775\n",
      "batch 2826: loss 0.053772 accuracy: 0.971779\n",
      "batch 2827: loss 0.043002 accuracy: 0.971786\n",
      "batch 2828: loss 0.030815 accuracy: 0.971792\n",
      "batch 2829: loss 0.028675 accuracy: 0.971800\n",
      "batch 2830: loss 0.018793 accuracy: 0.971809\n",
      "batch 2831: loss 0.034982 accuracy: 0.971811\n",
      "batch 2832: loss 0.072409 accuracy: 0.971820\n",
      "batch 2833: loss 0.056055 accuracy: 0.971823\n",
      "batch 2834: loss 0.024756 accuracy: 0.971831\n",
      "batch 2835: loss 0.055367 accuracy: 0.971835\n",
      "batch 2836: loss 0.016000 accuracy: 0.971845\n",
      "batch 2837: loss 0.048498 accuracy: 0.971852\n",
      "batch 2838: loss 0.028557 accuracy: 0.971860\n",
      "batch 2839: loss 0.032020 accuracy: 0.971866\n",
      "batch 2840: loss 0.024141 accuracy: 0.971874\n",
      "batch 2841: loss 0.066209 accuracy: 0.971877\n",
      "batch 2842: loss 0.032681 accuracy: 0.971882\n",
      "batch 2843: loss 0.028002 accuracy: 0.971890\n",
      "batch 2844: loss 0.013869 accuracy: 0.971900\n",
      "batch 2845: loss 0.019048 accuracy: 0.971910\n",
      "batch 2846: loss 0.035289 accuracy: 0.971914\n",
      "batch 2847: loss 0.018166 accuracy: 0.971922\n",
      "batch 2848: loss 0.034508 accuracy: 0.971931\n",
      "batch 2849: loss 0.026901 accuracy: 0.971939\n",
      "batch 2850: loss 0.038161 accuracy: 0.971947\n",
      "batch 2851: loss 0.012150 accuracy: 0.971957\n",
      "batch 2852: loss 0.016629 accuracy: 0.971966\n",
      "batch 2853: loss 0.012257 accuracy: 0.971976\n",
      "batch 2854: loss 0.025500 accuracy: 0.971982\n",
      "batch 2855: loss 0.021688 accuracy: 0.971991\n",
      "batch 2856: loss 0.036191 accuracy: 0.971997\n",
      "batch 2857: loss 0.039552 accuracy: 0.972005\n",
      "batch 2858: loss 0.018851 accuracy: 0.972013\n",
      "batch 2859: loss 0.029745 accuracy: 0.972019\n",
      "batch 2860: loss 0.007017 accuracy: 0.972029\n",
      "batch 2861: loss 0.033502 accuracy: 0.972035\n",
      "batch 2862: loss 0.023977 accuracy: 0.972043\n",
      "batch 2863: loss 0.042592 accuracy: 0.972048\n",
      "batch 2864: loss 0.042089 accuracy: 0.972056\n",
      "batch 2865: loss 0.042728 accuracy: 0.972062\n",
      "batch 2866: loss 0.022316 accuracy: 0.972070\n",
      "batch 2867: loss 0.042569 accuracy: 0.972076\n",
      "batch 2868: loss 0.031910 accuracy: 0.972084\n",
      "batch 2869: loss 0.023168 accuracy: 0.972094\n",
      "batch 2870: loss 0.027094 accuracy: 0.972102\n",
      "batch 2871: loss 0.030670 accuracy: 0.972110\n",
      "batch 2872: loss 0.024251 accuracy: 0.972120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2873: loss 0.039857 accuracy: 0.972124\n",
      "batch 2874: loss 0.047918 accuracy: 0.972129\n",
      "batch 2875: loss 0.014801 accuracy: 0.972137\n",
      "batch 2876: loss 0.020912 accuracy: 0.972146\n",
      "batch 2877: loss 0.017521 accuracy: 0.972153\n",
      "batch 2878: loss 0.034870 accuracy: 0.972159\n",
      "batch 2879: loss 0.041287 accuracy: 0.972165\n",
      "batch 2880: loss 0.014210 accuracy: 0.972175\n",
      "batch 2881: loss 0.031903 accuracy: 0.972181\n",
      "batch 2882: loss 0.070764 accuracy: 0.972183\n",
      "batch 2883: loss 0.050614 accuracy: 0.972190\n",
      "batch 2884: loss 0.053673 accuracy: 0.972192\n",
      "batch 2885: loss 0.018756 accuracy: 0.972202\n",
      "batch 2886: loss 0.016954 accuracy: 0.972210\n",
      "batch 2887: loss 0.030778 accuracy: 0.972216\n",
      "batch 2888: loss 0.013198 accuracy: 0.972224\n",
      "batch 2889: loss 0.021841 accuracy: 0.972232\n",
      "batch 2890: loss 0.011460 accuracy: 0.972241\n",
      "batch 2891: loss 0.040925 accuracy: 0.972249\n",
      "batch 2892: loss 0.033178 accuracy: 0.972255\n",
      "batch 2893: loss 0.025531 accuracy: 0.972263\n",
      "batch 2894: loss 0.014910 accuracy: 0.972273\n",
      "batch 2895: loss 0.025612 accuracy: 0.972281\n",
      "batch 2896: loss 0.023362 accuracy: 0.972289\n",
      "batch 2897: loss 0.025492 accuracy: 0.972296\n",
      "batch 2898: loss 0.018506 accuracy: 0.972306\n",
      "batch 2899: loss 0.013408 accuracy: 0.972314\n",
      "batch 2900: loss 0.032583 accuracy: 0.972320\n",
      "model saved to ./save\\ckpt-2900\n",
      "batch 2901: loss 0.047736 accuracy: 0.972323\n",
      "batch 2902: loss 0.025742 accuracy: 0.972327\n",
      "batch 2903: loss 0.034451 accuracy: 0.972333\n",
      "batch 2904: loss 0.021245 accuracy: 0.972339\n",
      "batch 2905: loss 0.018355 accuracy: 0.972347\n",
      "batch 2906: loss 0.049373 accuracy: 0.972348\n",
      "batch 2907: loss 0.033951 accuracy: 0.972354\n",
      "batch 2908: loss 0.033145 accuracy: 0.972360\n",
      "batch 2909: loss 0.014949 accuracy: 0.972368\n",
      "batch 2910: loss 0.059617 accuracy: 0.972375\n",
      "batch 2911: loss 0.018034 accuracy: 0.972383\n",
      "batch 2912: loss 0.006126 accuracy: 0.972393\n",
      "batch 2913: loss 0.042326 accuracy: 0.972397\n",
      "batch 2914: loss 0.026355 accuracy: 0.972405\n",
      "batch 2915: loss 0.025615 accuracy: 0.972411\n",
      "batch 2916: loss 0.014905 accuracy: 0.972420\n",
      "batch 2917: loss 0.023564 accuracy: 0.972426\n",
      "batch 2918: loss 0.016388 accuracy: 0.972436\n",
      "batch 2919: loss 0.029476 accuracy: 0.972440\n",
      "batch 2920: loss 0.028947 accuracy: 0.972448\n",
      "batch 2921: loss 0.017145 accuracy: 0.972457\n",
      "batch 2922: loss 0.051433 accuracy: 0.972463\n",
      "batch 2923: loss 0.020299 accuracy: 0.972473\n",
      "batch 2924: loss 0.049833 accuracy: 0.972480\n",
      "batch 2925: loss 0.041824 accuracy: 0.972485\n",
      "batch 2926: loss 0.050309 accuracy: 0.972489\n",
      "batch 2927: loss 0.047784 accuracy: 0.972491\n",
      "batch 2928: loss 0.033032 accuracy: 0.972499\n",
      "batch 2929: loss 0.026262 accuracy: 0.972507\n",
      "batch 2930: loss 0.024685 accuracy: 0.972513\n",
      "batch 2931: loss 0.029226 accuracy: 0.972520\n",
      "batch 2932: loss 0.029770 accuracy: 0.972525\n",
      "batch 2933: loss 0.046067 accuracy: 0.972529\n",
      "batch 2934: loss 0.013100 accuracy: 0.972538\n",
      "batch 2935: loss 0.013141 accuracy: 0.972548\n",
      "batch 2936: loss 0.026297 accuracy: 0.972552\n",
      "batch 2937: loss 0.027841 accuracy: 0.972558\n",
      "batch 2938: loss 0.033427 accuracy: 0.972565\n",
      "batch 2939: loss 0.019809 accuracy: 0.972575\n",
      "batch 2940: loss 0.047986 accuracy: 0.972579\n",
      "batch 2941: loss 0.015445 accuracy: 0.972588\n",
      "batch 2942: loss 0.011823 accuracy: 0.972598\n",
      "batch 2943: loss 0.013061 accuracy: 0.972607\n",
      "batch 2944: loss 0.051637 accuracy: 0.972613\n",
      "batch 2945: loss 0.050523 accuracy: 0.972617\n",
      "batch 2946: loss 0.046341 accuracy: 0.972620\n",
      "batch 2947: loss 0.018455 accuracy: 0.972627\n",
      "batch 2948: loss 0.019251 accuracy: 0.972635\n",
      "batch 2949: loss 0.055099 accuracy: 0.972639\n",
      "batch 2950: loss 0.014122 accuracy: 0.972648\n",
      "batch 2951: loss 0.023003 accuracy: 0.972656\n",
      "batch 2952: loss 0.040441 accuracy: 0.972660\n",
      "batch 2953: loss 0.021626 accuracy: 0.972669\n",
      "batch 2954: loss 0.014393 accuracy: 0.972677\n",
      "batch 2955: loss 0.041227 accuracy: 0.972681\n",
      "batch 2956: loss 0.033070 accuracy: 0.972689\n",
      "batch 2957: loss 0.051586 accuracy: 0.972693\n",
      "batch 2958: loss 0.013450 accuracy: 0.972702\n",
      "batch 2959: loss 0.020413 accuracy: 0.972711\n",
      "batch 2960: loss 0.038005 accuracy: 0.972717\n",
      "batch 2961: loss 0.022207 accuracy: 0.972726\n",
      "batch 2962: loss 0.012334 accuracy: 0.972735\n",
      "batch 2963: loss 0.028555 accuracy: 0.972741\n",
      "batch 2964: loss 0.012746 accuracy: 0.972750\n",
      "batch 2965: loss 0.024808 accuracy: 0.972756\n",
      "batch 2966: loss 0.018217 accuracy: 0.972765\n",
      "batch 2967: loss 0.027258 accuracy: 0.972773\n",
      "batch 2968: loss 0.025304 accuracy: 0.972780\n",
      "batch 2969: loss 0.025398 accuracy: 0.972788\n",
      "batch 2970: loss 0.021214 accuracy: 0.972794\n",
      "batch 2971: loss 0.020127 accuracy: 0.972799\n",
      "batch 2972: loss 0.036474 accuracy: 0.972805\n",
      "batch 2973: loss 0.012538 accuracy: 0.972814\n",
      "batch 2974: loss 0.016922 accuracy: 0.972824\n",
      "batch 2975: loss 0.045729 accuracy: 0.972829\n",
      "batch 2976: loss 0.015450 accuracy: 0.972837\n",
      "batch 2977: loss 0.021155 accuracy: 0.972844\n",
      "batch 2978: loss 0.030489 accuracy: 0.972852\n",
      "batch 2979: loss 0.011987 accuracy: 0.972861\n",
      "batch 2980: loss 0.021053 accuracy: 0.972868\n",
      "batch 2981: loss 0.039139 accuracy: 0.972874\n",
      "batch 2982: loss 0.015278 accuracy: 0.972883\n",
      "batch 2983: loss 0.016818 accuracy: 0.972890\n",
      "batch 2984: loss 0.025211 accuracy: 0.972898\n",
      "batch 2985: loss 0.019137 accuracy: 0.972905\n",
      "batch 2986: loss 0.015947 accuracy: 0.972914\n",
      "batch 2987: loss 0.043603 accuracy: 0.972920\n",
      "batch 2988: loss 0.012558 accuracy: 0.972927\n",
      "batch 2989: loss 0.009946 accuracy: 0.972936\n",
      "batch 2990: loss 0.017281 accuracy: 0.972942\n",
      "batch 2991: loss 0.019413 accuracy: 0.972950\n",
      "batch 2992: loss 0.015749 accuracy: 0.972959\n",
      "batch 2993: loss 0.015445 accuracy: 0.972968\n",
      "batch 2994: loss 0.029107 accuracy: 0.972973\n",
      "batch 2995: loss 0.033456 accuracy: 0.972977\n",
      "batch 2996: loss 0.033286 accuracy: 0.972985\n",
      "batch 2997: loss 0.016167 accuracy: 0.972994\n",
      "batch 2998: loss 0.010771 accuracy: 0.973003\n",
      "batch 2999: loss 0.024825 accuracy: 0.973010\n",
      "batch 3000: loss 0.033178 accuracy: 0.973016\n",
      "model saved to ./save\\ckpt-3000\n",
      "batch 3001: loss 0.018910 accuracy: 0.973023\n",
      "batch 3002: loss 0.031565 accuracy: 0.973030\n",
      "batch 3003: loss 0.015575 accuracy: 0.973039\n",
      "batch 3004: loss 0.034301 accuracy: 0.973043\n",
      "batch 3005: loss 0.034657 accuracy: 0.973051\n",
      "batch 3006: loss 0.013151 accuracy: 0.973060\n",
      "batch 3007: loss 0.022396 accuracy: 0.973065\n",
      "batch 3008: loss 0.022465 accuracy: 0.973072\n",
      "batch 3009: loss 0.008303 accuracy: 0.973081\n",
      "batch 3010: loss 0.028278 accuracy: 0.973089\n",
      "batch 3011: loss 0.014811 accuracy: 0.973096\n",
      "batch 3012: loss 0.054856 accuracy: 0.973100\n",
      "batch 3013: loss 0.022027 accuracy: 0.973105\n",
      "batch 3014: loss 0.021385 accuracy: 0.973114\n",
      "batch 3015: loss 0.043916 accuracy: 0.973120\n",
      "batch 3016: loss 0.031321 accuracy: 0.973126\n",
      "batch 3017: loss 0.015073 accuracy: 0.973135\n",
      "batch 3018: loss 0.019333 accuracy: 0.973142\n",
      "batch 3019: loss 0.019426 accuracy: 0.973151\n",
      "batch 3020: loss 0.014879 accuracy: 0.973158\n",
      "batch 3021: loss 0.029746 accuracy: 0.973163\n",
      "batch 3022: loss 0.016108 accuracy: 0.973171\n",
      "batch 3023: loss 0.040203 accuracy: 0.973173\n",
      "batch 3024: loss 0.009518 accuracy: 0.973180\n",
      "batch 3025: loss 0.029451 accuracy: 0.973187\n",
      "batch 3026: loss 0.022011 accuracy: 0.973195\n",
      "batch 3027: loss 0.027109 accuracy: 0.973202\n",
      "batch 3028: loss 0.026443 accuracy: 0.973209\n",
      "batch 3029: loss 0.024436 accuracy: 0.973215\n",
      "batch 3030: loss 0.019330 accuracy: 0.973222\n",
      "batch 3031: loss 0.022013 accuracy: 0.973229\n",
      "batch 3032: loss 0.010287 accuracy: 0.973238\n",
      "batch 3033: loss 0.031715 accuracy: 0.973243\n",
      "batch 3034: loss 0.030416 accuracy: 0.973249\n",
      "batch 3035: loss 0.026309 accuracy: 0.973256\n",
      "batch 3036: loss 0.019199 accuracy: 0.973263\n",
      "batch 3037: loss 0.009768 accuracy: 0.973272\n",
      "batch 3038: loss 0.027796 accuracy: 0.973277\n",
      "batch 3039: loss 0.046623 accuracy: 0.973283\n",
      "batch 3040: loss 0.019764 accuracy: 0.973288\n",
      "batch 3041: loss 0.017522 accuracy: 0.973297\n",
      "batch 3042: loss 0.072534 accuracy: 0.973303\n",
      "batch 3043: loss 0.018929 accuracy: 0.973308\n",
      "batch 3044: loss 0.013841 accuracy: 0.973317\n",
      "batch 3045: loss 0.012991 accuracy: 0.973324\n",
      "batch 3046: loss 0.022499 accuracy: 0.973333\n",
      "batch 3047: loss 0.017693 accuracy: 0.973342\n",
      "batch 3048: loss 0.014128 accuracy: 0.973350\n",
      "batch 3049: loss 0.017531 accuracy: 0.973357\n",
      "batch 3050: loss 0.033582 accuracy: 0.973364\n",
      "batch 3051: loss 0.013889 accuracy: 0.973373\n",
      "batch 3052: loss 0.016754 accuracy: 0.973380\n",
      "batch 3053: loss 0.015859 accuracy: 0.973387\n",
      "batch 3054: loss 0.012645 accuracy: 0.973394\n",
      "batch 3055: loss 0.017057 accuracy: 0.973401\n",
      "batch 3056: loss 0.026617 accuracy: 0.973407\n",
      "batch 3057: loss 0.013472 accuracy: 0.973414\n",
      "batch 3058: loss 0.096141 accuracy: 0.973421\n",
      "batch 3059: loss 0.011383 accuracy: 0.973428\n",
      "batch 3060: loss 0.019620 accuracy: 0.973435\n",
      "batch 3061: loss 0.033587 accuracy: 0.973441\n",
      "batch 3062: loss 0.020517 accuracy: 0.973448\n",
      "batch 3063: loss 0.025339 accuracy: 0.973455\n",
      "batch 3064: loss 0.025450 accuracy: 0.973460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3065: loss 0.019001 accuracy: 0.973467\n",
      "batch 3066: loss 0.028136 accuracy: 0.973472\n",
      "batch 3067: loss 0.021744 accuracy: 0.973478\n",
      "batch 3068: loss 0.024638 accuracy: 0.973485\n",
      "batch 3069: loss 0.022314 accuracy: 0.973492\n",
      "batch 3070: loss 0.026007 accuracy: 0.973497\n",
      "batch 3071: loss 0.043102 accuracy: 0.973503\n",
      "batch 3072: loss 0.011705 accuracy: 0.973511\n",
      "batch 3073: loss 0.027269 accuracy: 0.973517\n",
      "batch 3074: loss 0.017815 accuracy: 0.973524\n",
      "batch 3075: loss 0.038188 accuracy: 0.973529\n",
      "batch 3076: loss 0.006549 accuracy: 0.973538\n",
      "batch 3077: loss 0.036879 accuracy: 0.973545\n",
      "batch 3078: loss 0.014800 accuracy: 0.973553\n",
      "batch 3079: loss 0.028634 accuracy: 0.973557\n",
      "batch 3080: loss 0.010596 accuracy: 0.973565\n",
      "batch 3081: loss 0.014727 accuracy: 0.973572\n",
      "batch 3082: loss 0.027716 accuracy: 0.973578\n",
      "batch 3083: loss 0.020493 accuracy: 0.973585\n",
      "batch 3084: loss 0.018617 accuracy: 0.973593\n",
      "batch 3085: loss 0.038655 accuracy: 0.973600\n",
      "batch 3086: loss 0.007029 accuracy: 0.973609\n",
      "batch 3087: loss 0.017734 accuracy: 0.973616\n",
      "batch 3088: loss 0.019604 accuracy: 0.973623\n",
      "batch 3089: loss 0.016114 accuracy: 0.973631\n",
      "batch 3090: loss 0.026492 accuracy: 0.973640\n",
      "batch 3091: loss 0.007863 accuracy: 0.973648\n",
      "batch 3092: loss 0.048663 accuracy: 0.973653\n",
      "batch 3093: loss 0.014598 accuracy: 0.973662\n",
      "batch 3094: loss 0.013025 accuracy: 0.973669\n",
      "batch 3095: loss 0.016579 accuracy: 0.973676\n",
      "batch 3096: loss 0.021004 accuracy: 0.973683\n",
      "batch 3097: loss 0.018604 accuracy: 0.973689\n",
      "batch 3098: loss 0.051802 accuracy: 0.973693\n",
      "batch 3099: loss 0.010233 accuracy: 0.973702\n",
      "batch 3100: loss 0.033179 accuracy: 0.973707\n",
      "model saved to ./save\\ckpt-3100\n",
      "batch 3101: loss 0.016244 accuracy: 0.973714\n",
      "batch 3102: loss 0.017293 accuracy: 0.973721\n",
      "batch 3103: loss 0.019857 accuracy: 0.973727\n",
      "batch 3104: loss 0.029114 accuracy: 0.973733\n",
      "batch 3105: loss 0.026281 accuracy: 0.973738\n",
      "batch 3106: loss 0.021584 accuracy: 0.973743\n",
      "batch 3107: loss 0.027031 accuracy: 0.973747\n",
      "batch 3108: loss 0.008922 accuracy: 0.973755\n",
      "batch 3109: loss 0.016042 accuracy: 0.973762\n",
      "batch 3110: loss 0.007189 accuracy: 0.973770\n",
      "batch 3111: loss 0.014426 accuracy: 0.973779\n",
      "batch 3112: loss 0.052395 accuracy: 0.973781\n",
      "batch 3113: loss 0.018542 accuracy: 0.973789\n",
      "batch 3114: loss 0.009936 accuracy: 0.973798\n",
      "batch 3115: loss 0.009627 accuracy: 0.973806\n",
      "batch 3116: loss 0.033553 accuracy: 0.973810\n",
      "batch 3117: loss 0.015122 accuracy: 0.973818\n",
      "batch 3118: loss 0.039534 accuracy: 0.973823\n",
      "batch 3119: loss 0.019633 accuracy: 0.973830\n",
      "batch 3120: loss 0.025689 accuracy: 0.973837\n",
      "batch 3121: loss 0.026841 accuracy: 0.973844\n",
      "batch 3122: loss 0.033952 accuracy: 0.973849\n",
      "batch 3123: loss 0.009334 accuracy: 0.973857\n",
      "batch 3124: loss 0.011096 accuracy: 0.973864\n",
      "batch 3125: loss 0.009750 accuracy: 0.973872\n",
      "batch 3126: loss 0.005862 accuracy: 0.973881\n",
      "batch 3127: loss 0.011206 accuracy: 0.973887\n",
      "batch 3128: loss 0.025079 accuracy: 0.973893\n",
      "batch 3129: loss 0.019943 accuracy: 0.973898\n",
      "batch 3130: loss 0.045839 accuracy: 0.973904\n",
      "batch 3131: loss 0.010254 accuracy: 0.973911\n",
      "batch 3132: loss 0.018825 accuracy: 0.973920\n",
      "batch 3133: loss 0.018228 accuracy: 0.973925\n",
      "batch 3134: loss 0.025665 accuracy: 0.973930\n",
      "batch 3135: loss 0.020227 accuracy: 0.973937\n",
      "batch 3136: loss 0.032776 accuracy: 0.973943\n",
      "batch 3137: loss 0.010463 accuracy: 0.973952\n",
      "batch 3138: loss 0.025082 accuracy: 0.973957\n",
      "batch 3139: loss 0.021584 accuracy: 0.973963\n",
      "batch 3140: loss 0.036237 accuracy: 0.973967\n",
      "batch 3141: loss 0.011579 accuracy: 0.973975\n",
      "batch 3142: loss 0.027990 accuracy: 0.973980\n",
      "batch 3143: loss 0.024422 accuracy: 0.973987\n",
      "batch 3144: loss 0.027689 accuracy: 0.973994\n",
      "batch 3145: loss 0.015469 accuracy: 0.974002\n",
      "batch 3146: loss 0.012093 accuracy: 0.974010\n",
      "batch 3147: loss 0.062120 accuracy: 0.974010\n",
      "batch 3148: loss 0.029692 accuracy: 0.974017\n",
      "batch 3149: loss 0.054195 accuracy: 0.974021\n",
      "batch 3150: loss 0.012638 accuracy: 0.974029\n",
      "batch 3151: loss 0.016186 accuracy: 0.974037\n",
      "batch 3152: loss 0.017946 accuracy: 0.974044\n",
      "batch 3153: loss 0.018505 accuracy: 0.974050\n",
      "batch 3154: loss 0.057807 accuracy: 0.974054\n",
      "batch 3155: loss 0.022468 accuracy: 0.974059\n",
      "batch 3156: loss 0.024823 accuracy: 0.974066\n",
      "batch 3157: loss 0.024278 accuracy: 0.974072\n",
      "batch 3158: loss 0.018660 accuracy: 0.974079\n",
      "batch 3159: loss 0.100094 accuracy: 0.974082\n",
      "batch 3160: loss 0.020230 accuracy: 0.974087\n",
      "batch 3161: loss 0.042934 accuracy: 0.974089\n",
      "batch 3162: loss 0.020481 accuracy: 0.974096\n",
      "batch 3163: loss 0.011986 accuracy: 0.974104\n",
      "batch 3164: loss 0.027703 accuracy: 0.974109\n",
      "batch 3165: loss 0.013556 accuracy: 0.974116\n",
      "batch 3166: loss 0.015490 accuracy: 0.974124\n",
      "batch 3167: loss 0.009694 accuracy: 0.974132\n",
      "batch 3168: loss 0.009367 accuracy: 0.974140\n",
      "batch 3169: loss 0.010102 accuracy: 0.974147\n",
      "batch 3170: loss 0.027341 accuracy: 0.974153\n",
      "batch 3171: loss 0.009406 accuracy: 0.974161\n",
      "batch 3172: loss 0.044597 accuracy: 0.974166\n",
      "batch 3173: loss 0.018923 accuracy: 0.974175\n",
      "batch 3174: loss 0.014501 accuracy: 0.974183\n",
      "batch 3175: loss 0.029407 accuracy: 0.974189\n",
      "batch 3176: loss 0.012946 accuracy: 0.974197\n",
      "batch 3177: loss 0.016204 accuracy: 0.974205\n",
      "batch 3178: loss 0.016605 accuracy: 0.974212\n",
      "batch 3179: loss 0.023764 accuracy: 0.974217\n",
      "batch 3180: loss 0.027873 accuracy: 0.974223\n",
      "batch 3181: loss 0.023718 accuracy: 0.974229\n",
      "batch 3182: loss 0.027798 accuracy: 0.974235\n",
      "batch 3183: loss 0.018984 accuracy: 0.974241\n",
      "batch 3184: loss 0.017320 accuracy: 0.974248\n",
      "batch 3185: loss 0.028767 accuracy: 0.974255\n",
      "batch 3186: loss 0.035237 accuracy: 0.974259\n",
      "batch 3187: loss 0.019875 accuracy: 0.974266\n",
      "batch 3188: loss 0.010264 accuracy: 0.974274\n",
      "batch 3189: loss 0.010821 accuracy: 0.974282\n",
      "batch 3190: loss 0.029173 accuracy: 0.974289\n",
      "batch 3191: loss 0.026097 accuracy: 0.974294\n",
      "batch 3192: loss 0.011068 accuracy: 0.974302\n",
      "batch 3193: loss 0.043965 accuracy: 0.974307\n",
      "batch 3194: loss 0.010339 accuracy: 0.974315\n",
      "batch 3195: loss 0.015782 accuracy: 0.974321\n",
      "batch 3196: loss 0.015344 accuracy: 0.974328\n",
      "batch 3197: loss 0.008230 accuracy: 0.974336\n",
      "batch 3198: loss 0.009939 accuracy: 0.974344\n",
      "batch 3199: loss 0.015606 accuracy: 0.974352\n",
      "batch 3200: loss 0.018118 accuracy: 0.974356\n",
      "model saved to ./save\\ckpt-3200\n",
      "batch 3201: loss 0.043644 accuracy: 0.974361\n",
      "batch 3202: loss 0.014051 accuracy: 0.974368\n",
      "batch 3203: loss 0.008639 accuracy: 0.974376\n",
      "batch 3204: loss 0.023360 accuracy: 0.974381\n",
      "batch 3205: loss 0.039423 accuracy: 0.974384\n",
      "batch 3206: loss 0.007426 accuracy: 0.974392\n",
      "batch 3207: loss 0.017994 accuracy: 0.974398\n",
      "batch 3208: loss 0.012905 accuracy: 0.974406\n",
      "batch 3209: loss 0.012413 accuracy: 0.974414\n",
      "batch 3210: loss 0.107382 accuracy: 0.974419\n",
      "batch 3211: loss 0.022312 accuracy: 0.974426\n",
      "batch 3212: loss 0.029452 accuracy: 0.974432\n",
      "batch 3213: loss 0.028951 accuracy: 0.974437\n",
      "batch 3214: loss 0.012012 accuracy: 0.974445\n",
      "batch 3215: loss 0.015174 accuracy: 0.974451\n",
      "batch 3216: loss 0.008211 accuracy: 0.974459\n",
      "batch 3217: loss 0.018100 accuracy: 0.974467\n",
      "batch 3218: loss 0.018914 accuracy: 0.974473\n",
      "batch 3219: loss 0.021481 accuracy: 0.974478\n",
      "batch 3220: loss 0.031508 accuracy: 0.974483\n",
      "batch 3221: loss 0.023760 accuracy: 0.974488\n",
      "batch 3222: loss 0.014092 accuracy: 0.974494\n",
      "batch 3223: loss 0.015313 accuracy: 0.974502\n",
      "batch 3224: loss 0.019817 accuracy: 0.974510\n",
      "batch 3225: loss 0.019946 accuracy: 0.974516\n",
      "batch 3226: loss 0.007727 accuracy: 0.974524\n",
      "batch 3227: loss 0.019716 accuracy: 0.974531\n",
      "batch 3228: loss 0.011512 accuracy: 0.974537\n",
      "batch 3229: loss 0.008947 accuracy: 0.974545\n",
      "batch 3230: loss 0.065106 accuracy: 0.974550\n",
      "batch 3231: loss 0.013511 accuracy: 0.974558\n",
      "batch 3232: loss 0.009741 accuracy: 0.974565\n",
      "batch 3233: loss 0.024878 accuracy: 0.974570\n",
      "batch 3234: loss 0.010575 accuracy: 0.974578\n",
      "batch 3235: loss 0.048964 accuracy: 0.974581\n",
      "batch 3236: loss 0.022985 accuracy: 0.974586\n",
      "batch 3237: loss 0.020093 accuracy: 0.974592\n",
      "batch 3238: loss 0.036535 accuracy: 0.974594\n",
      "batch 3239: loss 0.007132 accuracy: 0.974602\n",
      "batch 3240: loss 0.021632 accuracy: 0.974608\n",
      "batch 3241: loss 0.025083 accuracy: 0.974614\n",
      "batch 3242: loss 0.030253 accuracy: 0.974619\n",
      "batch 3243: loss 0.012544 accuracy: 0.974627\n",
      "batch 3244: loss 0.014110 accuracy: 0.974635\n",
      "batch 3245: loss 0.016600 accuracy: 0.974640\n",
      "batch 3246: loss 0.028873 accuracy: 0.974646\n",
      "batch 3247: loss 0.020548 accuracy: 0.974652\n",
      "batch 3248: loss 0.016368 accuracy: 0.974658\n",
      "batch 3249: loss 0.018642 accuracy: 0.974665\n",
      "batch 3250: loss 0.010832 accuracy: 0.974672\n",
      "batch 3251: loss 0.008797 accuracy: 0.974680\n",
      "batch 3252: loss 0.015715 accuracy: 0.974686\n",
      "batch 3253: loss 0.010639 accuracy: 0.974694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3254: loss 0.018005 accuracy: 0.974700\n",
      "batch 3255: loss 0.021908 accuracy: 0.974707\n",
      "batch 3256: loss 0.030646 accuracy: 0.974711\n",
      "batch 3257: loss 0.039006 accuracy: 0.974716\n",
      "batch 3258: loss 0.024803 accuracy: 0.974722\n",
      "batch 3259: loss 0.022466 accuracy: 0.974727\n",
      "batch 3260: loss 0.009404 accuracy: 0.974735\n",
      "batch 3261: loss 0.035222 accuracy: 0.974739\n",
      "batch 3262: loss 0.038185 accuracy: 0.974743\n",
      "batch 3263: loss 0.013922 accuracy: 0.974750\n",
      "batch 3264: loss 0.010341 accuracy: 0.974756\n",
      "batch 3265: loss 0.015801 accuracy: 0.974763\n",
      "batch 3266: loss 0.016752 accuracy: 0.974769\n",
      "batch 3267: loss 0.014378 accuracy: 0.974777\n",
      "batch 3268: loss 0.010739 accuracy: 0.974784\n",
      "batch 3269: loss 0.042142 accuracy: 0.974787\n",
      "batch 3270: loss 0.012289 accuracy: 0.974795\n",
      "batch 3271: loss 0.021491 accuracy: 0.974803\n",
      "batch 3272: loss 0.017252 accuracy: 0.974809\n",
      "batch 3273: loss 0.026904 accuracy: 0.974814\n",
      "batch 3274: loss 0.018493 accuracy: 0.974821\n",
      "batch 3275: loss 0.018966 accuracy: 0.974828\n",
      "batch 3276: loss 0.009611 accuracy: 0.974835\n",
      "batch 3277: loss 0.011551 accuracy: 0.974843\n",
      "batch 3278: loss 0.039679 accuracy: 0.974847\n",
      "batch 3279: loss 0.010405 accuracy: 0.974855\n",
      "batch 3280: loss 0.034061 accuracy: 0.974861\n",
      "batch 3281: loss 0.013245 accuracy: 0.974869\n",
      "batch 3282: loss 0.019591 accuracy: 0.974875\n",
      "batch 3283: loss 0.014131 accuracy: 0.974883\n",
      "batch 3284: loss 0.009816 accuracy: 0.974890\n",
      "batch 3285: loss 0.011443 accuracy: 0.974897\n",
      "batch 3286: loss 0.015139 accuracy: 0.974903\n",
      "batch 3287: loss 0.008080 accuracy: 0.974910\n",
      "batch 3288: loss 0.024101 accuracy: 0.974915\n",
      "batch 3289: loss 0.011465 accuracy: 0.974922\n",
      "batch 3290: loss 0.018583 accuracy: 0.974930\n",
      "batch 3291: loss 0.008918 accuracy: 0.974938\n",
      "batch 3292: loss 0.010357 accuracy: 0.974945\n",
      "batch 3293: loss 0.014249 accuracy: 0.974951\n",
      "batch 3294: loss 0.013794 accuracy: 0.974958\n",
      "batch 3295: loss 0.022865 accuracy: 0.974961\n",
      "batch 3296: loss 0.019832 accuracy: 0.974967\n",
      "batch 3297: loss 0.013264 accuracy: 0.974974\n",
      "batch 3298: loss 0.010020 accuracy: 0.974982\n",
      "batch 3299: loss 0.014865 accuracy: 0.974988\n",
      "batch 3300: loss 0.017787 accuracy: 0.974994\n",
      "model saved to ./save\\ckpt-3300\n",
      "batch 3301: loss 0.011667 accuracy: 0.975000\n",
      "batch 3302: loss 0.012896 accuracy: 0.975006\n",
      "batch 3303: loss 0.028976 accuracy: 0.975011\n",
      "batch 3304: loss 0.039112 accuracy: 0.975012\n",
      "batch 3305: loss 0.009799 accuracy: 0.975020\n",
      "batch 3306: loss 0.016283 accuracy: 0.975026\n",
      "batch 3307: loss 0.017399 accuracy: 0.975032\n",
      "batch 3308: loss 0.007274 accuracy: 0.975039\n",
      "batch 3309: loss 0.018621 accuracy: 0.975045\n",
      "batch 3310: loss 0.059034 accuracy: 0.975051\n",
      "batch 3311: loss 0.027638 accuracy: 0.975056\n",
      "batch 3312: loss 0.019883 accuracy: 0.975059\n",
      "batch 3313: loss 0.055514 accuracy: 0.975062\n",
      "batch 3314: loss 0.029791 accuracy: 0.975068\n",
      "batch 3315: loss 0.014666 accuracy: 0.975075\n",
      "batch 3316: loss 0.019440 accuracy: 0.975083\n",
      "batch 3317: loss 0.009924 accuracy: 0.975090\n",
      "batch 3318: loss 0.007793 accuracy: 0.975098\n",
      "batch 3319: loss 0.042910 accuracy: 0.975104\n",
      "batch 3320: loss 0.013037 accuracy: 0.975111\n",
      "batch 3321: loss 0.011190 accuracy: 0.975119\n",
      "batch 3322: loss 0.015129 accuracy: 0.975125\n",
      "batch 3323: loss 0.014213 accuracy: 0.975131\n",
      "batch 3324: loss 0.033870 accuracy: 0.975137\n",
      "batch 3325: loss 0.010629 accuracy: 0.975144\n",
      "batch 3326: loss 0.015486 accuracy: 0.975150\n",
      "batch 3327: loss 0.020786 accuracy: 0.975156\n",
      "batch 3328: loss 0.029407 accuracy: 0.975161\n",
      "batch 3329: loss 0.006590 accuracy: 0.975168\n",
      "batch 3330: loss 0.015600 accuracy: 0.975176\n",
      "batch 3331: loss 0.034573 accuracy: 0.975182\n",
      "batch 3332: loss 0.007220 accuracy: 0.975189\n",
      "batch 3333: loss 0.033523 accuracy: 0.975192\n",
      "batch 3334: loss 0.025967 accuracy: 0.975196\n",
      "batch 3335: loss 0.022169 accuracy: 0.975201\n",
      "batch 3336: loss 0.031394 accuracy: 0.975207\n",
      "batch 3337: loss 0.014898 accuracy: 0.975213\n",
      "batch 3338: loss 0.017865 accuracy: 0.975220\n",
      "batch 3339: loss 0.014910 accuracy: 0.975226\n",
      "batch 3340: loss 0.032961 accuracy: 0.975230\n",
      "batch 3341: loss 0.023469 accuracy: 0.975238\n",
      "batch 3342: loss 0.021047 accuracy: 0.975244\n",
      "batch 3343: loss 0.022103 accuracy: 0.975250\n",
      "batch 3344: loss 0.019184 accuracy: 0.975254\n",
      "batch 3345: loss 0.028202 accuracy: 0.975260\n",
      "batch 3346: loss 0.010210 accuracy: 0.975267\n",
      "batch 3347: loss 0.011344 accuracy: 0.975275\n",
      "batch 3348: loss 0.014116 accuracy: 0.975282\n",
      "batch 3349: loss 0.023378 accuracy: 0.975287\n",
      "batch 3350: loss 0.009336 accuracy: 0.975294\n",
      "batch 3351: loss 0.012156 accuracy: 0.975301\n",
      "batch 3352: loss 0.019374 accuracy: 0.975309\n",
      "batch 3353: loss 0.010482 accuracy: 0.975316\n",
      "batch 3354: loss 0.008570 accuracy: 0.975323\n",
      "batch 3355: loss 0.019283 accuracy: 0.975329\n",
      "batch 3356: loss 0.012765 accuracy: 0.975337\n",
      "batch 3357: loss 0.014310 accuracy: 0.975344\n",
      "batch 3358: loss 0.010110 accuracy: 0.975351\n",
      "batch 3359: loss 0.014173 accuracy: 0.975357\n",
      "batch 3360: loss 0.028596 accuracy: 0.975362\n",
      "batch 3361: loss 0.023967 accuracy: 0.975366\n",
      "batch 3362: loss 0.021809 accuracy: 0.975372\n",
      "batch 3363: loss 0.019944 accuracy: 0.975378\n",
      "batch 3364: loss 0.015879 accuracy: 0.975385\n",
      "batch 3365: loss 0.009195 accuracy: 0.975392\n",
      "batch 3366: loss 0.012885 accuracy: 0.975398\n",
      "batch 3367: loss 0.011652 accuracy: 0.975405\n",
      "batch 3368: loss 0.018190 accuracy: 0.975411\n",
      "batch 3369: loss 0.013514 accuracy: 0.975418\n",
      "batch 3370: loss 0.015177 accuracy: 0.975424\n",
      "batch 3371: loss 0.025007 accuracy: 0.975430\n",
      "batch 3372: loss 0.022640 accuracy: 0.975433\n",
      "batch 3373: loss 0.019771 accuracy: 0.975437\n",
      "batch 3374: loss 0.020933 accuracy: 0.975441\n",
      "batch 3375: loss 0.013545 accuracy: 0.975447\n",
      "batch 3376: loss 0.021801 accuracy: 0.975453\n",
      "batch 3377: loss 0.018004 accuracy: 0.975459\n",
      "batch 3378: loss 0.009455 accuracy: 0.975466\n",
      "batch 3379: loss 0.018419 accuracy: 0.975472\n",
      "batch 3380: loss 0.011264 accuracy: 0.975478\n",
      "batch 3381: loss 0.016520 accuracy: 0.975483\n",
      "batch 3382: loss 0.018010 accuracy: 0.975489\n",
      "batch 3383: loss 0.039271 accuracy: 0.975495\n",
      "batch 3384: loss 0.023929 accuracy: 0.975501\n",
      "batch 3385: loss 0.045717 accuracy: 0.975505\n",
      "batch 3386: loss 0.010121 accuracy: 0.975512\n",
      "batch 3387: loss 0.028682 accuracy: 0.975517\n",
      "batch 3388: loss 0.004659 accuracy: 0.975524\n",
      "batch 3389: loss 0.008712 accuracy: 0.975531\n",
      "batch 3390: loss 0.006185 accuracy: 0.975538\n",
      "batch 3391: loss 0.022014 accuracy: 0.975544\n",
      "batch 3392: loss 0.011179 accuracy: 0.975551\n",
      "batch 3393: loss 0.023164 accuracy: 0.975557\n",
      "batch 3394: loss 0.012998 accuracy: 0.975564\n",
      "batch 3395: loss 0.027626 accuracy: 0.975570\n",
      "batch 3396: loss 0.010619 accuracy: 0.975577\n",
      "batch 3397: loss 0.006800 accuracy: 0.975584\n",
      "batch 3398: loss 0.014661 accuracy: 0.975590\n",
      "batch 3399: loss 0.006345 accuracy: 0.975597\n",
      "batch 3400: loss 0.012882 accuracy: 0.975604\n",
      "model saved to ./save\\ckpt-3400\n",
      "batch 3401: loss 0.021401 accuracy: 0.975611\n",
      "batch 3402: loss 0.033167 accuracy: 0.975616\n",
      "batch 3403: loss 0.034380 accuracy: 0.975620\n",
      "batch 3404: loss 0.011511 accuracy: 0.975627\n",
      "batch 3405: loss 0.099133 accuracy: 0.975630\n",
      "batch 3406: loss 0.016018 accuracy: 0.975637\n",
      "batch 3407: loss 0.011354 accuracy: 0.975644\n",
      "batch 3408: loss 0.008202 accuracy: 0.975651\n",
      "batch 3409: loss 0.043640 accuracy: 0.975655\n",
      "batch 3410: loss 0.009181 accuracy: 0.975663\n",
      "batch 3411: loss 0.032236 accuracy: 0.975668\n",
      "batch 3412: loss 0.015891 accuracy: 0.975675\n",
      "batch 3413: loss 0.009684 accuracy: 0.975682\n",
      "batch 3414: loss 0.022579 accuracy: 0.975688\n",
      "batch 3415: loss 0.007764 accuracy: 0.975695\n",
      "batch 3416: loss 0.008699 accuracy: 0.975702\n",
      "batch 3417: loss 0.006974 accuracy: 0.975709\n",
      "batch 3418: loss 0.011633 accuracy: 0.975715\n",
      "batch 3419: loss 0.014730 accuracy: 0.975722\n",
      "batch 3420: loss 0.022557 accuracy: 0.975726\n",
      "batch 3421: loss 0.018015 accuracy: 0.975732\n",
      "batch 3422: loss 0.017359 accuracy: 0.975738\n",
      "batch 3423: loss 0.037986 accuracy: 0.975740\n",
      "batch 3424: loss 0.013177 accuracy: 0.975747\n",
      "batch 3425: loss 0.018576 accuracy: 0.975753\n",
      "batch 3426: loss 0.028497 accuracy: 0.975757\n",
      "batch 3427: loss 0.053025 accuracy: 0.975761\n",
      "batch 3428: loss 0.030570 accuracy: 0.975766\n",
      "batch 3429: loss 0.018115 accuracy: 0.975770\n",
      "batch 3430: loss 0.009123 accuracy: 0.975777\n",
      "batch 3431: loss 0.018541 accuracy: 0.975782\n",
      "batch 3432: loss 0.021825 accuracy: 0.975789\n",
      "batch 3433: loss 0.020433 accuracy: 0.975796\n",
      "batch 3434: loss 0.009712 accuracy: 0.975803\n",
      "batch 3435: loss 0.056803 accuracy: 0.975808\n",
      "batch 3436: loss 0.007242 accuracy: 0.975815\n",
      "batch 3437: loss 0.006845 accuracy: 0.975822\n",
      "batch 3438: loss 0.013975 accuracy: 0.975827\n",
      "batch 3439: loss 0.033467 accuracy: 0.975831\n",
      "batch 3440: loss 0.015185 accuracy: 0.975837\n",
      "batch 3441: loss 0.018925 accuracy: 0.975843\n",
      "batch 3442: loss 0.046461 accuracy: 0.975847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3443: loss 0.010525 accuracy: 0.975854\n",
      "batch 3444: loss 0.008924 accuracy: 0.975861\n",
      "batch 3445: loss 0.021748 accuracy: 0.975866\n",
      "batch 3446: loss 0.009614 accuracy: 0.975873\n",
      "batch 3447: loss 0.019475 accuracy: 0.975879\n",
      "batch 3448: loss 0.021351 accuracy: 0.975883\n",
      "batch 3449: loss 0.022988 accuracy: 0.975888\n",
      "batch 3450: loss 0.032617 accuracy: 0.975894\n",
      "batch 3451: loss 0.014721 accuracy: 0.975901\n",
      "batch 3452: loss 0.038509 accuracy: 0.975904\n",
      "batch 3453: loss 0.032275 accuracy: 0.975909\n",
      "batch 3454: loss 0.012698 accuracy: 0.975915\n",
      "batch 3455: loss 0.040460 accuracy: 0.975917\n",
      "batch 3456: loss 0.009152 accuracy: 0.975924\n",
      "batch 3457: loss 0.020662 accuracy: 0.975928\n",
      "batch 3458: loss 0.009930 accuracy: 0.975935\n",
      "batch 3459: loss 0.017159 accuracy: 0.975941\n",
      "batch 3460: loss 0.017039 accuracy: 0.975948\n",
      "batch 3461: loss 0.027537 accuracy: 0.975953\n",
      "batch 3462: loss 0.021539 accuracy: 0.975957\n",
      "batch 3463: loss 0.032931 accuracy: 0.975961\n",
      "batch 3464: loss 0.015645 accuracy: 0.975968\n",
      "batch 3465: loss 0.025004 accuracy: 0.975974\n",
      "batch 3466: loss 0.031102 accuracy: 0.975978\n",
      "batch 3467: loss 0.017245 accuracy: 0.975983\n",
      "batch 3468: loss 0.011303 accuracy: 0.975990\n",
      "batch 3469: loss 0.012037 accuracy: 0.975997\n",
      "batch 3470: loss 0.011948 accuracy: 0.976003\n",
      "batch 3471: loss 0.027538 accuracy: 0.976008\n",
      "batch 3472: loss 0.019167 accuracy: 0.976014\n",
      "batch 3473: loss 0.005514 accuracy: 0.976020\n",
      "batch 3474: loss 0.014680 accuracy: 0.976026\n",
      "batch 3475: loss 0.015812 accuracy: 0.976031\n",
      "batch 3476: loss 0.010453 accuracy: 0.976038\n",
      "batch 3477: loss 0.023727 accuracy: 0.976044\n",
      "batch 3478: loss 0.005859 accuracy: 0.976051\n",
      "batch 3479: loss 0.054141 accuracy: 0.976056\n",
      "batch 3480: loss 0.010261 accuracy: 0.976063\n",
      "batch 3481: loss 0.007929 accuracy: 0.976070\n",
      "batch 3482: loss 0.014720 accuracy: 0.976075\n",
      "batch 3483: loss 0.012531 accuracy: 0.976081\n",
      "batch 3484: loss 0.021893 accuracy: 0.976085\n",
      "batch 3485: loss 0.016624 accuracy: 0.976092\n",
      "batch 3486: loss 0.008313 accuracy: 0.976098\n",
      "batch 3487: loss 0.021490 accuracy: 0.976105\n",
      "batch 3488: loss 0.012180 accuracy: 0.976112\n",
      "batch 3489: loss 0.037156 accuracy: 0.976116\n",
      "batch 3490: loss 0.013884 accuracy: 0.976123\n",
      "batch 3491: loss 0.015871 accuracy: 0.976130\n",
      "batch 3492: loss 0.011692 accuracy: 0.976137\n",
      "batch 3493: loss 0.016240 accuracy: 0.976142\n",
      "batch 3494: loss 0.011753 accuracy: 0.976149\n",
      "batch 3495: loss 0.008004 accuracy: 0.976156\n",
      "batch 3496: loss 0.012735 accuracy: 0.976161\n",
      "batch 3497: loss 0.022865 accuracy: 0.976165\n",
      "batch 3498: loss 0.012238 accuracy: 0.976172\n",
      "batch 3499: loss 0.009928 accuracy: 0.976179\n",
      "batch 3500: loss 0.006931 accuracy: 0.976185\n",
      "model saved to ./save\\ckpt-3500\n",
      "batch 3501: loss 0.009713 accuracy: 0.976192\n",
      "batch 3502: loss 0.017909 accuracy: 0.976199\n",
      "batch 3503: loss 0.014393 accuracy: 0.976203\n",
      "batch 3504: loss 0.025132 accuracy: 0.976208\n",
      "batch 3505: loss 0.007495 accuracy: 0.976215\n",
      "batch 3506: loss 0.008290 accuracy: 0.976222\n",
      "batch 3507: loss 0.015624 accuracy: 0.976229\n",
      "batch 3508: loss 0.015837 accuracy: 0.976234\n",
      "batch 3509: loss 0.023990 accuracy: 0.976238\n",
      "batch 3510: loss 0.016122 accuracy: 0.976242\n",
      "batch 3511: loss 0.017608 accuracy: 0.976249\n",
      "batch 3512: loss 0.009496 accuracy: 0.976255\n",
      "batch 3513: loss 0.016239 accuracy: 0.976261\n",
      "batch 3514: loss 0.032487 accuracy: 0.976262\n",
      "batch 3515: loss 0.005128 accuracy: 0.976268\n",
      "batch 3516: loss 0.013669 accuracy: 0.976275\n",
      "batch 3517: loss 0.074937 accuracy: 0.976278\n",
      "batch 3518: loss 0.016704 accuracy: 0.976283\n",
      "batch 3519: loss 0.023921 accuracy: 0.976287\n",
      "batch 3520: loss 0.022039 accuracy: 0.976292\n",
      "batch 3521: loss 0.019065 accuracy: 0.976299\n",
      "batch 3522: loss 0.025744 accuracy: 0.976303\n",
      "batch 3523: loss 0.020056 accuracy: 0.976308\n",
      "batch 3524: loss 0.009856 accuracy: 0.976315\n",
      "batch 3525: loss 0.029778 accuracy: 0.976317\n",
      "batch 3526: loss 0.030978 accuracy: 0.976321\n",
      "batch 3527: loss 0.014803 accuracy: 0.976327\n",
      "batch 3528: loss 0.013736 accuracy: 0.976333\n",
      "batch 3529: loss 0.040938 accuracy: 0.976336\n",
      "batch 3530: loss 0.018165 accuracy: 0.976341\n",
      "batch 3531: loss 0.015378 accuracy: 0.976346\n",
      "batch 3532: loss 0.012614 accuracy: 0.976353\n",
      "batch 3533: loss 0.016386 accuracy: 0.976358\n",
      "batch 3534: loss 0.015107 accuracy: 0.976365\n",
      "batch 3535: loss 0.019867 accuracy: 0.976370\n",
      "batch 3536: loss 0.018961 accuracy: 0.976374\n",
      "batch 3537: loss 0.029539 accuracy: 0.976378\n",
      "batch 3538: loss 0.043202 accuracy: 0.976379\n",
      "batch 3539: loss 0.026122 accuracy: 0.976383\n",
      "batch 3540: loss 0.024612 accuracy: 0.976388\n",
      "batch 3541: loss 0.035899 accuracy: 0.976390\n",
      "batch 3542: loss 0.043689 accuracy: 0.976391\n",
      "batch 3543: loss 0.012795 accuracy: 0.976397\n",
      "batch 3544: loss 0.015868 accuracy: 0.976403\n",
      "batch 3545: loss 0.014708 accuracy: 0.976410\n",
      "batch 3546: loss 0.016402 accuracy: 0.976415\n",
      "batch 3547: loss 0.025174 accuracy: 0.976421\n",
      "batch 3548: loss 0.017130 accuracy: 0.976426\n",
      "batch 3549: loss 0.022926 accuracy: 0.976430\n",
      "batch 3550: loss 0.035218 accuracy: 0.976433\n",
      "batch 3551: loss 0.006663 accuracy: 0.976440\n",
      "batch 3552: loss 0.024794 accuracy: 0.976444\n",
      "batch 3553: loss 0.009778 accuracy: 0.976451\n",
      "batch 3554: loss 0.013705 accuracy: 0.976456\n",
      "batch 3555: loss 0.018296 accuracy: 0.976461\n",
      "batch 3556: loss 0.018796 accuracy: 0.976466\n",
      "batch 3557: loss 0.017415 accuracy: 0.976471\n",
      "batch 3558: loss 0.009183 accuracy: 0.976478\n",
      "batch 3559: loss 0.012337 accuracy: 0.976485\n",
      "batch 3560: loss 0.013406 accuracy: 0.976491\n",
      "batch 3561: loss 0.037185 accuracy: 0.976495\n",
      "batch 3562: loss 0.013039 accuracy: 0.976502\n",
      "batch 3563: loss 0.009871 accuracy: 0.976508\n",
      "batch 3564: loss 0.016596 accuracy: 0.976513\n",
      "batch 3565: loss 0.009718 accuracy: 0.976520\n",
      "batch 3566: loss 0.016429 accuracy: 0.976525\n",
      "batch 3567: loss 0.005939 accuracy: 0.976532\n",
      "batch 3568: loss 0.028258 accuracy: 0.976535\n",
      "batch 3569: loss 0.047563 accuracy: 0.976538\n",
      "batch 3570: loss 0.023902 accuracy: 0.976543\n",
      "batch 3571: loss 0.007989 accuracy: 0.976550\n",
      "batch 3572: loss 0.021884 accuracy: 0.976553\n",
      "batch 3573: loss 0.009854 accuracy: 0.976560\n",
      "batch 3574: loss 0.029026 accuracy: 0.976565\n",
      "batch 3575: loss 0.027004 accuracy: 0.976570\n",
      "batch 3576: loss 0.017383 accuracy: 0.976575\n",
      "batch 3577: loss 0.043793 accuracy: 0.976575\n",
      "batch 3578: loss 0.013543 accuracy: 0.976580\n",
      "batch 3579: loss 0.014268 accuracy: 0.976587\n",
      "batch 3580: loss 0.013533 accuracy: 0.976593\n",
      "batch 3581: loss 0.015611 accuracy: 0.976598\n",
      "batch 3582: loss 0.009017 accuracy: 0.976605\n",
      "batch 3583: loss 0.014612 accuracy: 0.976611\n",
      "batch 3584: loss 0.030628 accuracy: 0.976616\n",
      "batch 3585: loss 0.015125 accuracy: 0.976622\n",
      "batch 3586: loss 0.015441 accuracy: 0.976627\n",
      "batch 3587: loss 0.018505 accuracy: 0.976633\n",
      "batch 3588: loss 0.024695 accuracy: 0.976638\n",
      "batch 3589: loss 0.008300 accuracy: 0.976645\n",
      "batch 3590: loss 0.009548 accuracy: 0.976651\n",
      "batch 3591: loss 0.013680 accuracy: 0.976656\n",
      "batch 3592: loss 0.020829 accuracy: 0.976660\n",
      "batch 3593: loss 0.008171 accuracy: 0.976667\n",
      "batch 3594: loss 0.015860 accuracy: 0.976672\n",
      "batch 3595: loss 0.060731 accuracy: 0.976675\n",
      "batch 3596: loss 0.041343 accuracy: 0.976678\n",
      "batch 3597: loss 0.030947 accuracy: 0.976683\n",
      "batch 3598: loss 0.019073 accuracy: 0.976688\n",
      "batch 3599: loss 0.007841 accuracy: 0.976694\n",
      "batch 3600: loss 0.028022 accuracy: 0.976698\n",
      "model saved to ./save\\ckpt-3600\n",
      "batch 3601: loss 0.043714 accuracy: 0.976702\n",
      "batch 3602: loss 0.047424 accuracy: 0.976706\n",
      "batch 3603: loss 0.014625 accuracy: 0.976711\n",
      "batch 3604: loss 0.010661 accuracy: 0.976717\n",
      "batch 3605: loss 0.026493 accuracy: 0.976722\n",
      "batch 3606: loss 0.016127 accuracy: 0.976729\n",
      "batch 3607: loss 0.033075 accuracy: 0.976732\n",
      "batch 3608: loss 0.022040 accuracy: 0.976737\n",
      "batch 3609: loss 0.019144 accuracy: 0.976742\n",
      "batch 3610: loss 0.022085 accuracy: 0.976747\n",
      "batch 3611: loss 0.014969 accuracy: 0.976753\n",
      "batch 3612: loss 0.051054 accuracy: 0.976758\n",
      "batch 3613: loss 0.010795 accuracy: 0.976764\n",
      "batch 3614: loss 0.022394 accuracy: 0.976768\n",
      "batch 3615: loss 0.027182 accuracy: 0.976773\n",
      "batch 3616: loss 0.016680 accuracy: 0.976779\n",
      "batch 3617: loss 0.008693 accuracy: 0.976786\n",
      "batch 3618: loss 0.018887 accuracy: 0.976791\n",
      "batch 3619: loss 0.020333 accuracy: 0.976796\n",
      "batch 3620: loss 0.012443 accuracy: 0.976802\n",
      "batch 3621: loss 0.032152 accuracy: 0.976806\n",
      "batch 3622: loss 0.017439 accuracy: 0.976811\n",
      "batch 3623: loss 0.016203 accuracy: 0.976817\n",
      "batch 3624: loss 0.007927 accuracy: 0.976823\n",
      "batch 3625: loss 0.007230 accuracy: 0.976830\n",
      "batch 3626: loss 0.021772 accuracy: 0.976833\n",
      "batch 3627: loss 0.029017 accuracy: 0.976836\n",
      "batch 3628: loss 0.018571 accuracy: 0.976841\n",
      "batch 3629: loss 0.057324 accuracy: 0.976842\n",
      "batch 3630: loss 0.024777 accuracy: 0.976845\n",
      "batch 3631: loss 0.011254 accuracy: 0.976852\n",
      "batch 3632: loss 0.007189 accuracy: 0.976858\n",
      "batch 3633: loss 0.024017 accuracy: 0.976863\n",
      "batch 3634: loss 0.012690 accuracy: 0.976869\n",
      "batch 3635: loss 0.008030 accuracy: 0.976876\n",
      "batch 3636: loss 0.017876 accuracy: 0.976881\n",
      "batch 3637: loss 0.012396 accuracy: 0.976886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3638: loss 0.028174 accuracy: 0.976889\n",
      "batch 3639: loss 0.020308 accuracy: 0.976894\n",
      "batch 3640: loss 0.024506 accuracy: 0.976899\n",
      "batch 3641: loss 0.035576 accuracy: 0.976901\n",
      "batch 3642: loss 0.018676 accuracy: 0.976906\n",
      "batch 3643: loss 0.038249 accuracy: 0.976910\n",
      "batch 3644: loss 0.037447 accuracy: 0.976912\n",
      "batch 3645: loss 0.018098 accuracy: 0.976917\n",
      "batch 3646: loss 0.018449 accuracy: 0.976922\n",
      "batch 3647: loss 0.015552 accuracy: 0.976928\n",
      "batch 3648: loss 0.032454 accuracy: 0.976932\n",
      "batch 3649: loss 0.016285 accuracy: 0.976937\n",
      "batch 3650: loss 0.014319 accuracy: 0.976942\n",
      "batch 3651: loss 0.037322 accuracy: 0.976944\n",
      "batch 3652: loss 0.019601 accuracy: 0.976949\n",
      "batch 3653: loss 0.095238 accuracy: 0.976954\n",
      "batch 3654: loss 0.013720 accuracy: 0.976959\n",
      "batch 3655: loss 0.020522 accuracy: 0.976964\n",
      "batch 3656: loss 0.027080 accuracy: 0.976969\n",
      "batch 3657: loss 0.033092 accuracy: 0.976974\n",
      "batch 3658: loss 0.009465 accuracy: 0.976980\n",
      "batch 3659: loss 0.008306 accuracy: 0.976986\n",
      "batch 3660: loss 0.011679 accuracy: 0.976993\n",
      "batch 3661: loss 0.062629 accuracy: 0.976998\n",
      "batch 3662: loss 0.036026 accuracy: 0.977000\n",
      "batch 3663: loss 0.015777 accuracy: 0.977005\n",
      "batch 3664: loss 0.012924 accuracy: 0.977010\n",
      "batch 3665: loss 0.027421 accuracy: 0.977013\n",
      "batch 3666: loss 0.017173 accuracy: 0.977018\n",
      "batch 3667: loss 0.049172 accuracy: 0.977022\n",
      "batch 3668: loss 0.009735 accuracy: 0.977028\n",
      "batch 3669: loss 0.014194 accuracy: 0.977034\n",
      "batch 3670: loss 0.012408 accuracy: 0.977040\n",
      "batch 3671: loss 0.004825 accuracy: 0.977047\n",
      "batch 3672: loss 0.024079 accuracy: 0.977051\n",
      "batch 3673: loss 0.035069 accuracy: 0.977052\n",
      "batch 3674: loss 0.034368 accuracy: 0.977056\n",
      "batch 3675: loss 0.018303 accuracy: 0.977061\n",
      "batch 3676: loss 0.011325 accuracy: 0.977067\n",
      "batch 3677: loss 0.016286 accuracy: 0.977073\n",
      "batch 3678: loss 0.014157 accuracy: 0.977078\n",
      "batch 3679: loss 0.015169 accuracy: 0.977083\n",
      "batch 3680: loss 0.017403 accuracy: 0.977088\n",
      "batch 3681: loss 0.021800 accuracy: 0.977093\n",
      "batch 3682: loss 0.029362 accuracy: 0.977096\n",
      "batch 3683: loss 0.004855 accuracy: 0.977102\n",
      "batch 3684: loss 0.050877 accuracy: 0.977107\n",
      "batch 3685: loss 0.021412 accuracy: 0.977111\n",
      "batch 3686: loss 0.047816 accuracy: 0.977114\n",
      "batch 3687: loss 0.022325 accuracy: 0.977118\n",
      "batch 3688: loss 0.022388 accuracy: 0.977124\n",
      "batch 3689: loss 0.018788 accuracy: 0.977129\n",
      "batch 3690: loss 0.012728 accuracy: 0.977134\n",
      "batch 3691: loss 0.046780 accuracy: 0.977137\n",
      "batch 3692: loss 0.012059 accuracy: 0.977142\n",
      "batch 3693: loss 0.013755 accuracy: 0.977148\n",
      "batch 3694: loss 0.024929 accuracy: 0.977152\n",
      "batch 3695: loss 0.011994 accuracy: 0.977156\n",
      "batch 3696: loss 0.007845 accuracy: 0.977163\n",
      "batch 3697: loss 0.036324 accuracy: 0.977167\n",
      "batch 3698: loss 0.027676 accuracy: 0.977172\n",
      "batch 3699: loss 0.027632 accuracy: 0.977177\n",
      "batch 3700: loss 0.031789 accuracy: 0.977182\n",
      "model saved to ./save\\ckpt-3700\n",
      "batch 3701: loss 0.030243 accuracy: 0.977184\n",
      "batch 3702: loss 0.016889 accuracy: 0.977189\n",
      "batch 3703: loss 0.017199 accuracy: 0.977194\n",
      "batch 3704: loss 0.016051 accuracy: 0.977198\n",
      "batch 3705: loss 0.015757 accuracy: 0.977202\n",
      "batch 3706: loss 0.017950 accuracy: 0.977205\n",
      "batch 3707: loss 0.009382 accuracy: 0.977211\n",
      "batch 3708: loss 0.006294 accuracy: 0.977218\n",
      "batch 3709: loss 0.016634 accuracy: 0.977222\n",
      "batch 3710: loss 0.004603 accuracy: 0.977229\n",
      "batch 3711: loss 0.008042 accuracy: 0.977235\n",
      "batch 3712: loss 0.016983 accuracy: 0.977239\n",
      "batch 3713: loss 0.023812 accuracy: 0.977243\n",
      "batch 3714: loss 0.021172 accuracy: 0.977248\n",
      "batch 3715: loss 0.012702 accuracy: 0.977252\n",
      "batch 3716: loss 0.016259 accuracy: 0.977259\n",
      "batch 3717: loss 0.017077 accuracy: 0.977263\n",
      "batch 3718: loss 0.018041 accuracy: 0.977268\n",
      "batch 3719: loss 0.013859 accuracy: 0.977274\n",
      "batch 3720: loss 0.012569 accuracy: 0.977280\n",
      "batch 3721: loss 0.013705 accuracy: 0.977286\n",
      "batch 3722: loss 0.019559 accuracy: 0.977290\n",
      "batch 3723: loss 0.025682 accuracy: 0.977292\n",
      "batch 3724: loss 0.016003 accuracy: 0.977298\n",
      "batch 3725: loss 0.022754 accuracy: 0.977301\n",
      "batch 3726: loss 0.011734 accuracy: 0.977307\n",
      "batch 3727: loss 0.007159 accuracy: 0.977314\n",
      "batch 3728: loss 0.008534 accuracy: 0.977320\n",
      "batch 3729: loss 0.012415 accuracy: 0.977324\n",
      "batch 3730: loss 0.025118 accuracy: 0.977329\n",
      "batch 3731: loss 0.017792 accuracy: 0.977334\n",
      "batch 3732: loss 0.018716 accuracy: 0.977339\n",
      "batch 3733: loss 0.023062 accuracy: 0.977342\n",
      "batch 3734: loss 0.022851 accuracy: 0.977345\n",
      "batch 3735: loss 0.015700 accuracy: 0.977350\n",
      "batch 3736: loss 0.032423 accuracy: 0.977355\n",
      "batch 3737: loss 0.004548 accuracy: 0.977361\n",
      "batch 3738: loss 0.018952 accuracy: 0.977366\n",
      "batch 3739: loss 0.022974 accuracy: 0.977369\n",
      "batch 3740: loss 0.015616 accuracy: 0.977374\n",
      "batch 3741: loss 0.032064 accuracy: 0.977376\n",
      "batch 3742: loss 0.028656 accuracy: 0.977379\n",
      "batch 3743: loss 0.042838 accuracy: 0.977384\n",
      "batch 3744: loss 0.016281 accuracy: 0.977390\n",
      "batch 3745: loss 0.021243 accuracy: 0.977392\n",
      "batch 3746: loss 0.024656 accuracy: 0.977397\n",
      "batch 3747: loss 0.009147 accuracy: 0.977403\n",
      "batch 3748: loss 0.012156 accuracy: 0.977407\n",
      "batch 3749: loss 0.030333 accuracy: 0.977411\n",
      "batch 3750: loss 0.012824 accuracy: 0.977417\n",
      "batch 3751: loss 0.019346 accuracy: 0.977421\n",
      "batch 3752: loss 0.017334 accuracy: 0.977426\n",
      "batch 3753: loss 0.008320 accuracy: 0.977432\n",
      "batch 3754: loss 0.044105 accuracy: 0.977435\n",
      "batch 3755: loss 0.023494 accuracy: 0.977440\n",
      "batch 3756: loss 0.011637 accuracy: 0.977446\n",
      "batch 3757: loss 0.022314 accuracy: 0.977451\n",
      "batch 3758: loss 0.036562 accuracy: 0.977454\n",
      "batch 3759: loss 0.029758 accuracy: 0.977459\n",
      "batch 3760: loss 0.011147 accuracy: 0.977465\n",
      "batch 3761: loss 0.010738 accuracy: 0.977471\n",
      "batch 3762: loss 0.011901 accuracy: 0.977477\n",
      "batch 3763: loss 0.010548 accuracy: 0.977483\n",
      "batch 3764: loss 0.031124 accuracy: 0.977486\n",
      "batch 3765: loss 0.011993 accuracy: 0.977492\n",
      "batch 3766: loss 0.020138 accuracy: 0.977497\n",
      "batch 3767: loss 0.012973 accuracy: 0.977503\n",
      "batch 3768: loss 0.026855 accuracy: 0.977507\n",
      "batch 3769: loss 0.006699 accuracy: 0.977513\n",
      "batch 3770: loss 0.010198 accuracy: 0.977518\n",
      "batch 3771: loss 0.014199 accuracy: 0.977524\n",
      "batch 3772: loss 0.014202 accuracy: 0.977530\n",
      "batch 3773: loss 0.006282 accuracy: 0.977536\n",
      "batch 3774: loss 0.025788 accuracy: 0.977540\n",
      "batch 3775: loss 0.011747 accuracy: 0.977546\n",
      "batch 3776: loss 0.012965 accuracy: 0.977551\n",
      "batch 3777: loss 0.030561 accuracy: 0.977554\n",
      "batch 3778: loss 0.027916 accuracy: 0.977559\n",
      "batch 3779: loss 0.016496 accuracy: 0.977564\n",
      "batch 3780: loss 0.007516 accuracy: 0.977569\n",
      "batch 3781: loss 0.012685 accuracy: 0.977575\n",
      "batch 3782: loss 0.024806 accuracy: 0.977580\n",
      "batch 3783: loss 0.025835 accuracy: 0.977583\n",
      "batch 3784: loss 0.014670 accuracy: 0.977589\n",
      "batch 3785: loss 0.019757 accuracy: 0.977594\n",
      "batch 3786: loss 0.009455 accuracy: 0.977598\n",
      "batch 3787: loss 0.019560 accuracy: 0.977603\n",
      "batch 3788: loss 0.007597 accuracy: 0.977609\n",
      "batch 3789: loss 0.030946 accuracy: 0.977613\n",
      "batch 3790: loss 0.006196 accuracy: 0.977619\n",
      "batch 3791: loss 0.024144 accuracy: 0.977624\n",
      "batch 3792: loss 0.027540 accuracy: 0.977627\n",
      "batch 3793: loss 0.014792 accuracy: 0.977633\n",
      "batch 3794: loss 0.021126 accuracy: 0.977638\n",
      "batch 3795: loss 0.010315 accuracy: 0.977644\n",
      "batch 3796: loss 0.014032 accuracy: 0.977648\n",
      "batch 3797: loss 0.026629 accuracy: 0.977653\n",
      "batch 3798: loss 0.015791 accuracy: 0.977657\n",
      "batch 3799: loss 0.012036 accuracy: 0.977663\n",
      "batch 3800: loss 0.016291 accuracy: 0.977669\n",
      "model saved to ./save\\ckpt-3800\n",
      "batch 3801: loss 0.015480 accuracy: 0.977674\n",
      "batch 3802: loss 0.007961 accuracy: 0.977679\n",
      "batch 3803: loss 0.006769 accuracy: 0.977685\n",
      "batch 3804: loss 0.006625 accuracy: 0.977691\n",
      "batch 3805: loss 0.017405 accuracy: 0.977696\n",
      "batch 3806: loss 0.011497 accuracy: 0.977700\n",
      "batch 3807: loss 0.013922 accuracy: 0.977705\n",
      "batch 3808: loss 0.018577 accuracy: 0.977709\n",
      "batch 3809: loss 0.023796 accuracy: 0.977713\n",
      "batch 3810: loss 0.014332 accuracy: 0.977717\n",
      "batch 3811: loss 0.008383 accuracy: 0.977723\n",
      "batch 3812: loss 0.006449 accuracy: 0.977729\n",
      "batch 3813: loss 0.009783 accuracy: 0.977735\n",
      "batch 3814: loss 0.020702 accuracy: 0.977739\n",
      "batch 3815: loss 0.011570 accuracy: 0.977745\n",
      "batch 3816: loss 0.023165 accuracy: 0.977748\n",
      "batch 3817: loss 0.028559 accuracy: 0.977750\n",
      "batch 3818: loss 0.009532 accuracy: 0.977756\n",
      "batch 3819: loss 0.022951 accuracy: 0.977760\n",
      "batch 3820: loss 0.021167 accuracy: 0.977765\n",
      "batch 3821: loss 0.018512 accuracy: 0.977769\n",
      "batch 3822: loss 0.011043 accuracy: 0.977775\n",
      "batch 3823: loss 0.033616 accuracy: 0.977776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3824: loss 0.017343 accuracy: 0.977780\n",
      "batch 3825: loss 0.009269 accuracy: 0.977786\n",
      "batch 3826: loss 0.016592 accuracy: 0.977791\n",
      "batch 3827: loss 0.014749 accuracy: 0.977796\n",
      "batch 3828: loss 0.017730 accuracy: 0.977801\n",
      "batch 3829: loss 0.006836 accuracy: 0.977807\n",
      "batch 3830: loss 0.008988 accuracy: 0.977813\n",
      "batch 3831: loss 0.043090 accuracy: 0.977814\n",
      "batch 3832: loss 0.017535 accuracy: 0.977819\n",
      "batch 3833: loss 0.037310 accuracy: 0.977822\n",
      "batch 3834: loss 0.019157 accuracy: 0.977827\n",
      "batch 3835: loss 0.012200 accuracy: 0.977832\n",
      "batch 3836: loss 0.012841 accuracy: 0.977838\n",
      "batch 3837: loss 0.029519 accuracy: 0.977841\n",
      "batch 3838: loss 0.017158 accuracy: 0.977846\n",
      "batch 3839: loss 0.009143 accuracy: 0.977852\n",
      "batch 3840: loss 0.029923 accuracy: 0.977855\n",
      "batch 3841: loss 0.009830 accuracy: 0.977861\n",
      "batch 3842: loss 0.016229 accuracy: 0.977865\n",
      "batch 3843: loss 0.013516 accuracy: 0.977869\n",
      "batch 3844: loss 0.030518 accuracy: 0.977874\n",
      "batch 3845: loss 0.008496 accuracy: 0.977880\n",
      "batch 3846: loss 0.011055 accuracy: 0.977885\n",
      "batch 3847: loss 0.009086 accuracy: 0.977891\n",
      "batch 3848: loss 0.025834 accuracy: 0.977896\n",
      "batch 3849: loss 0.012392 accuracy: 0.977901\n",
      "batch 3850: loss 0.014773 accuracy: 0.977907\n",
      "batch 3851: loss 0.016159 accuracy: 0.977913\n",
      "batch 3852: loss 0.026498 accuracy: 0.977917\n",
      "batch 3853: loss 0.015807 accuracy: 0.977923\n",
      "batch 3854: loss 0.018023 accuracy: 0.977927\n",
      "batch 3855: loss 0.022076 accuracy: 0.977929\n",
      "batch 3856: loss 0.022480 accuracy: 0.977934\n",
      "batch 3857: loss 0.010615 accuracy: 0.977939\n",
      "batch 3858: loss 0.010195 accuracy: 0.977945\n",
      "batch 3859: loss 0.027517 accuracy: 0.977948\n",
      "batch 3860: loss 0.021525 accuracy: 0.977953\n",
      "batch 3861: loss 0.009064 accuracy: 0.977958\n",
      "batch 3862: loss 0.019832 accuracy: 0.977963\n",
      "batch 3863: loss 0.024393 accuracy: 0.977967\n",
      "batch 3864: loss 0.024160 accuracy: 0.977972\n",
      "batch 3865: loss 0.015090 accuracy: 0.977977\n",
      "batch 3866: loss 0.016549 accuracy: 0.977983\n",
      "batch 3867: loss 0.017880 accuracy: 0.977986\n",
      "batch 3868: loss 0.012820 accuracy: 0.977990\n",
      "batch 3869: loss 0.018875 accuracy: 0.977995\n",
      "batch 3870: loss 0.011780 accuracy: 0.978001\n",
      "batch 3871: loss 0.009936 accuracy: 0.978006\n",
      "batch 3872: loss 0.018346 accuracy: 0.978011\n",
      "batch 3873: loss 0.006959 accuracy: 0.978016\n",
      "batch 3874: loss 0.008380 accuracy: 0.978022\n",
      "batch 3875: loss 0.011132 accuracy: 0.978028\n",
      "batch 3876: loss 0.026158 accuracy: 0.978029\n",
      "batch 3877: loss 0.011119 accuracy: 0.978034\n",
      "batch 3878: loss 0.022528 accuracy: 0.978037\n",
      "batch 3879: loss 0.017440 accuracy: 0.978041\n",
      "batch 3880: loss 0.013754 accuracy: 0.978046\n",
      "batch 3881: loss 0.018431 accuracy: 0.978051\n",
      "batch 3882: loss 0.006516 accuracy: 0.978057\n",
      "batch 3883: loss 0.016761 accuracy: 0.978061\n",
      "batch 3884: loss 0.015282 accuracy: 0.978066\n",
      "batch 3885: loss 0.015291 accuracy: 0.978070\n",
      "batch 3886: loss 0.013909 accuracy: 0.978076\n",
      "batch 3887: loss 0.008448 accuracy: 0.978081\n",
      "batch 3888: loss 0.016915 accuracy: 0.978086\n",
      "batch 3889: loss 0.006146 accuracy: 0.978091\n",
      "batch 3890: loss 0.008505 accuracy: 0.978097\n",
      "batch 3891: loss 0.007196 accuracy: 0.978103\n",
      "batch 3892: loss 0.012698 accuracy: 0.978107\n",
      "batch 3893: loss 0.010260 accuracy: 0.978112\n",
      "batch 3894: loss 0.033106 accuracy: 0.978117\n",
      "batch 3895: loss 0.014223 accuracy: 0.978122\n",
      "batch 3896: loss 0.013378 accuracy: 0.978128\n",
      "batch 3897: loss 0.015924 accuracy: 0.978132\n",
      "batch 3898: loss 0.012457 accuracy: 0.978138\n",
      "batch 3899: loss 0.020150 accuracy: 0.978141\n",
      "batch 3900: loss 0.026563 accuracy: 0.978145\n",
      "model saved to ./save\\ckpt-3900\n",
      "batch 3901: loss 0.010883 accuracy: 0.978151\n",
      "batch 3902: loss 0.014985 accuracy: 0.978157\n",
      "batch 3903: loss 0.022796 accuracy: 0.978160\n",
      "batch 3904: loss 0.013644 accuracy: 0.978165\n",
      "batch 3905: loss 0.011800 accuracy: 0.978171\n",
      "batch 3906: loss 0.025473 accuracy: 0.978174\n",
      "batch 3907: loss 0.010923 accuracy: 0.978178\n",
      "batch 3908: loss 0.004828 accuracy: 0.978184\n",
      "batch 3909: loss 0.028467 accuracy: 0.978188\n",
      "batch 3910: loss 0.011545 accuracy: 0.978194\n",
      "batch 3911: loss 0.023356 accuracy: 0.978198\n",
      "batch 3912: loss 0.030676 accuracy: 0.978201\n",
      "batch 3913: loss 0.005194 accuracy: 0.978206\n",
      "batch 3914: loss 0.014403 accuracy: 0.978209\n",
      "batch 3915: loss 0.006274 accuracy: 0.978215\n",
      "batch 3916: loss 0.007311 accuracy: 0.978221\n",
      "batch 3917: loss 0.005647 accuracy: 0.978226\n",
      "batch 3918: loss 0.005686 accuracy: 0.978232\n",
      "batch 3919: loss 0.009020 accuracy: 0.978236\n",
      "batch 3920: loss 0.016862 accuracy: 0.978240\n",
      "batch 3921: loss 0.010827 accuracy: 0.978245\n",
      "batch 3922: loss 0.019594 accuracy: 0.978249\n",
      "batch 3923: loss 0.021588 accuracy: 0.978252\n",
      "batch 3924: loss 0.016226 accuracy: 0.978256\n",
      "batch 3925: loss 0.028289 accuracy: 0.978260\n",
      "batch 3926: loss 0.003877 accuracy: 0.978266\n",
      "batch 3927: loss 0.008593 accuracy: 0.978271\n",
      "batch 3928: loss 0.007477 accuracy: 0.978277\n",
      "batch 3929: loss 0.010383 accuracy: 0.978282\n",
      "batch 3930: loss 0.012381 accuracy: 0.978287\n",
      "batch 3931: loss 0.006392 accuracy: 0.978292\n",
      "batch 3932: loss 0.008769 accuracy: 0.978298\n",
      "batch 3933: loss 0.005619 accuracy: 0.978303\n",
      "batch 3934: loss 0.010505 accuracy: 0.978309\n",
      "batch 3935: loss 0.009797 accuracy: 0.978314\n",
      "batch 3936: loss 0.031018 accuracy: 0.978316\n",
      "batch 3937: loss 0.005921 accuracy: 0.978321\n",
      "batch 3938: loss 0.023216 accuracy: 0.978326\n",
      "batch 3939: loss 0.017212 accuracy: 0.978330\n",
      "batch 3940: loss 0.016502 accuracy: 0.978334\n",
      "batch 3941: loss 0.006229 accuracy: 0.978340\n",
      "batch 3942: loss 0.011180 accuracy: 0.978345\n",
      "batch 3943: loss 0.006508 accuracy: 0.978351\n",
      "batch 3944: loss 0.016120 accuracy: 0.978355\n",
      "batch 3945: loss 0.010776 accuracy: 0.978360\n",
      "batch 3946: loss 0.007676 accuracy: 0.978366\n",
      "batch 3947: loss 0.010823 accuracy: 0.978370\n",
      "batch 3948: loss 0.013865 accuracy: 0.978376\n",
      "batch 3949: loss 0.014156 accuracy: 0.978380\n",
      "batch 3950: loss 0.014775 accuracy: 0.978384\n",
      "batch 3951: loss 0.020111 accuracy: 0.978388\n",
      "batch 3952: loss 0.003351 accuracy: 0.978394\n",
      "batch 3953: loss 0.003509 accuracy: 0.978399\n",
      "batch 3954: loss 0.094657 accuracy: 0.978402\n",
      "batch 3955: loss 0.016250 accuracy: 0.978406\n",
      "batch 3956: loss 0.007975 accuracy: 0.978412\n",
      "batch 3957: loss 0.010011 accuracy: 0.978417\n",
      "batch 3958: loss 0.052975 accuracy: 0.978419\n",
      "batch 3959: loss 0.005102 accuracy: 0.978424\n",
      "batch 3960: loss 0.006203 accuracy: 0.978430\n",
      "batch 3961: loss 0.048864 accuracy: 0.978434\n",
      "batch 3962: loss 0.019367 accuracy: 0.978439\n",
      "batch 3963: loss 0.016689 accuracy: 0.978444\n",
      "batch 3964: loss 0.016145 accuracy: 0.978448\n",
      "batch 3965: loss 0.012641 accuracy: 0.978453\n",
      "batch 3966: loss 0.009454 accuracy: 0.978459\n",
      "batch 3967: loss 0.010823 accuracy: 0.978464\n",
      "batch 3968: loss 0.010511 accuracy: 0.978469\n",
      "batch 3969: loss 0.004517 accuracy: 0.978475\n",
      "batch 3970: loss 0.011437 accuracy: 0.978480\n",
      "batch 3971: loss 0.011134 accuracy: 0.978484\n",
      "batch 3972: loss 0.007014 accuracy: 0.978490\n",
      "batch 3973: loss 0.006985 accuracy: 0.978495\n",
      "batch 3974: loss 0.005103 accuracy: 0.978501\n",
      "batch 3975: loss 0.017396 accuracy: 0.978506\n",
      "batch 3976: loss 0.022163 accuracy: 0.978509\n",
      "batch 3977: loss 0.023244 accuracy: 0.978513\n",
      "batch 3978: loss 0.005580 accuracy: 0.978518\n",
      "batch 3979: loss 0.024833 accuracy: 0.978523\n",
      "batch 3980: loss 0.013625 accuracy: 0.978528\n",
      "batch 3981: loss 0.008334 accuracy: 0.978533\n",
      "batch 3982: loss 0.016941 accuracy: 0.978538\n",
      "batch 3983: loss 0.018011 accuracy: 0.978543\n",
      "batch 3984: loss 0.007870 accuracy: 0.978548\n",
      "batch 3985: loss 0.011596 accuracy: 0.978552\n",
      "batch 3986: loss 0.012111 accuracy: 0.978557\n",
      "batch 3987: loss 0.006430 accuracy: 0.978562\n",
      "batch 3988: loss 0.006901 accuracy: 0.978567\n",
      "batch 3989: loss 0.055300 accuracy: 0.978571\n",
      "batch 3990: loss 0.027851 accuracy: 0.978574\n",
      "batch 3991: loss 0.013035 accuracy: 0.978578\n",
      "batch 3992: loss 0.007163 accuracy: 0.978584\n",
      "batch 3993: loss 0.009157 accuracy: 0.978589\n",
      "batch 3994: loss 0.025539 accuracy: 0.978593\n",
      "batch 3995: loss 0.009745 accuracy: 0.978599\n",
      "batch 3996: loss 0.011958 accuracy: 0.978603\n",
      "batch 3997: loss 0.007898 accuracy: 0.978608\n",
      "batch 3998: loss 0.013024 accuracy: 0.978612\n",
      "batch 3999: loss 0.009808 accuracy: 0.978617\n",
      "batch 4000: loss 0.017403 accuracy: 0.978622\n",
      "model saved to ./save\\ckpt-4000\n",
      "batch 4001: loss 0.008159 accuracy: 0.978627\n",
      "batch 4002: loss 0.011921 accuracy: 0.978631\n",
      "batch 4003: loss 0.018599 accuracy: 0.978635\n",
      "batch 4004: loss 0.007606 accuracy: 0.978640\n",
      "batch 4005: loss 0.017649 accuracy: 0.978645\n",
      "batch 4006: loss 0.010965 accuracy: 0.978650\n",
      "batch 4007: loss 0.019731 accuracy: 0.978653\n",
      "batch 4008: loss 0.014417 accuracy: 0.978658\n",
      "batch 4009: loss 0.023266 accuracy: 0.978660\n",
      "batch 4010: loss 0.008253 accuracy: 0.978665\n",
      "batch 4011: loss 0.007409 accuracy: 0.978670\n",
      "batch 4012: loss 0.038301 accuracy: 0.978673\n",
      "batch 4013: loss 0.004530 accuracy: 0.978678\n",
      "batch 4014: loss 0.016371 accuracy: 0.978684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4015: loss 0.012373 accuracy: 0.978689\n",
      "batch 4016: loss 0.036573 accuracy: 0.978689\n",
      "batch 4017: loss 0.012950 accuracy: 0.978695\n",
      "batch 4018: loss 0.017312 accuracy: 0.978699\n",
      "batch 4019: loss 0.009932 accuracy: 0.978704\n",
      "batch 4020: loss 0.009156 accuracy: 0.978709\n",
      "batch 4021: loss 0.008806 accuracy: 0.978715\n",
      "batch 4022: loss 0.027096 accuracy: 0.978717\n",
      "batch 4023: loss 0.012164 accuracy: 0.978721\n",
      "batch 4024: loss 0.006799 accuracy: 0.978727\n",
      "batch 4025: loss 0.014685 accuracy: 0.978732\n",
      "batch 4026: loss 0.021185 accuracy: 0.978736\n",
      "batch 4027: loss 0.017801 accuracy: 0.978740\n",
      "batch 4028: loss 0.028091 accuracy: 0.978742\n",
      "batch 4029: loss 0.015094 accuracy: 0.978744\n",
      "batch 4030: loss 0.017887 accuracy: 0.978748\n",
      "batch 4031: loss 0.018487 accuracy: 0.978752\n",
      "batch 4032: loss 0.009551 accuracy: 0.978758\n",
      "batch 4033: loss 0.010880 accuracy: 0.978762\n",
      "batch 4034: loss 0.009376 accuracy: 0.978767\n",
      "batch 4035: loss 0.011615 accuracy: 0.978772\n",
      "batch 4036: loss 0.018507 accuracy: 0.978778\n",
      "batch 4037: loss 0.007048 accuracy: 0.978783\n",
      "batch 4038: loss 0.010046 accuracy: 0.978787\n",
      "batch 4039: loss 0.011372 accuracy: 0.978792\n",
      "batch 4040: loss 0.002757 accuracy: 0.978797\n",
      "batch 4041: loss 0.015388 accuracy: 0.978803\n",
      "batch 4042: loss 0.022820 accuracy: 0.978805\n",
      "batch 4043: loss 0.017553 accuracy: 0.978811\n",
      "batch 4044: loss 0.013151 accuracy: 0.978815\n",
      "batch 4045: loss 0.004219 accuracy: 0.978820\n",
      "batch 4046: loss 0.007043 accuracy: 0.978825\n",
      "batch 4047: loss 0.014453 accuracy: 0.978829\n",
      "batch 4048: loss 0.014998 accuracy: 0.978834\n",
      "batch 4049: loss 0.013584 accuracy: 0.978838\n",
      "batch 4050: loss 0.008330 accuracy: 0.978844\n",
      "batch 4051: loss 0.014677 accuracy: 0.978849\n",
      "batch 4052: loss 0.008030 accuracy: 0.978854\n",
      "batch 4053: loss 0.008174 accuracy: 0.978859\n",
      "batch 4054: loss 0.034139 accuracy: 0.978862\n",
      "batch 4055: loss 0.007072 accuracy: 0.978867\n",
      "batch 4056: loss 0.007956 accuracy: 0.978872\n",
      "batch 4057: loss 0.012706 accuracy: 0.978878\n",
      "batch 4058: loss 0.009871 accuracy: 0.978881\n",
      "batch 4059: loss 0.022853 accuracy: 0.978884\n",
      "batch 4060: loss 0.014562 accuracy: 0.978889\n",
      "batch 4061: loss 0.009908 accuracy: 0.978895\n",
      "batch 4062: loss 0.019802 accuracy: 0.978900\n",
      "batch 4063: loss 0.048286 accuracy: 0.978901\n",
      "batch 4064: loss 0.005934 accuracy: 0.978907\n",
      "batch 4065: loss 0.020165 accuracy: 0.978909\n",
      "batch 4066: loss 0.028039 accuracy: 0.978913\n",
      "batch 4067: loss 0.014172 accuracy: 0.978918\n",
      "batch 4068: loss 0.012131 accuracy: 0.978924\n",
      "batch 4069: loss 0.013816 accuracy: 0.978927\n",
      "batch 4070: loss 0.004891 accuracy: 0.978933\n",
      "batch 4071: loss 0.008846 accuracy: 0.978938\n",
      "batch 4072: loss 0.007875 accuracy: 0.978943\n",
      "batch 4073: loss 0.010577 accuracy: 0.978948\n",
      "batch 4074: loss 0.010471 accuracy: 0.978953\n",
      "batch 4075: loss 0.011077 accuracy: 0.978959\n",
      "batch 4076: loss 0.026536 accuracy: 0.978962\n",
      "batch 4077: loss 0.017019 accuracy: 0.978966\n",
      "batch 4078: loss 0.005567 accuracy: 0.978972\n",
      "batch 4079: loss 0.018442 accuracy: 0.978974\n",
      "batch 4080: loss 0.027962 accuracy: 0.978976\n",
      "batch 4081: loss 0.012141 accuracy: 0.978980\n",
      "batch 4082: loss 0.010704 accuracy: 0.978984\n",
      "batch 4083: loss 0.007010 accuracy: 0.978989\n",
      "batch 4084: loss 0.008280 accuracy: 0.978994\n",
      "batch 4085: loss 0.026438 accuracy: 0.978998\n",
      "batch 4086: loss 0.006614 accuracy: 0.979003\n",
      "batch 4087: loss 0.010805 accuracy: 0.979007\n",
      "batch 4088: loss 0.011589 accuracy: 0.979012\n",
      "batch 4089: loss 0.022426 accuracy: 0.979015\n",
      "batch 4090: loss 0.008485 accuracy: 0.979020\n",
      "batch 4091: loss 0.018941 accuracy: 0.979023\n",
      "batch 4092: loss 0.009969 accuracy: 0.979028\n",
      "batch 4093: loss 0.013736 accuracy: 0.979033\n",
      "batch 4094: loss 0.009506 accuracy: 0.979038\n",
      "batch 4095: loss 0.006135 accuracy: 0.979043\n",
      "batch 4096: loss 0.033861 accuracy: 0.979046\n",
      "batch 4097: loss 0.018850 accuracy: 0.979048\n",
      "batch 4098: loss 0.023083 accuracy: 0.979052\n",
      "batch 4099: loss 0.007092 accuracy: 0.979057\n",
      "batch 4100: loss 0.014700 accuracy: 0.979061\n",
      "model saved to ./save\\ckpt-4100\n",
      "batch 4101: loss 0.007453 accuracy: 0.979066\n",
      "batch 4102: loss 0.013319 accuracy: 0.979070\n",
      "batch 4103: loss 0.011965 accuracy: 0.979074\n",
      "batch 4104: loss 0.035290 accuracy: 0.979078\n",
      "batch 4105: loss 0.013822 accuracy: 0.979083\n",
      "batch 4106: loss 0.015930 accuracy: 0.979088\n",
      "batch 4107: loss 0.020663 accuracy: 0.979092\n",
      "batch 4108: loss 0.020163 accuracy: 0.979095\n",
      "batch 4109: loss 0.005428 accuracy: 0.979100\n",
      "batch 4110: loss 0.004407 accuracy: 0.979105\n",
      "batch 4111: loss 0.013525 accuracy: 0.979109\n",
      "batch 4112: loss 0.013882 accuracy: 0.979114\n",
      "batch 4113: loss 0.005485 accuracy: 0.979119\n",
      "batch 4114: loss 0.016869 accuracy: 0.979123\n",
      "batch 4115: loss 0.027123 accuracy: 0.979127\n",
      "batch 4116: loss 0.009995 accuracy: 0.979132\n",
      "batch 4117: loss 0.015077 accuracy: 0.979136\n",
      "batch 4118: loss 0.008698 accuracy: 0.979141\n",
      "batch 4119: loss 0.009269 accuracy: 0.979146\n",
      "batch 4120: loss 0.026936 accuracy: 0.979149\n",
      "batch 4121: loss 0.012810 accuracy: 0.979153\n",
      "batch 4122: loss 0.013841 accuracy: 0.979157\n",
      "batch 4123: loss 0.020080 accuracy: 0.979161\n",
      "batch 4124: loss 0.015842 accuracy: 0.979165\n",
      "batch 4125: loss 0.004041 accuracy: 0.979170\n",
      "batch 4126: loss 0.022462 accuracy: 0.979173\n",
      "batch 4127: loss 0.011413 accuracy: 0.979176\n",
      "batch 4128: loss 0.022379 accuracy: 0.979179\n",
      "batch 4129: loss 0.012136 accuracy: 0.979184\n",
      "batch 4130: loss 0.013337 accuracy: 0.979188\n",
      "batch 4131: loss 0.014127 accuracy: 0.979192\n",
      "batch 4132: loss 0.006056 accuracy: 0.979197\n",
      "batch 4133: loss 0.014432 accuracy: 0.979201\n",
      "batch 4134: loss 0.007828 accuracy: 0.979206\n",
      "batch 4135: loss 0.005111 accuracy: 0.979211\n",
      "batch 4136: loss 0.012889 accuracy: 0.979214\n",
      "batch 4137: loss 0.012812 accuracy: 0.979219\n",
      "batch 4138: loss 0.005140 accuracy: 0.979224\n",
      "batch 4139: loss 0.014263 accuracy: 0.979228\n",
      "batch 4140: loss 0.007746 accuracy: 0.979233\n",
      "batch 4141: loss 0.025797 accuracy: 0.979236\n",
      "batch 4142: loss 0.045558 accuracy: 0.979240\n",
      "batch 4143: loss 0.004985 accuracy: 0.979245\n",
      "batch 4144: loss 0.005105 accuracy: 0.979250\n",
      "batch 4145: loss 0.010154 accuracy: 0.979255\n",
      "batch 4146: loss 0.006901 accuracy: 0.979260\n",
      "batch 4147: loss 0.010235 accuracy: 0.979265\n",
      "batch 4148: loss 0.033676 accuracy: 0.979266\n",
      "batch 4149: loss 0.012948 accuracy: 0.979271\n",
      "batch 4150: loss 0.007413 accuracy: 0.979276\n",
      "batch 4151: loss 0.011340 accuracy: 0.979281\n",
      "batch 4152: loss 0.016912 accuracy: 0.979285\n",
      "batch 4153: loss 0.003598 accuracy: 0.979290\n",
      "batch 4154: loss 0.026029 accuracy: 0.979292\n",
      "batch 4155: loss 0.008371 accuracy: 0.979297\n",
      "batch 4156: loss 0.010195 accuracy: 0.979302\n",
      "batch 4157: loss 0.005882 accuracy: 0.979307\n",
      "batch 4158: loss 0.004468 accuracy: 0.979312\n",
      "batch 4159: loss 0.010281 accuracy: 0.979317\n",
      "batch 4160: loss 0.025618 accuracy: 0.979321\n",
      "batch 4161: loss 0.013329 accuracy: 0.979325\n",
      "batch 4162: loss 0.020154 accuracy: 0.979327\n",
      "batch 4163: loss 0.017296 accuracy: 0.979331\n",
      "batch 4164: loss 0.010851 accuracy: 0.979336\n",
      "batch 4165: loss 0.004376 accuracy: 0.979341\n",
      "batch 4166: loss 0.009652 accuracy: 0.979346\n",
      "batch 4167: loss 0.005848 accuracy: 0.979351\n",
      "batch 4168: loss 0.017400 accuracy: 0.979355\n",
      "batch 4169: loss 0.004946 accuracy: 0.979360\n",
      "batch 4170: loss 0.013795 accuracy: 0.979365\n",
      "batch 4171: loss 0.043916 accuracy: 0.979367\n",
      "batch 4172: loss 0.014594 accuracy: 0.979372\n",
      "batch 4173: loss 0.009083 accuracy: 0.979377\n",
      "batch 4174: loss 0.011259 accuracy: 0.979381\n",
      "batch 4175: loss 0.011845 accuracy: 0.979386\n",
      "batch 4176: loss 0.014931 accuracy: 0.979389\n",
      "batch 4177: loss 0.007334 accuracy: 0.979394\n",
      "batch 4178: loss 0.031103 accuracy: 0.979397\n",
      "batch 4179: loss 0.026073 accuracy: 0.979400\n",
      "batch 4180: loss 0.016715 accuracy: 0.979402\n",
      "batch 4181: loss 0.010346 accuracy: 0.979406\n",
      "batch 4182: loss 0.029998 accuracy: 0.979410\n",
      "batch 4183: loss 0.008159 accuracy: 0.979414\n",
      "batch 4184: loss 0.023577 accuracy: 0.979417\n",
      "batch 4185: loss 0.017729 accuracy: 0.979421\n",
      "batch 4186: loss 0.006932 accuracy: 0.979426\n",
      "batch 4187: loss 0.007081 accuracy: 0.979430\n",
      "batch 4188: loss 0.020229 accuracy: 0.979434\n",
      "batch 4189: loss 0.007256 accuracy: 0.979439\n",
      "batch 4190: loss 0.013545 accuracy: 0.979443\n",
      "batch 4191: loss 0.010398 accuracy: 0.979448\n",
      "batch 4192: loss 0.007234 accuracy: 0.979453\n",
      "batch 4193: loss 0.015018 accuracy: 0.979456\n",
      "batch 4194: loss 0.005592 accuracy: 0.979461\n",
      "batch 4195: loss 0.020549 accuracy: 0.979464\n",
      "batch 4196: loss 0.005519 accuracy: 0.979469\n",
      "batch 4197: loss 0.004002 accuracy: 0.979474\n",
      "batch 4198: loss 0.005058 accuracy: 0.979478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4199: loss 0.010051 accuracy: 0.979483\n",
      "batch 4200: loss 0.017270 accuracy: 0.979488\n",
      "model saved to ./save\\ckpt-4200\n",
      "batch 4201: loss 0.008668 accuracy: 0.979493\n",
      "batch 4202: loss 0.011379 accuracy: 0.979497\n",
      "batch 4203: loss 0.037041 accuracy: 0.979500\n",
      "batch 4204: loss 0.010669 accuracy: 0.979505\n",
      "batch 4205: loss 0.010344 accuracy: 0.979510\n",
      "batch 4206: loss 0.008881 accuracy: 0.979515\n",
      "batch 4207: loss 0.005846 accuracy: 0.979520\n",
      "batch 4208: loss 0.010662 accuracy: 0.979524\n",
      "batch 4209: loss 0.016416 accuracy: 0.979527\n",
      "batch 4210: loss 0.007862 accuracy: 0.979532\n",
      "batch 4211: loss 0.008515 accuracy: 0.979537\n",
      "batch 4212: loss 0.007707 accuracy: 0.979542\n",
      "batch 4213: loss 0.027712 accuracy: 0.979546\n",
      "batch 4214: loss 0.007082 accuracy: 0.979550\n",
      "batch 4215: loss 0.012299 accuracy: 0.979555\n",
      "batch 4216: loss 0.009423 accuracy: 0.979560\n",
      "batch 4217: loss 0.015124 accuracy: 0.979565\n",
      "batch 4218: loss 0.006320 accuracy: 0.979570\n",
      "batch 4219: loss 0.019410 accuracy: 0.979573\n",
      "batch 4220: loss 0.010057 accuracy: 0.979577\n",
      "batch 4221: loss 0.008815 accuracy: 0.979582\n",
      "batch 4222: loss 0.004228 accuracy: 0.979587\n",
      "batch 4223: loss 0.009513 accuracy: 0.979592\n",
      "batch 4224: loss 0.033849 accuracy: 0.979595\n",
      "batch 4225: loss 0.023357 accuracy: 0.979599\n",
      "batch 4226: loss 0.014254 accuracy: 0.979603\n",
      "batch 4227: loss 0.012601 accuracy: 0.979607\n",
      "batch 4228: loss 0.004710 accuracy: 0.979612\n",
      "batch 4229: loss 0.008462 accuracy: 0.979617\n",
      "batch 4230: loss 0.012612 accuracy: 0.979622\n",
      "batch 4231: loss 0.010840 accuracy: 0.979625\n",
      "batch 4232: loss 0.011129 accuracy: 0.979630\n",
      "batch 4233: loss 0.027542 accuracy: 0.979634\n",
      "batch 4234: loss 0.015949 accuracy: 0.979638\n",
      "batch 4235: loss 0.009379 accuracy: 0.979641\n",
      "batch 4236: loss 0.006716 accuracy: 0.979646\n",
      "batch 4237: loss 0.014279 accuracy: 0.979650\n",
      "batch 4238: loss 0.015397 accuracy: 0.979653\n",
      "batch 4239: loss 0.009715 accuracy: 0.979658\n",
      "batch 4240: loss 0.025164 accuracy: 0.979662\n",
      "batch 4241: loss 0.013852 accuracy: 0.979666\n",
      "batch 4242: loss 0.009283 accuracy: 0.979670\n",
      "batch 4243: loss 0.010077 accuracy: 0.979675\n",
      "batch 4244: loss 0.019305 accuracy: 0.979677\n",
      "batch 4245: loss 0.003656 accuracy: 0.979682\n",
      "batch 4246: loss 0.011919 accuracy: 0.979687\n",
      "batch 4247: loss 0.014425 accuracy: 0.979692\n",
      "batch 4248: loss 0.014619 accuracy: 0.979696\n",
      "batch 4249: loss 0.009901 accuracy: 0.979701\n",
      "batch 4250: loss 0.004468 accuracy: 0.979706\n",
      "batch 4251: loss 0.030477 accuracy: 0.979710\n",
      "batch 4252: loss 0.010252 accuracy: 0.979714\n",
      "batch 4253: loss 0.006649 accuracy: 0.979719\n",
      "batch 4254: loss 0.003851 accuracy: 0.979724\n",
      "batch 4255: loss 0.005535 accuracy: 0.979729\n",
      "batch 4256: loss 0.011362 accuracy: 0.979733\n",
      "batch 4257: loss 0.021018 accuracy: 0.979737\n",
      "batch 4258: loss 0.007536 accuracy: 0.979742\n",
      "batch 4259: loss 0.017750 accuracy: 0.979745\n",
      "batch 4260: loss 0.008659 accuracy: 0.979750\n",
      "batch 4261: loss 0.023563 accuracy: 0.979752\n",
      "batch 4262: loss 0.016480 accuracy: 0.979757\n",
      "batch 4263: loss 0.003413 accuracy: 0.979762\n",
      "batch 4264: loss 0.016760 accuracy: 0.979766\n",
      "batch 4265: loss 0.005507 accuracy: 0.979770\n",
      "batch 4266: loss 0.013642 accuracy: 0.979774\n",
      "batch 4267: loss 0.006594 accuracy: 0.979779\n",
      "batch 4268: loss 0.012399 accuracy: 0.979782\n",
      "batch 4269: loss 0.006053 accuracy: 0.979787\n",
      "batch 4270: loss 0.022564 accuracy: 0.979789\n",
      "batch 4271: loss 0.010190 accuracy: 0.979794\n",
      "batch 4272: loss 0.018759 accuracy: 0.979798\n",
      "batch 4273: loss 0.029296 accuracy: 0.979801\n",
      "batch 4274: loss 0.011278 accuracy: 0.979806\n",
      "batch 4275: loss 0.004703 accuracy: 0.979811\n",
      "batch 4276: loss 0.010433 accuracy: 0.979815\n",
      "batch 4277: loss 0.010818 accuracy: 0.979820\n",
      "batch 4278: loss 0.027026 accuracy: 0.979822\n",
      "batch 4279: loss 0.006470 accuracy: 0.979826\n",
      "batch 4280: loss 0.008016 accuracy: 0.979831\n",
      "batch 4281: loss 0.014430 accuracy: 0.979835\n",
      "batch 4282: loss 0.014643 accuracy: 0.979838\n",
      "batch 4283: loss 0.031568 accuracy: 0.979841\n",
      "batch 4284: loss 0.038299 accuracy: 0.979845\n",
      "batch 4285: loss 0.003983 accuracy: 0.979850\n",
      "batch 4286: loss 0.012337 accuracy: 0.979854\n",
      "batch 4287: loss 0.017018 accuracy: 0.979858\n",
      "batch 4288: loss 0.014570 accuracy: 0.979861\n",
      "batch 4289: loss 0.016806 accuracy: 0.979865\n",
      "batch 4290: loss 0.012626 accuracy: 0.979868\n",
      "batch 4291: loss 0.012988 accuracy: 0.979872\n",
      "batch 4292: loss 0.003477 accuracy: 0.979877\n",
      "batch 4293: loss 0.015304 accuracy: 0.979880\n",
      "batch 4294: loss 0.006573 accuracy: 0.979885\n",
      "batch 4295: loss 0.014186 accuracy: 0.979888\n",
      "batch 4296: loss 0.013022 accuracy: 0.979892\n",
      "batch 4297: loss 0.007193 accuracy: 0.979896\n",
      "batch 4298: loss 0.012224 accuracy: 0.979901\n",
      "batch 4299: loss 0.015374 accuracy: 0.979905\n",
      "batch 4300: loss 0.007471 accuracy: 0.979909\n",
      "model saved to ./save\\ckpt-4300\n",
      "batch 4301: loss 0.009815 accuracy: 0.979913\n",
      "batch 4302: loss 0.009236 accuracy: 0.979918\n",
      "batch 4303: loss 0.029276 accuracy: 0.979919\n",
      "batch 4304: loss 0.015552 accuracy: 0.979922\n",
      "batch 4305: loss 0.005941 accuracy: 0.979927\n",
      "batch 4306: loss 0.020707 accuracy: 0.979929\n",
      "batch 4307: loss 0.011670 accuracy: 0.979933\n",
      "batch 4308: loss 0.008885 accuracy: 0.979937\n",
      "batch 4309: loss 0.015067 accuracy: 0.979941\n",
      "batch 4310: loss 0.008147 accuracy: 0.979945\n",
      "batch 4311: loss 0.012796 accuracy: 0.979949\n",
      "batch 4312: loss 0.016048 accuracy: 0.979952\n",
      "batch 4313: loss 0.009685 accuracy: 0.979957\n",
      "batch 4314: loss 0.007172 accuracy: 0.979962\n",
      "batch 4315: loss 0.020601 accuracy: 0.979964\n",
      "batch 4316: loss 0.003475 accuracy: 0.979969\n",
      "batch 4317: loss 0.005237 accuracy: 0.979973\n",
      "batch 4318: loss 0.015540 accuracy: 0.979977\n",
      "batch 4319: loss 0.003576 accuracy: 0.979981\n",
      "batch 4320: loss 0.006933 accuracy: 0.979986\n",
      "batch 4321: loss 0.009891 accuracy: 0.979991\n",
      "batch 4322: loss 0.008570 accuracy: 0.979995\n",
      "batch 4323: loss 0.014049 accuracy: 0.979999\n",
      "batch 4324: loss 0.008805 accuracy: 0.980003\n",
      "batch 4325: loss 0.006298 accuracy: 0.980008\n",
      "batch 4326: loss 0.006002 accuracy: 0.980013\n",
      "batch 4327: loss 0.011273 accuracy: 0.980017\n",
      "batch 4328: loss 0.012758 accuracy: 0.980021\n",
      "batch 4329: loss 0.020326 accuracy: 0.980023\n",
      "batch 4330: loss 0.004826 accuracy: 0.980028\n",
      "batch 4331: loss 0.014309 accuracy: 0.980032\n",
      "batch 4332: loss 0.013316 accuracy: 0.980037\n",
      "batch 4333: loss 0.015357 accuracy: 0.980040\n",
      "batch 4334: loss 0.012339 accuracy: 0.980044\n",
      "batch 4335: loss 0.014040 accuracy: 0.980047\n",
      "batch 4336: loss 0.014308 accuracy: 0.980051\n",
      "batch 4337: loss 0.014242 accuracy: 0.980055\n",
      "batch 4338: loss 0.010928 accuracy: 0.980060\n",
      "batch 4339: loss 0.011366 accuracy: 0.980065\n",
      "batch 4340: loss 0.004210 accuracy: 0.980069\n",
      "batch 4341: loss 0.036386 accuracy: 0.980070\n",
      "batch 4342: loss 0.010121 accuracy: 0.980074\n",
      "batch 4343: loss 0.008273 accuracy: 0.980078\n",
      "batch 4344: loss 0.007308 accuracy: 0.980083\n",
      "batch 4345: loss 0.003368 accuracy: 0.980087\n",
      "batch 4346: loss 0.014028 accuracy: 0.980092\n",
      "batch 4347: loss 0.014033 accuracy: 0.980095\n",
      "batch 4348: loss 0.004653 accuracy: 0.980100\n",
      "batch 4349: loss 0.006761 accuracy: 0.980105\n",
      "batch 4350: loss 0.004503 accuracy: 0.980109\n",
      "batch 4351: loss 0.048354 accuracy: 0.980113\n",
      "batch 4352: loss 0.017821 accuracy: 0.980116\n",
      "batch 4353: loss 0.032488 accuracy: 0.980119\n",
      "batch 4354: loss 0.009158 accuracy: 0.980124\n",
      "batch 4355: loss 0.006863 accuracy: 0.980129\n",
      "batch 4356: loss 0.002869 accuracy: 0.980133\n",
      "batch 4357: loss 0.006325 accuracy: 0.980138\n",
      "batch 4358: loss 0.012343 accuracy: 0.980141\n",
      "batch 4359: loss 0.007797 accuracy: 0.980146\n",
      "batch 4360: loss 0.012750 accuracy: 0.980149\n",
      "batch 4361: loss 0.028850 accuracy: 0.980152\n",
      "batch 4362: loss 0.005726 accuracy: 0.980157\n",
      "batch 4363: loss 0.008203 accuracy: 0.980162\n",
      "batch 4364: loss 0.017892 accuracy: 0.980165\n",
      "batch 4365: loss 0.008033 accuracy: 0.980169\n",
      "batch 4366: loss 0.005612 accuracy: 0.980174\n",
      "batch 4367: loss 0.029011 accuracy: 0.980177\n",
      "batch 4368: loss 0.006803 accuracy: 0.980182\n",
      "batch 4369: loss 0.008840 accuracy: 0.980187\n",
      "batch 4370: loss 0.006490 accuracy: 0.980191\n",
      "batch 4371: loss 0.007085 accuracy: 0.980196\n",
      "batch 4372: loss 0.008379 accuracy: 0.980200\n",
      "batch 4373: loss 0.011391 accuracy: 0.980203\n",
      "batch 4374: loss 0.008671 accuracy: 0.980208\n",
      "batch 4375: loss 0.006906 accuracy: 0.980213\n",
      "batch 4376: loss 0.012397 accuracy: 0.980216\n",
      "batch 4377: loss 0.004127 accuracy: 0.980220\n",
      "batch 4378: loss 0.008226 accuracy: 0.980225\n",
      "batch 4379: loss 0.005031 accuracy: 0.980229\n",
      "batch 4380: loss 0.010475 accuracy: 0.980233\n",
      "batch 4381: loss 0.010859 accuracy: 0.980236\n",
      "batch 4382: loss 0.010647 accuracy: 0.980241\n",
      "batch 4383: loss 0.007509 accuracy: 0.980245\n",
      "batch 4384: loss 0.023034 accuracy: 0.980249\n",
      "batch 4385: loss 0.005860 accuracy: 0.980253\n",
      "batch 4386: loss 0.008581 accuracy: 0.980258\n",
      "batch 4387: loss 0.011001 accuracy: 0.980262\n",
      "batch 4388: loss 0.010416 accuracy: 0.980267\n",
      "batch 4389: loss 0.008341 accuracy: 0.980271\n",
      "batch 4390: loss 0.004383 accuracy: 0.980276\n",
      "batch 4391: loss 0.007862 accuracy: 0.980280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4392: loss 0.010092 accuracy: 0.980285\n",
      "batch 4393: loss 0.011149 accuracy: 0.980288\n",
      "batch 4394: loss 0.012029 accuracy: 0.980292\n",
      "batch 4395: loss 0.025854 accuracy: 0.980295\n",
      "batch 4396: loss 0.006045 accuracy: 0.980299\n",
      "batch 4397: loss 0.014466 accuracy: 0.980302\n",
      "batch 4398: loss 0.004475 accuracy: 0.980307\n",
      "batch 4399: loss 0.013610 accuracy: 0.980311\n",
      "batch 4400: loss 0.050349 accuracy: 0.980315\n",
      "model saved to ./save\\ckpt-4400\n",
      "batch 4401: loss 0.017889 accuracy: 0.980317\n",
      "batch 4402: loss 0.012093 accuracy: 0.980321\n",
      "batch 4403: loss 0.023043 accuracy: 0.980324\n",
      "batch 4404: loss 0.008950 accuracy: 0.980327\n",
      "batch 4405: loss 0.011507 accuracy: 0.980331\n",
      "batch 4406: loss 0.016511 accuracy: 0.980335\n",
      "batch 4407: loss 0.046915 accuracy: 0.980337\n",
      "batch 4408: loss 0.019254 accuracy: 0.980340\n",
      "batch 4409: loss 0.010499 accuracy: 0.980344\n",
      "batch 4410: loss 0.008882 accuracy: 0.980348\n",
      "batch 4411: loss 0.007365 accuracy: 0.980352\n",
      "batch 4412: loss 0.009052 accuracy: 0.980357\n",
      "batch 4413: loss 0.010444 accuracy: 0.980361\n",
      "batch 4414: loss 0.012595 accuracy: 0.980365\n",
      "batch 4415: loss 0.015509 accuracy: 0.980368\n",
      "batch 4416: loss 0.021611 accuracy: 0.980371\n",
      "batch 4417: loss 0.010030 accuracy: 0.980376\n",
      "batch 4418: loss 0.018106 accuracy: 0.980379\n",
      "batch 4419: loss 0.007972 accuracy: 0.980383\n",
      "batch 4420: loss 0.011590 accuracy: 0.980388\n",
      "batch 4421: loss 0.006235 accuracy: 0.980392\n",
      "batch 4422: loss 0.012073 accuracy: 0.980396\n",
      "batch 4423: loss 0.020577 accuracy: 0.980399\n",
      "batch 4424: loss 0.015449 accuracy: 0.980402\n",
      "batch 4425: loss 0.020889 accuracy: 0.980404\n",
      "batch 4426: loss 0.008902 accuracy: 0.980409\n",
      "batch 4427: loss 0.005248 accuracy: 0.980413\n",
      "batch 4428: loss 0.015189 accuracy: 0.980418\n",
      "batch 4429: loss 0.014424 accuracy: 0.980422\n",
      "batch 4430: loss 0.006144 accuracy: 0.980427\n",
      "batch 4431: loss 0.023077 accuracy: 0.980430\n",
      "batch 4432: loss 0.019378 accuracy: 0.980433\n",
      "batch 4433: loss 0.017281 accuracy: 0.980438\n",
      "batch 4434: loss 0.010717 accuracy: 0.980442\n",
      "batch 4435: loss 0.020057 accuracy: 0.980445\n",
      "batch 4436: loss 0.012001 accuracy: 0.980448\n",
      "batch 4437: loss 0.017251 accuracy: 0.980452\n",
      "batch 4438: loss 0.004666 accuracy: 0.980456\n",
      "batch 4439: loss 0.004611 accuracy: 0.980461\n",
      "batch 4440: loss 0.005358 accuracy: 0.980465\n",
      "batch 4441: loss 0.011475 accuracy: 0.980468\n",
      "batch 4442: loss 0.004280 accuracy: 0.980473\n",
      "batch 4443: loss 0.025014 accuracy: 0.980475\n",
      "batch 4444: loss 0.012329 accuracy: 0.980478\n",
      "batch 4445: loss 0.011047 accuracy: 0.980482\n",
      "batch 4446: loss 0.018102 accuracy: 0.980486\n",
      "batch 4447: loss 0.008728 accuracy: 0.980490\n",
      "batch 4448: loss 0.010660 accuracy: 0.980494\n",
      "batch 4449: loss 0.008794 accuracy: 0.980499\n",
      "batch 4450: loss 0.016277 accuracy: 0.980502\n",
      "batch 4451: loss 0.012648 accuracy: 0.980507\n",
      "batch 4452: loss 0.003421 accuracy: 0.980511\n",
      "batch 4453: loss 0.007626 accuracy: 0.980515\n",
      "batch 4454: loss 0.026128 accuracy: 0.980517\n",
      "batch 4455: loss 0.023623 accuracy: 0.980521\n",
      "batch 4456: loss 0.014803 accuracy: 0.980525\n",
      "batch 4457: loss 0.013799 accuracy: 0.980528\n",
      "batch 4458: loss 0.023806 accuracy: 0.980532\n",
      "batch 4459: loss 0.007404 accuracy: 0.980536\n",
      "batch 4460: loss 0.017650 accuracy: 0.980539\n",
      "batch 4461: loss 0.021228 accuracy: 0.980541\n",
      "batch 4462: loss 0.024952 accuracy: 0.980543\n",
      "batch 4463: loss 0.047901 accuracy: 0.980544\n",
      "batch 4464: loss 0.003830 accuracy: 0.980549\n",
      "batch 4465: loss 0.004554 accuracy: 0.980553\n",
      "batch 4466: loss 0.006360 accuracy: 0.980557\n",
      "batch 4467: loss 0.004915 accuracy: 0.980562\n",
      "batch 4468: loss 0.033651 accuracy: 0.980565\n",
      "batch 4469: loss 0.003661 accuracy: 0.980569\n",
      "batch 4470: loss 0.086532 accuracy: 0.980573\n",
      "batch 4471: loss 0.021298 accuracy: 0.980576\n",
      "batch 4472: loss 0.006748 accuracy: 0.980580\n",
      "batch 4473: loss 0.012071 accuracy: 0.980583\n",
      "batch 4474: loss 0.017150 accuracy: 0.980587\n",
      "batch 4475: loss 0.024820 accuracy: 0.980590\n",
      "batch 4476: loss 0.024881 accuracy: 0.980592\n",
      "batch 4477: loss 0.008289 accuracy: 0.980596\n",
      "batch 4478: loss 0.011417 accuracy: 0.980599\n",
      "batch 4479: loss 0.004923 accuracy: 0.980604\n",
      "batch 4480: loss 0.003416 accuracy: 0.980608\n",
      "batch 4481: loss 0.019199 accuracy: 0.980612\n",
      "batch 4482: loss 0.013321 accuracy: 0.980616\n",
      "batch 4483: loss 0.007388 accuracy: 0.980620\n",
      "batch 4484: loss 0.021036 accuracy: 0.980623\n",
      "batch 4485: loss 0.107609 accuracy: 0.980625\n",
      "batch 4486: loss 0.005067 accuracy: 0.980630\n",
      "batch 4487: loss 0.019692 accuracy: 0.980633\n",
      "batch 4488: loss 0.010400 accuracy: 0.980637\n",
      "batch 4489: loss 0.006687 accuracy: 0.980641\n",
      "batch 4490: loss 0.008050 accuracy: 0.980646\n",
      "batch 4491: loss 0.009107 accuracy: 0.980649\n",
      "batch 4492: loss 0.015623 accuracy: 0.980652\n",
      "batch 4493: loss 0.005940 accuracy: 0.980656\n",
      "batch 4494: loss 0.005373 accuracy: 0.980661\n",
      "batch 4495: loss 0.017460 accuracy: 0.980663\n",
      "batch 4496: loss 0.002660 accuracy: 0.980667\n",
      "batch 4497: loss 0.012427 accuracy: 0.980670\n",
      "batch 4498: loss 0.020041 accuracy: 0.980673\n",
      "batch 4499: loss 0.006515 accuracy: 0.980678\n",
      "batch 4500: loss 0.030331 accuracy: 0.980681\n",
      "model saved to ./save\\ckpt-4500\n",
      "batch 4501: loss 0.009450 accuracy: 0.980685\n",
      "batch 4502: loss 0.006951 accuracy: 0.980690\n",
      "batch 4503: loss 0.004644 accuracy: 0.980694\n",
      "batch 4504: loss 0.014507 accuracy: 0.980697\n",
      "batch 4505: loss 0.017885 accuracy: 0.980700\n",
      "batch 4506: loss 0.005624 accuracy: 0.980704\n",
      "batch 4507: loss 0.007450 accuracy: 0.980709\n",
      "batch 4508: loss 0.005490 accuracy: 0.980713\n",
      "batch 4509: loss 0.009150 accuracy: 0.980717\n",
      "batch 4510: loss 0.017552 accuracy: 0.980719\n",
      "batch 4511: loss 0.006463 accuracy: 0.980724\n",
      "batch 4512: loss 0.005228 accuracy: 0.980728\n",
      "batch 4513: loss 0.004155 accuracy: 0.980732\n",
      "batch 4514: loss 0.007243 accuracy: 0.980736\n",
      "batch 4515: loss 0.010051 accuracy: 0.980741\n",
      "batch 4516: loss 0.010770 accuracy: 0.980745\n",
      "batch 4517: loss 0.008719 accuracy: 0.980748\n",
      "batch 4518: loss 0.015516 accuracy: 0.980751\n",
      "batch 4519: loss 0.013924 accuracy: 0.980756\n",
      "batch 4520: loss 0.007183 accuracy: 0.980760\n",
      "batch 4521: loss 0.009739 accuracy: 0.980764\n",
      "batch 4522: loss 0.007264 accuracy: 0.980768\n",
      "batch 4523: loss 0.010494 accuracy: 0.980773\n",
      "batch 4524: loss 0.004542 accuracy: 0.980777\n",
      "batch 4525: loss 0.002227 accuracy: 0.980781\n",
      "batch 4526: loss 0.004533 accuracy: 0.980785\n",
      "batch 4527: loss 0.011188 accuracy: 0.980788\n",
      "batch 4528: loss 0.009227 accuracy: 0.980793\n",
      "batch 4529: loss 0.010564 accuracy: 0.980796\n",
      "batch 4530: loss 0.024234 accuracy: 0.980798\n",
      "batch 4531: loss 0.011821 accuracy: 0.980802\n",
      "batch 4532: loss 0.006324 accuracy: 0.980806\n",
      "batch 4533: loss 0.018698 accuracy: 0.980808\n",
      "batch 4534: loss 0.010952 accuracy: 0.980813\n",
      "batch 4535: loss 0.006305 accuracy: 0.980817\n",
      "batch 4536: loss 0.014212 accuracy: 0.980820\n",
      "batch 4537: loss 0.007636 accuracy: 0.980824\n",
      "batch 4538: loss 0.012245 accuracy: 0.980827\n",
      "batch 4539: loss 0.016594 accuracy: 0.980832\n",
      "batch 4540: loss 0.014514 accuracy: 0.980835\n",
      "batch 4541: loss 0.004234 accuracy: 0.980839\n",
      "batch 4542: loss 0.008358 accuracy: 0.980843\n",
      "batch 4543: loss 0.006924 accuracy: 0.980847\n",
      "batch 4544: loss 0.006717 accuracy: 0.980851\n",
      "batch 4545: loss 0.013676 accuracy: 0.980855\n",
      "batch 4546: loss 0.004946 accuracy: 0.980859\n",
      "batch 4547: loss 0.008239 accuracy: 0.980863\n",
      "batch 4548: loss 0.013411 accuracy: 0.980866\n",
      "batch 4549: loss 0.024817 accuracy: 0.980869\n",
      "batch 4550: loss 0.027832 accuracy: 0.980871\n",
      "batch 4551: loss 0.020992 accuracy: 0.980874\n",
      "batch 4552: loss 0.012223 accuracy: 0.980879\n",
      "batch 4553: loss 0.007748 accuracy: 0.980883\n",
      "batch 4554: loss 0.009251 accuracy: 0.980887\n",
      "batch 4555: loss 0.007819 accuracy: 0.980891\n",
      "batch 4556: loss 0.009093 accuracy: 0.980895\n",
      "batch 4557: loss 0.023767 accuracy: 0.980898\n",
      "batch 4558: loss 0.006900 accuracy: 0.980903\n",
      "batch 4559: loss 0.012030 accuracy: 0.980906\n",
      "batch 4560: loss 0.013592 accuracy: 0.980909\n",
      "batch 4561: loss 0.023423 accuracy: 0.980912\n",
      "batch 4562: loss 0.021226 accuracy: 0.980915\n",
      "batch 4563: loss 0.005320 accuracy: 0.980919\n",
      "batch 4564: loss 0.006938 accuracy: 0.980923\n",
      "batch 4565: loss 0.009723 accuracy: 0.980928\n",
      "batch 4566: loss 0.006776 accuracy: 0.980932\n",
      "batch 4567: loss 0.012072 accuracy: 0.980935\n",
      "batch 4568: loss 0.007007 accuracy: 0.980939\n",
      "batch 4569: loss 0.016658 accuracy: 0.980942\n",
      "batch 4570: loss 0.011205 accuracy: 0.980945\n",
      "batch 4571: loss 0.010075 accuracy: 0.980949\n",
      "batch 4572: loss 0.020448 accuracy: 0.980952\n",
      "batch 4573: loss 0.009648 accuracy: 0.980955\n",
      "batch 4574: loss 0.007176 accuracy: 0.980960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4575: loss 0.009575 accuracy: 0.980964\n",
      "batch 4576: loss 0.004629 accuracy: 0.980968\n",
      "batch 4577: loss 0.007405 accuracy: 0.980972\n",
      "batch 4578: loss 0.034028 accuracy: 0.980975\n",
      "batch 4579: loss 0.004846 accuracy: 0.980979\n",
      "batch 4580: loss 0.015732 accuracy: 0.980983\n",
      "batch 4581: loss 0.030739 accuracy: 0.980985\n",
      "batch 4582: loss 0.011752 accuracy: 0.980988\n",
      "batch 4583: loss 0.029467 accuracy: 0.980991\n",
      "batch 4584: loss 0.009343 accuracy: 0.980996\n",
      "batch 4585: loss 0.011299 accuracy: 0.980999\n",
      "batch 4586: loss 0.009271 accuracy: 0.981003\n",
      "batch 4587: loss 0.005635 accuracy: 0.981007\n",
      "batch 4588: loss 0.011214 accuracy: 0.981010\n",
      "batch 4589: loss 0.005003 accuracy: 0.981014\n",
      "batch 4590: loss 0.006692 accuracy: 0.981018\n",
      "batch 4591: loss 0.018628 accuracy: 0.981021\n",
      "batch 4592: loss 0.004779 accuracy: 0.981025\n",
      "batch 4593: loss 0.003222 accuracy: 0.981030\n",
      "batch 4594: loss 0.017232 accuracy: 0.981034\n",
      "batch 4595: loss 0.010396 accuracy: 0.981038\n",
      "batch 4596: loss 0.005669 accuracy: 0.981042\n",
      "batch 4597: loss 0.010945 accuracy: 0.981046\n",
      "batch 4598: loss 0.008769 accuracy: 0.981050\n",
      "batch 4599: loss 0.016097 accuracy: 0.981053\n",
      "batch 4600: loss 0.005337 accuracy: 0.981057\n",
      "model saved to ./save\\ckpt-4600\n",
      "batch 4601: loss 0.013604 accuracy: 0.981060\n",
      "batch 4602: loss 0.006217 accuracy: 0.981064\n",
      "batch 4603: loss 0.009605 accuracy: 0.981069\n",
      "batch 4604: loss 0.008236 accuracy: 0.981073\n",
      "batch 4605: loss 0.019575 accuracy: 0.981076\n",
      "batch 4606: loss 0.008149 accuracy: 0.981079\n",
      "batch 4607: loss 0.010400 accuracy: 0.981083\n",
      "batch 4608: loss 0.018950 accuracy: 0.981086\n",
      "batch 4609: loss 0.007050 accuracy: 0.981090\n",
      "batch 4610: loss 0.008440 accuracy: 0.981094\n",
      "batch 4611: loss 0.007520 accuracy: 0.981098\n",
      "batch 4612: loss 0.028721 accuracy: 0.981100\n",
      "batch 4613: loss 0.007579 accuracy: 0.981104\n",
      "batch 4614: loss 0.009852 accuracy: 0.981108\n",
      "batch 4615: loss 0.008085 accuracy: 0.981112\n",
      "batch 4616: loss 0.004495 accuracy: 0.981117\n",
      "batch 4617: loss 0.007320 accuracy: 0.981120\n",
      "batch 4618: loss 0.008802 accuracy: 0.981124\n",
      "batch 4619: loss 0.041741 accuracy: 0.981126\n",
      "batch 4620: loss 0.005911 accuracy: 0.981130\n",
      "batch 4621: loss 0.007182 accuracy: 0.981134\n",
      "batch 4622: loss 0.035882 accuracy: 0.981136\n",
      "batch 4623: loss 0.004512 accuracy: 0.981140\n",
      "batch 4624: loss 0.005020 accuracy: 0.981144\n",
      "batch 4625: loss 0.014098 accuracy: 0.981148\n",
      "batch 4626: loss 0.003377 accuracy: 0.981152\n",
      "batch 4627: loss 0.017456 accuracy: 0.981155\n",
      "batch 4628: loss 0.011452 accuracy: 0.981159\n",
      "batch 4629: loss 0.003927 accuracy: 0.981163\n",
      "batch 4630: loss 0.011599 accuracy: 0.981167\n",
      "batch 4631: loss 0.005799 accuracy: 0.981171\n",
      "batch 4632: loss 0.015840 accuracy: 0.981175\n",
      "batch 4633: loss 0.005339 accuracy: 0.981179\n",
      "batch 4634: loss 0.012110 accuracy: 0.981183\n",
      "batch 4635: loss 0.007659 accuracy: 0.981187\n",
      "batch 4636: loss 0.010832 accuracy: 0.981192\n",
      "batch 4637: loss 0.004965 accuracy: 0.981196\n",
      "batch 4638: loss 0.007288 accuracy: 0.981200\n",
      "batch 4639: loss 0.011845 accuracy: 0.981204\n",
      "batch 4640: loss 0.010337 accuracy: 0.981208\n",
      "batch 4641: loss 0.029021 accuracy: 0.981210\n",
      "batch 4642: loss 0.003853 accuracy: 0.981214\n",
      "batch 4643: loss 0.010403 accuracy: 0.981218\n",
      "batch 4644: loss 0.004810 accuracy: 0.981222\n",
      "batch 4645: loss 0.013261 accuracy: 0.981226\n",
      "batch 4646: loss 0.007150 accuracy: 0.981230\n",
      "batch 4647: loss 0.011358 accuracy: 0.981233\n",
      "batch 4648: loss 0.009002 accuracy: 0.981237\n",
      "batch 4649: loss 0.010658 accuracy: 0.981241\n",
      "batch 4650: loss 0.004690 accuracy: 0.981245\n",
      "batch 4651: loss 0.006675 accuracy: 0.981249\n",
      "batch 4652: loss 0.008651 accuracy: 0.981253\n",
      "batch 4653: loss 0.016286 accuracy: 0.981256\n",
      "batch 4654: loss 0.006221 accuracy: 0.981260\n",
      "batch 4655: loss 0.010227 accuracy: 0.981264\n",
      "batch 4656: loss 0.011044 accuracy: 0.981267\n",
      "batch 4657: loss 0.008023 accuracy: 0.981271\n",
      "batch 4658: loss 0.005969 accuracy: 0.981275\n",
      "batch 4659: loss 0.007375 accuracy: 0.981279\n",
      "batch 4660: loss 0.007210 accuracy: 0.981283\n",
      "batch 4661: loss 0.011117 accuracy: 0.981287\n",
      "batch 4662: loss 0.010845 accuracy: 0.981291\n",
      "batch 4663: loss 0.007724 accuracy: 0.981295\n",
      "batch 4664: loss 0.005412 accuracy: 0.981299\n",
      "batch 4665: loss 0.021346 accuracy: 0.981302\n",
      "batch 4666: loss 0.006319 accuracy: 0.981306\n",
      "batch 4667: loss 0.008243 accuracy: 0.981310\n",
      "batch 4668: loss 0.009248 accuracy: 0.981314\n",
      "batch 4669: loss 0.021959 accuracy: 0.981316\n",
      "batch 4670: loss 0.004145 accuracy: 0.981320\n",
      "batch 4671: loss 0.009927 accuracy: 0.981323\n",
      "batch 4672: loss 0.003942 accuracy: 0.981327\n",
      "batch 4673: loss 0.008675 accuracy: 0.981331\n",
      "batch 4674: loss 0.009876 accuracy: 0.981335\n",
      "batch 4675: loss 0.019431 accuracy: 0.981338\n",
      "batch 4676: loss 0.018241 accuracy: 0.981341\n",
      "batch 4677: loss 0.004537 accuracy: 0.981345\n",
      "batch 4678: loss 0.007477 accuracy: 0.981349\n",
      "batch 4679: loss 0.015425 accuracy: 0.981351\n",
      "batch 4680: loss 0.009514 accuracy: 0.981354\n",
      "batch 4681: loss 0.006794 accuracy: 0.981358\n",
      "batch 4682: loss 0.007975 accuracy: 0.981362\n",
      "batch 4683: loss 0.014616 accuracy: 0.981365\n",
      "batch 4684: loss 0.015441 accuracy: 0.981368\n",
      "batch 4685: loss 0.002570 accuracy: 0.981372\n",
      "batch 4686: loss 0.006226 accuracy: 0.981376\n",
      "batch 4687: loss 0.005453 accuracy: 0.981380\n",
      "batch 4688: loss 0.011597 accuracy: 0.981383\n",
      "batch 4689: loss 0.005407 accuracy: 0.981387\n",
      "batch 4690: loss 0.010955 accuracy: 0.981390\n",
      "batch 4691: loss 0.011176 accuracy: 0.981394\n",
      "batch 4692: loss 0.004519 accuracy: 0.981398\n",
      "batch 4693: loss 0.012711 accuracy: 0.981401\n",
      "batch 4694: loss 0.007405 accuracy: 0.981405\n",
      "batch 4695: loss 0.001888 accuracy: 0.981409\n",
      "batch 4696: loss 0.021769 accuracy: 0.981412\n",
      "batch 4697: loss 0.009273 accuracy: 0.981414\n",
      "batch 4698: loss 0.013100 accuracy: 0.981417\n",
      "batch 4699: loss 0.008131 accuracy: 0.981421\n",
      "batch 4700: loss 0.008904 accuracy: 0.981424\n",
      "model saved to ./save\\ckpt-4700\n",
      "batch 4701: loss 0.008452 accuracy: 0.981428\n",
      "batch 4702: loss 0.008716 accuracy: 0.981432\n",
      "batch 4703: loss 0.012242 accuracy: 0.981435\n",
      "batch 4704: loss 0.016835 accuracy: 0.981438\n",
      "batch 4705: loss 0.002105 accuracy: 0.981442\n",
      "batch 4706: loss 0.003047 accuracy: 0.981446\n",
      "batch 4707: loss 0.011811 accuracy: 0.981449\n",
      "batch 4708: loss 0.003773 accuracy: 0.981453\n",
      "batch 4709: loss 0.005101 accuracy: 0.981456\n",
      "batch 4710: loss 0.006516 accuracy: 0.981460\n",
      "batch 4711: loss 0.011478 accuracy: 0.981463\n",
      "batch 4712: loss 0.005151 accuracy: 0.981467\n",
      "batch 4713: loss 0.019699 accuracy: 0.981470\n",
      "batch 4714: loss 0.014887 accuracy: 0.981473\n",
      "batch 4715: loss 0.006623 accuracy: 0.981477\n",
      "batch 4716: loss 0.012426 accuracy: 0.981481\n",
      "batch 4717: loss 0.005792 accuracy: 0.981485\n",
      "batch 4718: loss 0.007480 accuracy: 0.981489\n",
      "batch 4719: loss 0.008346 accuracy: 0.981493\n",
      "batch 4720: loss 0.008049 accuracy: 0.981497\n",
      "batch 4721: loss 0.011272 accuracy: 0.981500\n",
      "batch 4722: loss 0.005750 accuracy: 0.981504\n",
      "batch 4723: loss 0.014634 accuracy: 0.981507\n",
      "batch 4724: loss 0.025083 accuracy: 0.981509\n",
      "batch 4725: loss 0.003411 accuracy: 0.981513\n",
      "batch 4726: loss 0.014639 accuracy: 0.981516\n",
      "batch 4727: loss 0.010053 accuracy: 0.981519\n",
      "batch 4728: loss 0.011387 accuracy: 0.981523\n",
      "batch 4729: loss 0.005495 accuracy: 0.981526\n",
      "batch 4730: loss 0.011705 accuracy: 0.981530\n",
      "batch 4731: loss 0.012738 accuracy: 0.981534\n",
      "batch 4732: loss 0.005985 accuracy: 0.981538\n",
      "batch 4733: loss 0.005433 accuracy: 0.981542\n",
      "batch 4734: loss 0.010041 accuracy: 0.981546\n",
      "batch 4735: loss 0.012100 accuracy: 0.981549\n",
      "batch 4736: loss 0.006982 accuracy: 0.981553\n",
      "batch 4737: loss 0.004222 accuracy: 0.981557\n",
      "batch 4738: loss 0.088310 accuracy: 0.981559\n",
      "batch 4739: loss 0.006348 accuracy: 0.981563\n",
      "batch 4740: loss 0.010889 accuracy: 0.981567\n",
      "batch 4741: loss 0.007500 accuracy: 0.981571\n",
      "batch 4742: loss 0.004495 accuracy: 0.981575\n",
      "batch 4743: loss 0.009729 accuracy: 0.981579\n",
      "batch 4744: loss 0.006196 accuracy: 0.981583\n",
      "batch 4745: loss 0.010753 accuracy: 0.981587\n",
      "batch 4746: loss 0.005378 accuracy: 0.981590\n",
      "batch 4747: loss 0.031958 accuracy: 0.981592\n",
      "batch 4748: loss 0.012659 accuracy: 0.981595\n",
      "batch 4749: loss 0.012459 accuracy: 0.981598\n",
      "batch 4750: loss 0.003036 accuracy: 0.981602\n",
      "batch 4751: loss 0.002408 accuracy: 0.981606\n",
      "batch 4752: loss 0.004835 accuracy: 0.981610\n",
      "batch 4753: loss 0.007937 accuracy: 0.981613\n",
      "batch 4754: loss 0.010239 accuracy: 0.981616\n",
      "batch 4755: loss 0.018033 accuracy: 0.981620\n",
      "batch 4756: loss 0.007456 accuracy: 0.981624\n",
      "batch 4757: loss 0.015308 accuracy: 0.981627\n",
      "batch 4758: loss 0.007090 accuracy: 0.981631\n",
      "batch 4759: loss 0.009688 accuracy: 0.981634\n",
      "batch 4760: loss 0.003362 accuracy: 0.981638\n",
      "batch 4761: loss 0.004027 accuracy: 0.981642\n",
      "batch 4762: loss 0.004596 accuracy: 0.981646\n",
      "batch 4763: loss 0.015514 accuracy: 0.981649\n",
      "batch 4764: loss 0.012019 accuracy: 0.981653\n",
      "batch 4765: loss 0.005705 accuracy: 0.981655\n",
      "batch 4766: loss 0.010263 accuracy: 0.981658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4767: loss 0.005578 accuracy: 0.981662\n",
      "batch 4768: loss 0.004511 accuracy: 0.981666\n",
      "batch 4769: loss 0.011971 accuracy: 0.981670\n",
      "batch 4770: loss 0.009944 accuracy: 0.981673\n",
      "batch 4771: loss 0.003261 accuracy: 0.981676\n",
      "batch 4772: loss 0.016841 accuracy: 0.981679\n",
      "batch 4773: loss 0.009256 accuracy: 0.981682\n",
      "batch 4774: loss 0.007029 accuracy: 0.981686\n",
      "batch 4775: loss 0.007037 accuracy: 0.981690\n",
      "batch 4776: loss 0.004431 accuracy: 0.981694\n",
      "batch 4777: loss 0.003720 accuracy: 0.981697\n",
      "batch 4778: loss 0.015016 accuracy: 0.981700\n",
      "batch 4779: loss 0.006634 accuracy: 0.981704\n",
      "batch 4780: loss 0.009969 accuracy: 0.981708\n",
      "batch 4781: loss 0.029180 accuracy: 0.981710\n",
      "batch 4782: loss 0.010685 accuracy: 0.981713\n",
      "batch 4783: loss 0.012929 accuracy: 0.981717\n",
      "batch 4784: loss 0.005032 accuracy: 0.981721\n",
      "batch 4785: loss 0.007664 accuracy: 0.981725\n",
      "batch 4786: loss 0.004939 accuracy: 0.981729\n",
      "batch 4787: loss 0.009575 accuracy: 0.981732\n",
      "batch 4788: loss 0.006175 accuracy: 0.981736\n",
      "batch 4789: loss 0.006317 accuracy: 0.981740\n",
      "batch 4790: loss 0.016640 accuracy: 0.981743\n",
      "batch 4791: loss 0.018080 accuracy: 0.981746\n",
      "batch 4792: loss 0.008500 accuracy: 0.981749\n",
      "batch 4793: loss 0.005805 accuracy: 0.981753\n",
      "batch 4794: loss 0.033149 accuracy: 0.981756\n",
      "batch 4795: loss 0.004312 accuracy: 0.981760\n",
      "batch 4796: loss 0.009002 accuracy: 0.981764\n",
      "batch 4797: loss 0.011493 accuracy: 0.981766\n",
      "batch 4798: loss 0.012848 accuracy: 0.981770\n",
      "batch 4799: loss 0.011852 accuracy: 0.981773\n",
      "batch 4800: loss 0.007570 accuracy: 0.981777\n",
      "model saved to ./save\\ckpt-4800\n",
      "batch 4801: loss 0.018187 accuracy: 0.981779\n",
      "batch 4802: loss 0.019810 accuracy: 0.981782\n",
      "batch 4803: loss 0.013619 accuracy: 0.981786\n",
      "batch 4804: loss 0.004965 accuracy: 0.981790\n",
      "batch 4805: loss 0.013168 accuracy: 0.981793\n",
      "batch 4806: loss 0.012028 accuracy: 0.981796\n",
      "batch 4807: loss 0.005625 accuracy: 0.981800\n",
      "batch 4808: loss 0.007490 accuracy: 0.981804\n",
      "batch 4809: loss 0.004078 accuracy: 0.981808\n",
      "batch 4810: loss 0.012573 accuracy: 0.981810\n",
      "batch 4811: loss 0.010559 accuracy: 0.981813\n",
      "batch 4812: loss 0.005126 accuracy: 0.981817\n",
      "batch 4813: loss 0.009171 accuracy: 0.981821\n",
      "batch 4814: loss 0.027394 accuracy: 0.981823\n",
      "batch 4815: loss 0.010846 accuracy: 0.981827\n",
      "batch 4816: loss 0.003987 accuracy: 0.981831\n",
      "batch 4817: loss 0.003231 accuracy: 0.981835\n",
      "batch 4818: loss 0.002852 accuracy: 0.981839\n",
      "batch 4819: loss 0.009013 accuracy: 0.981841\n",
      "batch 4820: loss 0.007084 accuracy: 0.981845\n",
      "batch 4821: loss 0.006731 accuracy: 0.981849\n",
      "batch 4822: loss 0.005504 accuracy: 0.981853\n",
      "batch 4823: loss 0.018688 accuracy: 0.981855\n",
      "batch 4824: loss 0.018431 accuracy: 0.981858\n",
      "batch 4825: loss 0.007829 accuracy: 0.981862\n",
      "batch 4826: loss 0.010931 accuracy: 0.981865\n",
      "batch 4827: loss 0.006806 accuracy: 0.981868\n",
      "batch 4828: loss 0.008476 accuracy: 0.981872\n",
      "batch 4829: loss 0.012704 accuracy: 0.981875\n",
      "batch 4830: loss 0.010229 accuracy: 0.981877\n",
      "batch 4831: loss 0.019288 accuracy: 0.981879\n",
      "batch 4832: loss 0.002959 accuracy: 0.981883\n",
      "batch 4833: loss 0.001971 accuracy: 0.981887\n",
      "batch 4834: loss 0.010163 accuracy: 0.981890\n",
      "batch 4835: loss 0.019949 accuracy: 0.981893\n",
      "batch 4836: loss 0.009184 accuracy: 0.981897\n",
      "batch 4837: loss 0.026272 accuracy: 0.981898\n",
      "batch 4838: loss 0.009315 accuracy: 0.981902\n",
      "batch 4839: loss 0.003818 accuracy: 0.981906\n",
      "batch 4840: loss 0.011110 accuracy: 0.981909\n",
      "batch 4841: loss 0.004013 accuracy: 0.981912\n",
      "batch 4842: loss 0.005387 accuracy: 0.981916\n",
      "batch 4843: loss 0.045402 accuracy: 0.981918\n",
      "batch 4844: loss 0.018294 accuracy: 0.981920\n",
      "batch 4845: loss 0.004770 accuracy: 0.981923\n",
      "batch 4846: loss 0.007661 accuracy: 0.981927\n",
      "batch 4847: loss 0.040399 accuracy: 0.981930\n",
      "batch 4848: loss 0.002814 accuracy: 0.981933\n",
      "batch 4849: loss 0.026841 accuracy: 0.981936\n",
      "batch 4850: loss 0.032374 accuracy: 0.981939\n",
      "batch 4851: loss 0.017291 accuracy: 0.981941\n",
      "batch 4852: loss 0.007684 accuracy: 0.981945\n",
      "batch 4853: loss 0.011746 accuracy: 0.981948\n",
      "batch 4854: loss 0.002839 accuracy: 0.981952\n",
      "batch 4855: loss 0.010399 accuracy: 0.981955\n",
      "batch 4856: loss 0.005946 accuracy: 0.981959\n",
      "batch 4857: loss 0.004874 accuracy: 0.981963\n",
      "batch 4858: loss 0.007059 accuracy: 0.981966\n",
      "batch 4859: loss 0.003571 accuracy: 0.981970\n",
      "batch 4860: loss 0.003757 accuracy: 0.981974\n",
      "batch 4861: loss 0.007724 accuracy: 0.981978\n",
      "batch 4862: loss 0.025262 accuracy: 0.981980\n",
      "batch 4863: loss 0.006626 accuracy: 0.981984\n",
      "batch 4864: loss 0.011010 accuracy: 0.981987\n",
      "batch 4865: loss 0.016407 accuracy: 0.981989\n",
      "batch 4866: loss 0.005016 accuracy: 0.981993\n",
      "batch 4867: loss 0.006017 accuracy: 0.981997\n",
      "batch 4868: loss 0.020920 accuracy: 0.981999\n",
      "batch 4869: loss 0.003939 accuracy: 0.982003\n",
      "batch 4870: loss 0.010335 accuracy: 0.982007\n",
      "batch 4871: loss 0.012280 accuracy: 0.982010\n",
      "batch 4872: loss 0.013565 accuracy: 0.982014\n",
      "batch 4873: loss 0.006015 accuracy: 0.982018\n",
      "batch 4874: loss 0.014804 accuracy: 0.982020\n",
      "batch 4875: loss 0.015581 accuracy: 0.982023\n",
      "batch 4876: loss 0.022117 accuracy: 0.982026\n",
      "batch 4877: loss 0.005943 accuracy: 0.982029\n",
      "batch 4878: loss 0.004043 accuracy: 0.982033\n",
      "batch 4879: loss 0.004240 accuracy: 0.982037\n",
      "batch 4880: loss 0.007529 accuracy: 0.982041\n",
      "batch 4881: loss 0.040130 accuracy: 0.982042\n",
      "batch 4882: loss 0.016359 accuracy: 0.982045\n",
      "batch 4883: loss 0.005914 accuracy: 0.982049\n",
      "batch 4884: loss 0.031344 accuracy: 0.982051\n",
      "batch 4885: loss 0.014317 accuracy: 0.982055\n",
      "batch 4886: loss 0.016500 accuracy: 0.982058\n",
      "batch 4887: loss 0.013758 accuracy: 0.982061\n",
      "batch 4888: loss 0.009869 accuracy: 0.982065\n",
      "batch 4889: loss 0.014545 accuracy: 0.982067\n",
      "batch 4890: loss 0.010915 accuracy: 0.982071\n",
      "batch 4891: loss 0.004520 accuracy: 0.982075\n",
      "batch 4892: loss 0.011320 accuracy: 0.982077\n",
      "batch 4893: loss 0.003692 accuracy: 0.982081\n",
      "batch 4894: loss 0.026946 accuracy: 0.982084\n",
      "batch 4895: loss 0.024280 accuracy: 0.982086\n",
      "batch 4896: loss 0.007962 accuracy: 0.982090\n",
      "batch 4897: loss 0.007293 accuracy: 0.982094\n",
      "batch 4898: loss 0.017880 accuracy: 0.982096\n",
      "batch 4899: loss 0.004849 accuracy: 0.982100\n",
      "batch 4900: loss 0.014750 accuracy: 0.982102\n",
      "model saved to ./save\\ckpt-4900\n",
      "batch 4901: loss 0.006693 accuracy: 0.982105\n",
      "batch 4902: loss 0.021420 accuracy: 0.982108\n",
      "batch 4903: loss 0.016693 accuracy: 0.982111\n",
      "batch 4904: loss 0.009344 accuracy: 0.982114\n",
      "batch 4905: loss 0.009251 accuracy: 0.982118\n",
      "batch 4906: loss 0.012107 accuracy: 0.982121\n",
      "batch 4907: loss 0.009225 accuracy: 0.982125\n",
      "batch 4908: loss 0.023988 accuracy: 0.982126\n",
      "batch 4909: loss 0.006096 accuracy: 0.982129\n",
      "batch 4910: loss 0.007235 accuracy: 0.982133\n",
      "batch 4911: loss 0.011673 accuracy: 0.982137\n",
      "batch 4912: loss 0.015409 accuracy: 0.982139\n",
      "batch 4913: loss 0.007252 accuracy: 0.982143\n",
      "batch 4914: loss 0.005527 accuracy: 0.982147\n",
      "batch 4915: loss 0.012219 accuracy: 0.982149\n",
      "batch 4916: loss 0.007754 accuracy: 0.982153\n",
      "batch 4917: loss 0.010214 accuracy: 0.982155\n",
      "batch 4918: loss 0.005781 accuracy: 0.982159\n",
      "batch 4919: loss 0.014351 accuracy: 0.982162\n",
      "batch 4920: loss 0.006456 accuracy: 0.982165\n",
      "batch 4921: loss 0.006786 accuracy: 0.982169\n",
      "batch 4922: loss 0.006708 accuracy: 0.982172\n",
      "batch 4923: loss 0.006067 accuracy: 0.982176\n",
      "batch 4924: loss 0.006573 accuracy: 0.982180\n",
      "batch 4925: loss 0.003700 accuracy: 0.982183\n",
      "batch 4926: loss 0.007671 accuracy: 0.982186\n",
      "batch 4927: loss 0.017758 accuracy: 0.982189\n",
      "batch 4928: loss 0.002124 accuracy: 0.982192\n",
      "batch 4929: loss 0.007300 accuracy: 0.982196\n",
      "batch 4930: loss 0.022753 accuracy: 0.982198\n",
      "batch 4931: loss 0.002301 accuracy: 0.982202\n",
      "batch 4932: loss 0.006848 accuracy: 0.982206\n",
      "batch 4933: loss 0.008330 accuracy: 0.982209\n",
      "batch 4934: loss 0.013841 accuracy: 0.982212\n",
      "batch 4935: loss 0.006696 accuracy: 0.982215\n",
      "batch 4936: loss 0.011745 accuracy: 0.982219\n",
      "batch 4937: loss 0.008331 accuracy: 0.982223\n",
      "batch 4938: loss 0.008383 accuracy: 0.982226\n",
      "batch 4939: loss 0.007099 accuracy: 0.982230\n",
      "batch 4940: loss 0.006915 accuracy: 0.982233\n",
      "batch 4941: loss 0.009657 accuracy: 0.982237\n",
      "batch 4942: loss 0.007145 accuracy: 0.982241\n",
      "batch 4943: loss 0.003642 accuracy: 0.982244\n",
      "batch 4944: loss 0.003405 accuracy: 0.982248\n",
      "batch 4945: loss 0.004574 accuracy: 0.982251\n",
      "batch 4946: loss 0.004924 accuracy: 0.982255\n",
      "batch 4947: loss 0.003374 accuracy: 0.982258\n",
      "batch 4948: loss 0.008810 accuracy: 0.982262\n",
      "batch 4949: loss 0.004995 accuracy: 0.982266\n",
      "batch 4950: loss 0.014733 accuracy: 0.982269\n",
      "batch 4951: loss 0.006512 accuracy: 0.982273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4952: loss 0.004843 accuracy: 0.982276\n",
      "batch 4953: loss 0.006064 accuracy: 0.982280\n",
      "batch 4954: loss 0.009491 accuracy: 0.982283\n",
      "batch 4955: loss 0.006645 accuracy: 0.982286\n",
      "batch 4956: loss 0.014181 accuracy: 0.982289\n",
      "batch 4957: loss 0.005048 accuracy: 0.982292\n",
      "batch 4958: loss 0.017945 accuracy: 0.982295\n",
      "batch 4959: loss 0.032795 accuracy: 0.982297\n",
      "batch 4960: loss 0.012130 accuracy: 0.982300\n",
      "batch 4961: loss 0.010544 accuracy: 0.982302\n",
      "batch 4962: loss 0.007870 accuracy: 0.982306\n",
      "batch 4963: loss 0.007819 accuracy: 0.982310\n",
      "batch 4964: loss 0.007241 accuracy: 0.982313\n",
      "batch 4965: loss 0.005094 accuracy: 0.982317\n",
      "batch 4966: loss 0.011945 accuracy: 0.982320\n",
      "batch 4967: loss 0.003840 accuracy: 0.982324\n",
      "batch 4968: loss 0.009972 accuracy: 0.982326\n",
      "batch 4969: loss 0.003712 accuracy: 0.982330\n",
      "batch 4970: loss 0.003391 accuracy: 0.982334\n",
      "batch 4971: loss 0.006452 accuracy: 0.982337\n",
      "batch 4972: loss 0.003370 accuracy: 0.982341\n",
      "batch 4973: loss 0.008779 accuracy: 0.982344\n",
      "batch 4974: loss 0.005923 accuracy: 0.982348\n",
      "batch 4975: loss 0.002953 accuracy: 0.982351\n",
      "batch 4976: loss 0.005456 accuracy: 0.982355\n",
      "batch 4977: loss 0.005415 accuracy: 0.982358\n",
      "batch 4978: loss 0.040131 accuracy: 0.982361\n",
      "batch 4979: loss 0.004405 accuracy: 0.982364\n",
      "batch 4980: loss 0.004239 accuracy: 0.982368\n",
      "batch 4981: loss 0.003545 accuracy: 0.982372\n",
      "batch 4982: loss 0.011047 accuracy: 0.982375\n",
      "batch 4983: loss 0.009355 accuracy: 0.982378\n",
      "batch 4984: loss 0.010625 accuracy: 0.982380\n",
      "batch 4985: loss 0.005730 accuracy: 0.982384\n",
      "batch 4986: loss 0.005612 accuracy: 0.982387\n",
      "batch 4987: loss 0.011976 accuracy: 0.982390\n",
      "batch 4988: loss 0.028443 accuracy: 0.982392\n",
      "batch 4989: loss 0.012342 accuracy: 0.982395\n",
      "batch 4990: loss 0.008637 accuracy: 0.982398\n",
      "batch 4991: loss 0.010916 accuracy: 0.982401\n",
      "batch 4992: loss 0.006473 accuracy: 0.982404\n",
      "batch 4993: loss 0.009470 accuracy: 0.982407\n",
      "batch 4994: loss 0.019933 accuracy: 0.982409\n",
      "batch 4995: loss 0.008668 accuracy: 0.982412\n",
      "batch 4996: loss 0.013224 accuracy: 0.982414\n",
      "batch 4997: loss 0.004497 accuracy: 0.982418\n",
      "batch 4998: loss 0.014661 accuracy: 0.982421\n",
      "batch 4999: loss 0.002622 accuracy: 0.982425\n",
      "batch 5000: loss 0.004741 accuracy: 0.982428\n",
      "model saved to ./save\\ckpt-5000\n",
      "batch 5001: loss 0.008114 accuracy: 0.982432\n",
      "batch 5002: loss 0.008487 accuracy: 0.982435\n",
      "batch 5003: loss 0.018961 accuracy: 0.982436\n",
      "batch 5004: loss 0.012259 accuracy: 0.982439\n",
      "batch 5005: loss 0.011413 accuracy: 0.982441\n",
      "batch 5006: loss 0.011591 accuracy: 0.982445\n",
      "batch 5007: loss 0.026525 accuracy: 0.982446\n",
      "batch 5008: loss 0.015522 accuracy: 0.982449\n",
      "batch 5009: loss 0.008868 accuracy: 0.982452\n",
      "batch 5010: loss 0.006584 accuracy: 0.982456\n",
      "batch 5011: loss 0.008829 accuracy: 0.982459\n",
      "batch 5012: loss 0.008883 accuracy: 0.982463\n",
      "batch 5013: loss 0.006937 accuracy: 0.982466\n",
      "batch 5014: loss 0.005968 accuracy: 0.982470\n",
      "batch 5015: loss 0.007409 accuracy: 0.982473\n",
      "batch 5016: loss 0.008518 accuracy: 0.982476\n",
      "batch 5017: loss 0.009217 accuracy: 0.982478\n",
      "batch 5018: loss 0.009842 accuracy: 0.982481\n",
      "batch 5019: loss 0.007921 accuracy: 0.982483\n",
      "batch 5020: loss 0.004910 accuracy: 0.982487\n",
      "batch 5021: loss 0.011706 accuracy: 0.982489\n",
      "batch 5022: loss 0.008540 accuracy: 0.982493\n",
      "batch 5023: loss 0.005521 accuracy: 0.982496\n",
      "batch 5024: loss 0.003753 accuracy: 0.982499\n",
      "batch 5025: loss 0.009428 accuracy: 0.982503\n",
      "batch 5026: loss 0.012223 accuracy: 0.982505\n",
      "batch 5027: loss 0.006475 accuracy: 0.982509\n",
      "batch 5028: loss 0.003334 accuracy: 0.982512\n",
      "batch 5029: loss 0.004904 accuracy: 0.982516\n",
      "batch 5030: loss 0.015568 accuracy: 0.982517\n",
      "batch 5031: loss 0.005064 accuracy: 0.982521\n",
      "batch 5032: loss 0.006707 accuracy: 0.982524\n",
      "batch 5033: loss 0.003237 accuracy: 0.982528\n",
      "batch 5034: loss 0.011049 accuracy: 0.982530\n",
      "batch 5035: loss 0.004798 accuracy: 0.982534\n",
      "batch 5036: loss 0.012000 accuracy: 0.982537\n",
      "batch 5037: loss 0.002503 accuracy: 0.982541\n",
      "batch 5038: loss 0.007912 accuracy: 0.982543\n",
      "batch 5039: loss 0.006420 accuracy: 0.982547\n",
      "batch 5040: loss 0.011423 accuracy: 0.982549\n",
      "batch 5041: loss 0.026133 accuracy: 0.982551\n",
      "batch 5042: loss 0.008703 accuracy: 0.982554\n",
      "batch 5043: loss 0.023502 accuracy: 0.982557\n",
      "batch 5044: loss 0.006052 accuracy: 0.982560\n",
      "batch 5045: loss 0.006966 accuracy: 0.982563\n",
      "batch 5046: loss 0.009320 accuracy: 0.982567\n",
      "batch 5047: loss 0.019105 accuracy: 0.982568\n",
      "batch 5048: loss 0.019470 accuracy: 0.982571\n",
      "batch 5049: loss 0.007866 accuracy: 0.982574\n",
      "batch 5050: loss 0.003038 accuracy: 0.982578\n",
      "batch 5051: loss 0.010666 accuracy: 0.982580\n",
      "batch 5052: loss 0.007398 accuracy: 0.982584\n",
      "batch 5053: loss 0.023119 accuracy: 0.982586\n",
      "batch 5054: loss 0.012988 accuracy: 0.982588\n",
      "batch 5055: loss 0.013362 accuracy: 0.982591\n",
      "batch 5056: loss 0.012625 accuracy: 0.982593\n",
      "batch 5057: loss 0.007829 accuracy: 0.982597\n",
      "batch 5058: loss 0.008644 accuracy: 0.982599\n",
      "batch 5059: loss 0.006045 accuracy: 0.982603\n",
      "batch 5060: loss 0.010698 accuracy: 0.982605\n",
      "batch 5061: loss 0.007654 accuracy: 0.982609\n",
      "batch 5062: loss 0.008151 accuracy: 0.982611\n",
      "batch 5063: loss 0.006581 accuracy: 0.982615\n",
      "batch 5064: loss 0.010949 accuracy: 0.982618\n",
      "batch 5065: loss 0.005429 accuracy: 0.982621\n",
      "batch 5066: loss 0.005775 accuracy: 0.982625\n",
      "batch 5067: loss 0.004689 accuracy: 0.982628\n",
      "batch 5068: loss 0.028179 accuracy: 0.982630\n",
      "batch 5069: loss 0.004284 accuracy: 0.982633\n",
      "batch 5070: loss 0.007594 accuracy: 0.982637\n",
      "batch 5071: loss 0.006598 accuracy: 0.982640\n",
      "batch 5072: loss 0.012221 accuracy: 0.982643\n",
      "batch 5073: loss 0.008554 accuracy: 0.982647\n",
      "batch 5074: loss 0.003078 accuracy: 0.982650\n",
      "batch 5075: loss 0.006212 accuracy: 0.982654\n",
      "batch 5076: loss 0.022302 accuracy: 0.982656\n",
      "batch 5077: loss 0.003643 accuracy: 0.982660\n",
      "batch 5078: loss 0.010390 accuracy: 0.982662\n",
      "batch 5079: loss 0.010951 accuracy: 0.982664\n",
      "batch 5080: loss 0.009015 accuracy: 0.982668\n",
      "batch 5081: loss 0.005908 accuracy: 0.982671\n",
      "batch 5082: loss 0.006407 accuracy: 0.982675\n",
      "batch 5083: loss 0.004721 accuracy: 0.982678\n",
      "batch 5084: loss 0.014826 accuracy: 0.982680\n",
      "batch 5085: loss 0.003149 accuracy: 0.982684\n",
      "batch 5086: loss 0.008593 accuracy: 0.982687\n",
      "batch 5087: loss 0.008600 accuracy: 0.982690\n",
      "batch 5088: loss 0.006763 accuracy: 0.982693\n",
      "batch 5089: loss 0.006234 accuracy: 0.982696\n",
      "batch 5090: loss 0.008449 accuracy: 0.982700\n",
      "batch 5091: loss 0.006979 accuracy: 0.982703\n",
      "batch 5092: loss 0.011941 accuracy: 0.982706\n",
      "batch 5093: loss 0.008701 accuracy: 0.982709\n",
      "batch 5094: loss 0.014521 accuracy: 0.982712\n",
      "batch 5095: loss 0.012009 accuracy: 0.982715\n",
      "batch 5096: loss 0.008746 accuracy: 0.982717\n",
      "batch 5097: loss 0.009763 accuracy: 0.982721\n",
      "batch 5098: loss 0.014924 accuracy: 0.982723\n",
      "batch 5099: loss 0.005598 accuracy: 0.982726\n",
      "batch 5100: loss 0.003238 accuracy: 0.982730\n",
      "model saved to ./save\\ckpt-5100\n",
      "batch 5101: loss 0.004860 accuracy: 0.982733\n",
      "batch 5102: loss 0.010338 accuracy: 0.982737\n",
      "batch 5103: loss 0.003219 accuracy: 0.982740\n",
      "batch 5104: loss 0.004231 accuracy: 0.982743\n",
      "batch 5105: loss 0.002684 accuracy: 0.982747\n",
      "batch 5106: loss 0.006640 accuracy: 0.982750\n",
      "batch 5107: loss 0.008887 accuracy: 0.982754\n",
      "batch 5108: loss 0.006675 accuracy: 0.982757\n",
      "batch 5109: loss 0.011472 accuracy: 0.982759\n",
      "batch 5110: loss 0.005755 accuracy: 0.982763\n",
      "batch 5111: loss 0.007054 accuracy: 0.982766\n",
      "batch 5112: loss 0.006151 accuracy: 0.982769\n",
      "batch 5113: loss 0.006012 accuracy: 0.982773\n",
      "batch 5114: loss 0.004589 accuracy: 0.982776\n",
      "batch 5115: loss 0.006661 accuracy: 0.982780\n",
      "batch 5116: loss 0.019485 accuracy: 0.982782\n",
      "batch 5117: loss 0.006480 accuracy: 0.982785\n",
      "batch 5118: loss 0.008526 accuracy: 0.982789\n",
      "batch 5119: loss 0.015135 accuracy: 0.982791\n",
      "batch 5120: loss 0.003764 accuracy: 0.982794\n",
      "batch 5121: loss 0.007295 accuracy: 0.982798\n",
      "batch 5122: loss 0.010491 accuracy: 0.982801\n",
      "batch 5123: loss 0.012764 accuracy: 0.982803\n",
      "batch 5124: loss 0.006469 accuracy: 0.982807\n",
      "batch 5125: loss 0.002838 accuracy: 0.982810\n",
      "batch 5126: loss 0.004477 accuracy: 0.982814\n",
      "batch 5127: loss 0.007058 accuracy: 0.982817\n",
      "batch 5128: loss 0.003418 accuracy: 0.982820\n",
      "batch 5129: loss 0.004693 accuracy: 0.982824\n",
      "batch 5130: loss 0.011585 accuracy: 0.982826\n",
      "batch 5131: loss 0.002986 accuracy: 0.982829\n",
      "batch 5132: loss 0.003817 accuracy: 0.982833\n",
      "batch 5133: loss 0.013741 accuracy: 0.982835\n",
      "batch 5134: loss 0.004733 accuracy: 0.982838\n",
      "batch 5135: loss 0.003311 accuracy: 0.982842\n",
      "batch 5136: loss 0.008378 accuracy: 0.982845\n",
      "batch 5137: loss 0.004627 accuracy: 0.982848\n",
      "batch 5138: loss 0.006645 accuracy: 0.982852\n",
      "batch 5139: loss 0.013302 accuracy: 0.982854\n",
      "batch 5140: loss 0.015117 accuracy: 0.982855\n",
      "batch 5141: loss 0.008993 accuracy: 0.982859\n",
      "batch 5142: loss 0.005334 accuracy: 0.982862\n",
      "batch 5143: loss 0.002575 accuracy: 0.982865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5144: loss 0.006863 accuracy: 0.982869\n",
      "batch 5145: loss 0.005075 accuracy: 0.982872\n",
      "batch 5146: loss 0.010018 accuracy: 0.982875\n",
      "batch 5147: loss 0.010983 accuracy: 0.982878\n",
      "batch 5148: loss 0.004415 accuracy: 0.982881\n",
      "batch 5149: loss 0.009131 accuracy: 0.982884\n",
      "batch 5150: loss 0.008141 accuracy: 0.982887\n",
      "batch 5151: loss 0.007938 accuracy: 0.982889\n",
      "batch 5152: loss 0.007666 accuracy: 0.982893\n",
      "batch 5153: loss 0.010496 accuracy: 0.982896\n",
      "batch 5154: loss 0.010298 accuracy: 0.982899\n",
      "batch 5155: loss 0.004927 accuracy: 0.982902\n",
      "batch 5156: loss 0.003895 accuracy: 0.982906\n",
      "batch 5157: loss 0.006890 accuracy: 0.982908\n",
      "batch 5158: loss 0.006827 accuracy: 0.982911\n",
      "batch 5159: loss 0.008030 accuracy: 0.982915\n",
      "batch 5160: loss 0.009254 accuracy: 0.982918\n",
      "batch 5161: loss 0.007497 accuracy: 0.982921\n",
      "batch 5162: loss 0.002639 accuracy: 0.982925\n",
      "batch 5163: loss 0.008237 accuracy: 0.982928\n",
      "batch 5164: loss 0.014015 accuracy: 0.982930\n",
      "batch 5165: loss 0.006182 accuracy: 0.982934\n",
      "batch 5166: loss 0.006468 accuracy: 0.982937\n",
      "batch 5167: loss 0.003672 accuracy: 0.982940\n",
      "batch 5168: loss 0.007901 accuracy: 0.982944\n",
      "batch 5169: loss 0.013911 accuracy: 0.982946\n",
      "batch 5170: loss 0.011438 accuracy: 0.982949\n",
      "batch 5171: loss 0.006107 accuracy: 0.982952\n",
      "batch 5172: loss 0.003496 accuracy: 0.982956\n",
      "batch 5173: loss 0.010851 accuracy: 0.982959\n",
      "batch 5174: loss 0.015604 accuracy: 0.982960\n",
      "batch 5175: loss 0.003566 accuracy: 0.982964\n",
      "batch 5176: loss 0.003252 accuracy: 0.982967\n",
      "batch 5177: loss 0.004683 accuracy: 0.982970\n",
      "batch 5178: loss 0.004659 accuracy: 0.982974\n",
      "batch 5179: loss 0.004896 accuracy: 0.982977\n",
      "batch 5180: loss 0.008467 accuracy: 0.982980\n",
      "batch 5181: loss 0.009010 accuracy: 0.982983\n",
      "batch 5182: loss 0.017951 accuracy: 0.982986\n",
      "batch 5183: loss 0.037971 accuracy: 0.982986\n",
      "batch 5184: loss 0.004761 accuracy: 0.982989\n",
      "batch 5185: loss 0.006197 accuracy: 0.982993\n",
      "batch 5186: loss 0.008093 accuracy: 0.982996\n",
      "batch 5187: loss 0.009688 accuracy: 0.982999\n",
      "batch 5188: loss 0.005936 accuracy: 0.983002\n",
      "batch 5189: loss 0.004802 accuracy: 0.983006\n",
      "batch 5190: loss 0.008091 accuracy: 0.983009\n",
      "batch 5191: loss 0.023767 accuracy: 0.983011\n",
      "batch 5192: loss 0.003943 accuracy: 0.983015\n",
      "batch 5193: loss 0.014035 accuracy: 0.983017\n",
      "batch 5194: loss 0.007950 accuracy: 0.983019\n",
      "batch 5195: loss 0.013052 accuracy: 0.983022\n",
      "batch 5196: loss 0.002821 accuracy: 0.983025\n",
      "batch 5197: loss 0.002099 accuracy: 0.983028\n",
      "batch 5198: loss 0.006083 accuracy: 0.983031\n",
      "batch 5199: loss 0.005356 accuracy: 0.983035\n",
      "batch 5200: loss 0.024459 accuracy: 0.983036\n",
      "model saved to ./save\\ckpt-5200\n",
      "batch 5201: loss 0.007151 accuracy: 0.983039\n",
      "batch 5202: loss 0.006919 accuracy: 0.983042\n",
      "batch 5203: loss 0.025987 accuracy: 0.983044\n",
      "batch 5204: loss 0.035215 accuracy: 0.983045\n",
      "batch 5205: loss 0.003834 accuracy: 0.983048\n",
      "batch 5206: loss 0.008565 accuracy: 0.983051\n",
      "batch 5207: loss 0.004208 accuracy: 0.983054\n",
      "batch 5208: loss 0.004842 accuracy: 0.983057\n",
      "batch 5209: loss 0.009209 accuracy: 0.983060\n",
      "batch 5210: loss 0.004535 accuracy: 0.983064\n",
      "batch 5211: loss 0.004133 accuracy: 0.983067\n",
      "batch 5212: loss 0.018855 accuracy: 0.983069\n",
      "batch 5213: loss 0.004217 accuracy: 0.983073\n",
      "batch 5214: loss 0.006018 accuracy: 0.983076\n",
      "batch 5215: loss 0.012077 accuracy: 0.983079\n",
      "batch 5216: loss 0.015544 accuracy: 0.983080\n",
      "batch 5217: loss 0.008090 accuracy: 0.983084\n",
      "batch 5218: loss 0.007743 accuracy: 0.983086\n",
      "batch 5219: loss 0.004381 accuracy: 0.983089\n",
      "batch 5220: loss 0.006686 accuracy: 0.983092\n",
      "batch 5221: loss 0.012105 accuracy: 0.983095\n",
      "batch 5222: loss 0.004029 accuracy: 0.983098\n",
      "batch 5223: loss 0.010599 accuracy: 0.983100\n",
      "batch 5224: loss 0.008896 accuracy: 0.983103\n",
      "batch 5225: loss 0.006610 accuracy: 0.983107\n",
      "batch 5226: loss 0.006474 accuracy: 0.983110\n",
      "batch 5227: loss 0.009724 accuracy: 0.983112\n",
      "batch 5228: loss 0.003803 accuracy: 0.983115\n",
      "batch 5229: loss 0.003970 accuracy: 0.983119\n",
      "batch 5230: loss 0.008241 accuracy: 0.983122\n",
      "batch 5231: loss 0.002602 accuracy: 0.983125\n",
      "batch 5232: loss 0.003707 accuracy: 0.983128\n",
      "batch 5233: loss 0.004480 accuracy: 0.983131\n",
      "batch 5234: loss 0.005190 accuracy: 0.983135\n",
      "batch 5235: loss 0.018735 accuracy: 0.983137\n",
      "batch 5236: loss 0.004096 accuracy: 0.983140\n",
      "batch 5237: loss 0.007351 accuracy: 0.983143\n",
      "batch 5238: loss 0.008992 accuracy: 0.983147\n",
      "batch 5239: loss 0.006821 accuracy: 0.983150\n",
      "batch 5240: loss 0.006324 accuracy: 0.983153\n",
      "batch 5241: loss 0.005473 accuracy: 0.983156\n",
      "batch 5242: loss 0.010059 accuracy: 0.983158\n",
      "batch 5243: loss 0.006751 accuracy: 0.983162\n",
      "batch 5244: loss 0.004570 accuracy: 0.983165\n",
      "batch 5245: loss 0.011405 accuracy: 0.983168\n",
      "batch 5246: loss 0.014116 accuracy: 0.983170\n",
      "batch 5247: loss 0.011451 accuracy: 0.983174\n",
      "batch 5248: loss 0.007016 accuracy: 0.983177\n",
      "batch 5249: loss 0.002734 accuracy: 0.983180\n",
      "batch 5250: loss 0.008476 accuracy: 0.983183\n",
      "batch 5251: loss 0.005455 accuracy: 0.983186\n",
      "batch 5252: loss 0.008154 accuracy: 0.983190\n",
      "batch 5253: loss 0.005106 accuracy: 0.983193\n",
      "batch 5254: loss 0.011335 accuracy: 0.983195\n",
      "batch 5255: loss 0.008818 accuracy: 0.983198\n",
      "batch 5256: loss 0.010518 accuracy: 0.983200\n",
      "batch 5257: loss 0.005094 accuracy: 0.983204\n",
      "batch 5258: loss 0.005505 accuracy: 0.983207\n",
      "batch 5259: loss 0.005141 accuracy: 0.983210\n",
      "batch 5260: loss 0.011999 accuracy: 0.983213\n",
      "batch 5261: loss 0.009765 accuracy: 0.983216\n",
      "batch 5262: loss 0.006585 accuracy: 0.983219\n",
      "batch 5263: loss 0.004900 accuracy: 0.983222\n",
      "batch 5264: loss 0.039741 accuracy: 0.983224\n",
      "batch 5265: loss 0.004781 accuracy: 0.983227\n",
      "batch 5266: loss 0.012287 accuracy: 0.983230\n",
      "batch 5267: loss 0.010135 accuracy: 0.983233\n",
      "batch 5268: loss 0.007007 accuracy: 0.983236\n",
      "batch 5269: loss 0.007328 accuracy: 0.983239\n",
      "batch 5270: loss 0.006622 accuracy: 0.983241\n",
      "batch 5271: loss 0.011749 accuracy: 0.983244\n",
      "batch 5272: loss 0.017043 accuracy: 0.983246\n",
      "batch 5273: loss 0.011315 accuracy: 0.983249\n",
      "batch 5274: loss 0.013776 accuracy: 0.983251\n",
      "batch 5275: loss 0.001767 accuracy: 0.983254\n",
      "batch 5276: loss 0.005394 accuracy: 0.983258\n",
      "batch 5277: loss 0.005654 accuracy: 0.983261\n",
      "batch 5278: loss 0.010118 accuracy: 0.983264\n",
      "batch 5279: loss 0.008789 accuracy: 0.983267\n",
      "batch 5280: loss 0.011188 accuracy: 0.983270\n",
      "batch 5281: loss 0.007991 accuracy: 0.983273\n",
      "batch 5282: loss 0.006703 accuracy: 0.983277\n",
      "batch 5283: loss 0.003778 accuracy: 0.983280\n",
      "batch 5284: loss 0.007083 accuracy: 0.983283\n",
      "batch 5285: loss 0.010929 accuracy: 0.983285\n",
      "batch 5286: loss 0.007054 accuracy: 0.983288\n",
      "batch 5287: loss 0.022411 accuracy: 0.983290\n",
      "batch 5288: loss 0.012023 accuracy: 0.983292\n",
      "batch 5289: loss 0.003803 accuracy: 0.983295\n",
      "batch 5290: loss 0.017542 accuracy: 0.983297\n",
      "batch 5291: loss 0.006286 accuracy: 0.983300\n",
      "batch 5292: loss 0.011634 accuracy: 0.983303\n",
      "batch 5293: loss 0.011387 accuracy: 0.983306\n",
      "batch 5294: loss 0.005809 accuracy: 0.983309\n",
      "batch 5295: loss 0.006472 accuracy: 0.983312\n",
      "batch 5296: loss 0.011140 accuracy: 0.983313\n",
      "batch 5297: loss 0.006290 accuracy: 0.983316\n",
      "batch 5298: loss 0.007652 accuracy: 0.983320\n",
      "batch 5299: loss 0.006545 accuracy: 0.983323\n",
      "batch 5300: loss 0.009148 accuracy: 0.983326\n",
      "model saved to ./save\\ckpt-5300\n",
      "batch 5301: loss 0.002921 accuracy: 0.983329\n",
      "batch 5302: loss 0.006352 accuracy: 0.983332\n",
      "batch 5303: loss 0.008789 accuracy: 0.983335\n",
      "batch 5304: loss 0.005276 accuracy: 0.983338\n",
      "batch 5305: loss 0.009952 accuracy: 0.983341\n",
      "batch 5306: loss 0.003877 accuracy: 0.983344\n",
      "batch 5307: loss 0.008074 accuracy: 0.983346\n",
      "batch 5308: loss 0.002487 accuracy: 0.983349\n",
      "batch 5309: loss 0.008574 accuracy: 0.983352\n",
      "batch 5310: loss 0.003523 accuracy: 0.983355\n",
      "batch 5311: loss 0.003632 accuracy: 0.983358\n",
      "batch 5312: loss 0.005836 accuracy: 0.983362\n",
      "batch 5313: loss 0.005220 accuracy: 0.983365\n",
      "batch 5314: loss 0.008125 accuracy: 0.983368\n",
      "batch 5315: loss 0.008752 accuracy: 0.983371\n",
      "batch 5316: loss 0.005536 accuracy: 0.983374\n",
      "batch 5317: loss 0.005028 accuracy: 0.983377\n",
      "batch 5318: loss 0.021395 accuracy: 0.983379\n",
      "batch 5319: loss 0.004077 accuracy: 0.983383\n",
      "batch 5320: loss 0.008003 accuracy: 0.983386\n",
      "batch 5321: loss 0.002843 accuracy: 0.983389\n",
      "batch 5322: loss 0.004025 accuracy: 0.983392\n",
      "batch 5323: loss 0.016671 accuracy: 0.983394\n",
      "batch 5324: loss 0.006537 accuracy: 0.983397\n",
      "batch 5325: loss 0.006357 accuracy: 0.983400\n",
      "batch 5326: loss 0.002030 accuracy: 0.983403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5327: loss 0.006853 accuracy: 0.983407\n",
      "batch 5328: loss 0.007569 accuracy: 0.983410\n",
      "batch 5329: loss 0.008454 accuracy: 0.983412\n",
      "batch 5330: loss 0.003462 accuracy: 0.983415\n",
      "batch 5331: loss 0.002968 accuracy: 0.983418\n",
      "batch 5332: loss 0.002910 accuracy: 0.983421\n",
      "batch 5333: loss 0.006240 accuracy: 0.983424\n",
      "batch 5334: loss 0.014603 accuracy: 0.983426\n",
      "batch 5335: loss 0.003323 accuracy: 0.983430\n",
      "batch 5336: loss 0.004619 accuracy: 0.983433\n",
      "batch 5337: loss 0.007926 accuracy: 0.983436\n",
      "batch 5338: loss 0.011607 accuracy: 0.983438\n",
      "batch 5339: loss 0.011986 accuracy: 0.983441\n",
      "batch 5340: loss 0.006551 accuracy: 0.983444\n",
      "batch 5341: loss 0.004817 accuracy: 0.983447\n",
      "batch 5342: loss 0.005436 accuracy: 0.983450\n",
      "batch 5343: loss 0.007859 accuracy: 0.983453\n",
      "batch 5344: loss 0.001517 accuracy: 0.983456\n",
      "batch 5345: loss 0.004891 accuracy: 0.983460\n",
      "batch 5346: loss 0.004194 accuracy: 0.983463\n",
      "batch 5347: loss 0.010658 accuracy: 0.983465\n",
      "batch 5348: loss 0.004316 accuracy: 0.983468\n",
      "batch 5349: loss 0.004069 accuracy: 0.983471\n",
      "batch 5350: loss 0.003003 accuracy: 0.983474\n",
      "batch 5351: loss 0.017273 accuracy: 0.983476\n",
      "batch 5352: loss 0.004291 accuracy: 0.983479\n",
      "batch 5353: loss 0.003836 accuracy: 0.983482\n",
      "batch 5354: loss 0.005311 accuracy: 0.983486\n",
      "batch 5355: loss 0.013492 accuracy: 0.983488\n",
      "batch 5356: loss 0.005801 accuracy: 0.983491\n",
      "batch 5357: loss 0.006331 accuracy: 0.983494\n",
      "batch 5358: loss 0.004965 accuracy: 0.983497\n",
      "batch 5359: loss 0.002553 accuracy: 0.983500\n",
      "batch 5360: loss 0.011760 accuracy: 0.983503\n",
      "batch 5361: loss 0.007300 accuracy: 0.983506\n",
      "batch 5362: loss 0.003309 accuracy: 0.983509\n",
      "batch 5363: loss 0.007342 accuracy: 0.983512\n",
      "batch 5364: loss 0.002381 accuracy: 0.983515\n",
      "batch 5365: loss 0.007389 accuracy: 0.983518\n",
      "batch 5366: loss 0.003154 accuracy: 0.983522\n",
      "batch 5367: loss 0.003301 accuracy: 0.983525\n",
      "batch 5368: loss 0.007380 accuracy: 0.983528\n",
      "batch 5369: loss 0.003029 accuracy: 0.983531\n",
      "batch 5370: loss 0.004080 accuracy: 0.983534\n",
      "batch 5371: loss 0.004217 accuracy: 0.983537\n",
      "batch 5372: loss 0.009213 accuracy: 0.983539\n",
      "batch 5373: loss 0.005601 accuracy: 0.983542\n",
      "batch 5374: loss 0.006391 accuracy: 0.983545\n",
      "batch 5375: loss 0.005343 accuracy: 0.983548\n",
      "batch 5376: loss 0.005053 accuracy: 0.983551\n",
      "batch 5377: loss 0.003958 accuracy: 0.983554\n",
      "batch 5378: loss 0.007752 accuracy: 0.983557\n",
      "batch 5379: loss 0.009270 accuracy: 0.983559\n",
      "batch 5380: loss 0.010754 accuracy: 0.983562\n",
      "batch 5381: loss 0.007724 accuracy: 0.983564\n",
      "batch 5382: loss 0.009854 accuracy: 0.983566\n",
      "batch 5383: loss 0.005116 accuracy: 0.983569\n",
      "batch 5384: loss 0.003673 accuracy: 0.983572\n",
      "batch 5385: loss 0.003973 accuracy: 0.983575\n",
      "batch 5386: loss 0.006560 accuracy: 0.983578\n",
      "batch 5387: loss 0.007679 accuracy: 0.983581\n",
      "batch 5388: loss 0.011101 accuracy: 0.983583\n",
      "batch 5389: loss 0.009104 accuracy: 0.983586\n",
      "batch 5390: loss 0.005384 accuracy: 0.983589\n",
      "batch 5391: loss 0.004136 accuracy: 0.983592\n",
      "batch 5392: loss 0.006748 accuracy: 0.983595\n",
      "batch 5393: loss 0.004011 accuracy: 0.983598\n",
      "batch 5394: loss 0.007747 accuracy: 0.983602\n",
      "batch 5395: loss 0.007541 accuracy: 0.983604\n",
      "batch 5396: loss 0.003226 accuracy: 0.983607\n",
      "batch 5397: loss 0.007191 accuracy: 0.983609\n",
      "batch 5398: loss 0.003124 accuracy: 0.983612\n",
      "batch 5399: loss 0.027036 accuracy: 0.983614\n",
      "batch 5400: loss 0.003115 accuracy: 0.983617\n",
      "model saved to ./save\\ckpt-5400\n",
      "batch 5401: loss 0.005926 accuracy: 0.983620\n",
      "batch 5402: loss 0.009215 accuracy: 0.983623\n",
      "batch 5403: loss 0.002539 accuracy: 0.983626\n",
      "batch 5404: loss 0.002879 accuracy: 0.983629\n",
      "batch 5405: loss 0.005865 accuracy: 0.983632\n",
      "batch 5406: loss 0.009913 accuracy: 0.983634\n",
      "batch 5407: loss 0.002611 accuracy: 0.983637\n",
      "batch 5408: loss 0.011529 accuracy: 0.983639\n",
      "batch 5409: loss 0.004527 accuracy: 0.983642\n",
      "batch 5410: loss 0.002337 accuracy: 0.983645\n",
      "batch 5411: loss 0.005632 accuracy: 0.983648\n",
      "batch 5412: loss 0.003450 accuracy: 0.983651\n",
      "batch 5413: loss 0.007022 accuracy: 0.983654\n",
      "batch 5414: loss 0.007625 accuracy: 0.983657\n",
      "batch 5415: loss 0.005673 accuracy: 0.983660\n",
      "batch 5416: loss 0.003364 accuracy: 0.983663\n",
      "batch 5417: loss 0.004980 accuracy: 0.983666\n",
      "batch 5418: loss 0.005998 accuracy: 0.983670\n",
      "batch 5419: loss 0.004226 accuracy: 0.983672\n",
      "batch 5420: loss 0.007442 accuracy: 0.983676\n",
      "batch 5421: loss 0.004706 accuracy: 0.983679\n",
      "batch 5422: loss 0.002556 accuracy: 0.983682\n",
      "batch 5423: loss 0.007384 accuracy: 0.983685\n",
      "batch 5424: loss 0.003412 accuracy: 0.983688\n",
      "batch 5425: loss 0.004020 accuracy: 0.983691\n",
      "batch 5426: loss 0.004646 accuracy: 0.983694\n",
      "batch 5427: loss 0.005917 accuracy: 0.983697\n",
      "batch 5428: loss 0.004345 accuracy: 0.983700\n",
      "batch 5429: loss 0.001987 accuracy: 0.983703\n",
      "batch 5430: loss 0.006683 accuracy: 0.983706\n",
      "batch 5431: loss 0.002912 accuracy: 0.983709\n",
      "batch 5432: loss 0.004607 accuracy: 0.983712\n",
      "batch 5433: loss 0.003054 accuracy: 0.983715\n",
      "batch 5434: loss 0.003302 accuracy: 0.983718\n",
      "batch 5435: loss 0.006965 accuracy: 0.983721\n",
      "batch 5436: loss 0.006610 accuracy: 0.983724\n",
      "batch 5437: loss 0.008437 accuracy: 0.983727\n",
      "batch 5438: loss 0.007970 accuracy: 0.983729\n",
      "batch 5439: loss 0.007089 accuracy: 0.983732\n",
      "batch 5440: loss 0.004131 accuracy: 0.983735\n",
      "batch 5441: loss 0.003886 accuracy: 0.983738\n",
      "batch 5442: loss 0.004693 accuracy: 0.983741\n",
      "batch 5443: loss 0.003884 accuracy: 0.983744\n",
      "batch 5444: loss 0.005208 accuracy: 0.983747\n",
      "batch 5445: loss 0.004385 accuracy: 0.983750\n",
      "batch 5446: loss 0.003246 accuracy: 0.983753\n",
      "batch 5447: loss 0.009649 accuracy: 0.983755\n",
      "batch 5448: loss 0.007746 accuracy: 0.983758\n",
      "batch 5449: loss 0.011097 accuracy: 0.983760\n",
      "batch 5450: loss 0.003778 accuracy: 0.983763\n",
      "batch 5451: loss 0.008688 accuracy: 0.983765\n",
      "batch 5452: loss 0.005305 accuracy: 0.983768\n",
      "batch 5453: loss 0.004508 accuracy: 0.983771\n",
      "batch 5454: loss 0.035034 accuracy: 0.983771\n",
      "batch 5455: loss 0.015835 accuracy: 0.983773\n",
      "batch 5456: loss 0.006464 accuracy: 0.983776\n",
      "batch 5457: loss 0.005119 accuracy: 0.983779\n",
      "batch 5458: loss 0.005445 accuracy: 0.983782\n",
      "batch 5459: loss 0.008946 accuracy: 0.983785\n",
      "batch 5460: loss 0.009697 accuracy: 0.983787\n",
      "batch 5461: loss 0.002444 accuracy: 0.983790\n",
      "batch 5462: loss 0.006236 accuracy: 0.983793\n",
      "batch 5463: loss 0.006851 accuracy: 0.983796\n",
      "batch 5464: loss 0.004850 accuracy: 0.983799\n",
      "batch 5465: loss 0.011941 accuracy: 0.983801\n",
      "batch 5466: loss 0.003623 accuracy: 0.983804\n",
      "batch 5467: loss 0.005236 accuracy: 0.983807\n",
      "batch 5468: loss 0.005168 accuracy: 0.983810\n",
      "batch 5469: loss 0.012451 accuracy: 0.983812\n",
      "batch 5470: loss 0.014435 accuracy: 0.983814\n",
      "batch 5471: loss 0.001771 accuracy: 0.983817\n",
      "batch 5472: loss 0.005452 accuracy: 0.983820\n",
      "batch 5473: loss 0.003593 accuracy: 0.983823\n",
      "batch 5474: loss 0.007502 accuracy: 0.983826\n",
      "batch 5475: loss 0.004119 accuracy: 0.983829\n",
      "batch 5476: loss 0.005649 accuracy: 0.983831\n",
      "batch 5477: loss 0.008315 accuracy: 0.983834\n",
      "batch 5478: loss 0.006232 accuracy: 0.983837\n",
      "batch 5479: loss 0.005039 accuracy: 0.983840\n",
      "batch 5480: loss 0.004204 accuracy: 0.983843\n",
      "batch 5481: loss 0.004153 accuracy: 0.983846\n",
      "batch 5482: loss 0.005044 accuracy: 0.983849\n",
      "batch 5483: loss 0.009134 accuracy: 0.983852\n",
      "batch 5484: loss 0.004539 accuracy: 0.983855\n",
      "batch 5485: loss 0.008758 accuracy: 0.983858\n",
      "batch 5486: loss 0.003764 accuracy: 0.983861\n",
      "batch 5487: loss 0.004297 accuracy: 0.983864\n",
      "batch 5488: loss 0.005504 accuracy: 0.983867\n",
      "batch 5489: loss 0.012698 accuracy: 0.983869\n",
      "batch 5490: loss 0.007926 accuracy: 0.983872\n",
      "batch 5491: loss 0.007192 accuracy: 0.983874\n",
      "batch 5492: loss 0.002449 accuracy: 0.983877\n",
      "batch 5493: loss 0.010156 accuracy: 0.983879\n",
      "batch 5494: loss 0.003051 accuracy: 0.983882\n",
      "batch 5495: loss 0.004158 accuracy: 0.983885\n",
      "batch 5496: loss 0.002146 accuracy: 0.983888\n",
      "batch 5497: loss 0.008062 accuracy: 0.983890\n",
      "batch 5498: loss 0.004778 accuracy: 0.983893\n",
      "batch 5499: loss 0.009486 accuracy: 0.983895\n",
      "batch 5500: loss 0.004629 accuracy: 0.983898\n",
      "model saved to ./save\\ckpt-5500\n",
      "batch 5501: loss 0.007101 accuracy: 0.983901\n",
      "batch 5502: loss 0.012739 accuracy: 0.983903\n",
      "batch 5503: loss 0.003407 accuracy: 0.983906\n",
      "batch 5504: loss 0.010165 accuracy: 0.983909\n",
      "batch 5505: loss 0.010905 accuracy: 0.983912\n",
      "batch 5506: loss 0.005154 accuracy: 0.983915\n",
      "batch 5507: loss 0.004611 accuracy: 0.983918\n",
      "batch 5508: loss 0.003819 accuracy: 0.983921\n",
      "batch 5509: loss 0.005116 accuracy: 0.983924\n",
      "batch 5510: loss 0.009559 accuracy: 0.983926\n",
      "batch 5511: loss 0.005283 accuracy: 0.983929\n",
      "batch 5512: loss 0.002310 accuracy: 0.983932\n",
      "batch 5513: loss 0.014468 accuracy: 0.983934\n",
      "batch 5514: loss 0.010657 accuracy: 0.983936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5515: loss 0.006083 accuracy: 0.983939\n",
      "batch 5516: loss 0.003026 accuracy: 0.983941\n",
      "batch 5517: loss 0.005096 accuracy: 0.983944\n",
      "batch 5518: loss 0.003250 accuracy: 0.983947\n",
      "batch 5519: loss 0.003782 accuracy: 0.983950\n",
      "batch 5520: loss 0.004804 accuracy: 0.983953\n",
      "batch 5521: loss 0.004948 accuracy: 0.983956\n",
      "batch 5522: loss 0.002322 accuracy: 0.983959\n",
      "batch 5523: loss 0.005494 accuracy: 0.983962\n",
      "batch 5524: loss 0.004000 accuracy: 0.983965\n",
      "batch 5525: loss 0.003411 accuracy: 0.983968\n",
      "batch 5526: loss 0.005552 accuracy: 0.983971\n",
      "batch 5527: loss 0.009796 accuracy: 0.983973\n",
      "batch 5528: loss 0.006337 accuracy: 0.983976\n",
      "batch 5529: loss 0.003340 accuracy: 0.983979\n",
      "batch 5530: loss 0.005606 accuracy: 0.983982\n",
      "batch 5531: loss 0.003412 accuracy: 0.983985\n",
      "batch 5532: loss 0.012770 accuracy: 0.983987\n",
      "batch 5533: loss 0.012004 accuracy: 0.983990\n",
      "batch 5534: loss 0.004838 accuracy: 0.983993\n",
      "batch 5535: loss 0.004359 accuracy: 0.983996\n",
      "batch 5536: loss 0.004156 accuracy: 0.983999\n",
      "batch 5537: loss 0.008706 accuracy: 0.984001\n",
      "batch 5538: loss 0.019370 accuracy: 0.984003\n",
      "batch 5539: loss 0.008458 accuracy: 0.984005\n",
      "batch 5540: loss 0.004814 accuracy: 0.984008\n",
      "batch 5541: loss 0.004952 accuracy: 0.984011\n",
      "batch 5542: loss 0.004921 accuracy: 0.984014\n",
      "batch 5543: loss 0.006744 accuracy: 0.984017\n",
      "batch 5544: loss 0.009401 accuracy: 0.984019\n",
      "batch 5545: loss 0.013950 accuracy: 0.984021\n",
      "batch 5546: loss 0.007501 accuracy: 0.984024\n",
      "batch 5547: loss 0.006404 accuracy: 0.984027\n",
      "batch 5548: loss 0.011919 accuracy: 0.984029\n",
      "batch 5549: loss 0.005332 accuracy: 0.984032\n",
      "batch 5550: loss 0.007939 accuracy: 0.984034\n",
      "batch 5551: loss 0.007568 accuracy: 0.984037\n",
      "batch 5552: loss 0.007587 accuracy: 0.984040\n",
      "batch 5553: loss 0.006629 accuracy: 0.984043\n",
      "batch 5554: loss 0.004927 accuracy: 0.984046\n",
      "batch 5555: loss 0.019087 accuracy: 0.984048\n",
      "batch 5556: loss 0.006325 accuracy: 0.984051\n",
      "batch 5557: loss 0.004121 accuracy: 0.984054\n",
      "batch 5558: loss 0.007027 accuracy: 0.984056\n",
      "batch 5559: loss 0.004401 accuracy: 0.984059\n",
      "batch 5560: loss 0.005734 accuracy: 0.984062\n",
      "batch 5561: loss 0.004081 accuracy: 0.984065\n",
      "batch 5562: loss 0.002944 accuracy: 0.984068\n",
      "batch 5563: loss 0.019390 accuracy: 0.984070\n",
      "batch 5564: loss 0.005364 accuracy: 0.984073\n",
      "batch 5565: loss 0.006356 accuracy: 0.984076\n",
      "batch 5566: loss 0.005046 accuracy: 0.984079\n",
      "batch 5567: loss 0.005197 accuracy: 0.984081\n",
      "batch 5568: loss 0.015166 accuracy: 0.984083\n",
      "batch 5569: loss 0.002216 accuracy: 0.984086\n",
      "batch 5570: loss 0.013493 accuracy: 0.984088\n",
      "batch 5571: loss 0.002744 accuracy: 0.984091\n",
      "batch 5572: loss 0.003113 accuracy: 0.984094\n",
      "batch 5573: loss 0.005039 accuracy: 0.984097\n",
      "batch 5574: loss 0.007501 accuracy: 0.984100\n",
      "batch 5575: loss 0.009536 accuracy: 0.984102\n",
      "batch 5576: loss 0.003714 accuracy: 0.984105\n",
      "batch 5577: loss 0.003819 accuracy: 0.984108\n",
      "batch 5578: loss 0.007839 accuracy: 0.984111\n",
      "batch 5579: loss 0.003578 accuracy: 0.984114\n",
      "batch 5580: loss 0.007509 accuracy: 0.984117\n",
      "batch 5581: loss 0.003672 accuracy: 0.984119\n",
      "batch 5582: loss 0.002075 accuracy: 0.984122\n",
      "batch 5583: loss 0.004406 accuracy: 0.984125\n",
      "batch 5584: loss 0.003364 accuracy: 0.984128\n",
      "batch 5585: loss 0.036074 accuracy: 0.984128\n",
      "batch 5586: loss 0.004027 accuracy: 0.984131\n",
      "batch 5587: loss 0.005459 accuracy: 0.984134\n",
      "batch 5588: loss 0.004466 accuracy: 0.984137\n",
      "batch 5589: loss 0.008001 accuracy: 0.984140\n",
      "batch 5590: loss 0.012354 accuracy: 0.984141\n",
      "batch 5591: loss 0.007560 accuracy: 0.984143\n",
      "batch 5592: loss 0.002325 accuracy: 0.984146\n",
      "batch 5593: loss 0.004690 accuracy: 0.984149\n",
      "batch 5594: loss 0.005057 accuracy: 0.984152\n",
      "batch 5595: loss 0.006426 accuracy: 0.984155\n",
      "batch 5596: loss 0.004290 accuracy: 0.984158\n",
      "batch 5597: loss 0.004113 accuracy: 0.984160\n",
      "batch 5598: loss 0.008734 accuracy: 0.984163\n",
      "batch 5599: loss 0.004927 accuracy: 0.984166\n",
      "batch 5600: loss 0.024774 accuracy: 0.984167\n",
      "model saved to ./save\\ckpt-5600\n",
      "batch 5601: loss 0.012763 accuracy: 0.984169\n",
      "batch 5602: loss 0.004749 accuracy: 0.984172\n",
      "batch 5603: loss 0.002488 accuracy: 0.984175\n",
      "batch 5604: loss 0.003983 accuracy: 0.984178\n",
      "batch 5605: loss 0.008133 accuracy: 0.984180\n",
      "batch 5606: loss 0.007773 accuracy: 0.984183\n",
      "batch 5607: loss 0.001951 accuracy: 0.984186\n",
      "batch 5608: loss 0.003244 accuracy: 0.984189\n",
      "batch 5609: loss 0.010523 accuracy: 0.984192\n",
      "batch 5610: loss 0.011953 accuracy: 0.984194\n",
      "batch 5611: loss 0.006252 accuracy: 0.984196\n",
      "batch 5612: loss 0.003540 accuracy: 0.984199\n",
      "batch 5613: loss 0.004910 accuracy: 0.984202\n",
      "batch 5614: loss 0.003191 accuracy: 0.984205\n",
      "batch 5615: loss 0.021831 accuracy: 0.984206\n",
      "batch 5616: loss 0.008448 accuracy: 0.984209\n",
      "batch 5617: loss 0.005127 accuracy: 0.984211\n",
      "batch 5618: loss 0.022361 accuracy: 0.984213\n",
      "batch 5619: loss 0.008784 accuracy: 0.984216\n",
      "batch 5620: loss 0.006102 accuracy: 0.984219\n",
      "batch 5621: loss 0.007168 accuracy: 0.984222\n",
      "batch 5622: loss 0.008555 accuracy: 0.984224\n",
      "batch 5623: loss 0.005984 accuracy: 0.984227\n",
      "batch 5624: loss 0.011937 accuracy: 0.984229\n",
      "batch 5625: loss 0.004866 accuracy: 0.984232\n",
      "batch 5626: loss 0.009730 accuracy: 0.984235\n",
      "batch 5627: loss 0.003033 accuracy: 0.984238\n",
      "batch 5628: loss 0.007683 accuracy: 0.984240\n",
      "batch 5629: loss 0.005470 accuracy: 0.984242\n",
      "batch 5630: loss 0.005598 accuracy: 0.984245\n",
      "batch 5631: loss 0.003858 accuracy: 0.984248\n",
      "batch 5632: loss 0.002557 accuracy: 0.984251\n",
      "batch 5633: loss 0.007084 accuracy: 0.984254\n",
      "batch 5634: loss 0.008293 accuracy: 0.984256\n",
      "batch 5635: loss 0.002791 accuracy: 0.984259\n",
      "batch 5636: loss 0.005167 accuracy: 0.984262\n",
      "batch 5637: loss 0.006622 accuracy: 0.984265\n",
      "batch 5638: loss 0.019940 accuracy: 0.984267\n",
      "batch 5639: loss 0.006473 accuracy: 0.984269\n",
      "batch 5640: loss 0.004833 accuracy: 0.984272\n",
      "batch 5641: loss 0.004664 accuracy: 0.984275\n",
      "batch 5642: loss 0.011502 accuracy: 0.984277\n",
      "batch 5643: loss 0.013466 accuracy: 0.984279\n",
      "batch 5644: loss 0.005389 accuracy: 0.984282\n",
      "batch 5645: loss 0.005410 accuracy: 0.984284\n",
      "batch 5646: loss 0.006209 accuracy: 0.984287\n",
      "batch 5647: loss 0.003626 accuracy: 0.984290\n",
      "batch 5648: loss 0.010242 accuracy: 0.984292\n",
      "batch 5649: loss 0.005198 accuracy: 0.984295\n",
      "batch 5650: loss 0.005654 accuracy: 0.984297\n",
      "batch 5651: loss 0.005940 accuracy: 0.984300\n",
      "batch 5652: loss 0.047948 accuracy: 0.984301\n",
      "batch 5653: loss 0.009642 accuracy: 0.984303\n",
      "batch 5654: loss 0.002469 accuracy: 0.984306\n",
      "batch 5655: loss 0.007341 accuracy: 0.984309\n",
      "batch 5656: loss 0.007353 accuracy: 0.984311\n",
      "batch 5657: loss 0.008297 accuracy: 0.984314\n",
      "batch 5658: loss 0.005819 accuracy: 0.984317\n",
      "batch 5659: loss 0.002282 accuracy: 0.984320\n",
      "batch 5660: loss 0.002695 accuracy: 0.984323\n",
      "batch 5661: loss 0.002080 accuracy: 0.984325\n",
      "batch 5662: loss 0.010972 accuracy: 0.984327\n",
      "batch 5663: loss 0.004181 accuracy: 0.984330\n",
      "batch 5664: loss 0.003933 accuracy: 0.984333\n",
      "batch 5665: loss 0.015224 accuracy: 0.984335\n",
      "batch 5666: loss 0.006503 accuracy: 0.984337\n",
      "batch 5667: loss 0.013320 accuracy: 0.984339\n",
      "batch 5668: loss 0.005700 accuracy: 0.984342\n",
      "batch 5669: loss 0.006263 accuracy: 0.984345\n",
      "batch 5670: loss 0.005921 accuracy: 0.984348\n",
      "batch 5671: loss 0.004486 accuracy: 0.984350\n",
      "batch 5672: loss 0.006848 accuracy: 0.984353\n",
      "batch 5673: loss 0.001782 accuracy: 0.984356\n",
      "batch 5674: loss 0.012740 accuracy: 0.984359\n",
      "batch 5675: loss 0.003584 accuracy: 0.984361\n",
      "batch 5676: loss 0.004464 accuracy: 0.984364\n",
      "batch 5677: loss 0.003081 accuracy: 0.984367\n",
      "batch 5678: loss 0.003642 accuracy: 0.984370\n",
      "batch 5679: loss 0.004275 accuracy: 0.984372\n",
      "batch 5680: loss 0.016162 accuracy: 0.984374\n",
      "batch 5681: loss 0.083629 accuracy: 0.984376\n",
      "batch 5682: loss 0.013790 accuracy: 0.984377\n",
      "batch 5683: loss 0.004765 accuracy: 0.984380\n",
      "batch 5684: loss 0.005662 accuracy: 0.984383\n",
      "batch 5685: loss 0.008577 accuracy: 0.984384\n",
      "batch 5686: loss 0.001893 accuracy: 0.984387\n",
      "batch 5687: loss 0.006135 accuracy: 0.984390\n",
      "batch 5688: loss 0.002045 accuracy: 0.984393\n",
      "batch 5689: loss 0.007133 accuracy: 0.984395\n",
      "batch 5690: loss 0.011249 accuracy: 0.984397\n",
      "batch 5691: loss 0.001972 accuracy: 0.984400\n",
      "batch 5692: loss 0.001564 accuracy: 0.984403\n",
      "batch 5693: loss 0.003829 accuracy: 0.984406\n",
      "batch 5694: loss 0.008234 accuracy: 0.984407\n",
      "batch 5695: loss 0.004944 accuracy: 0.984410\n",
      "batch 5696: loss 0.006138 accuracy: 0.984412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5697: loss 0.009669 accuracy: 0.984415\n",
      "batch 5698: loss 0.008845 accuracy: 0.984417\n",
      "batch 5699: loss 0.002927 accuracy: 0.984420\n",
      "batch 5700: loss 0.010463 accuracy: 0.984422\n",
      "model saved to ./save\\ckpt-5700\n",
      "batch 5701: loss 0.006136 accuracy: 0.984425\n",
      "batch 5702: loss 0.007046 accuracy: 0.984428\n",
      "batch 5703: loss 0.015252 accuracy: 0.984430\n",
      "batch 5704: loss 0.004222 accuracy: 0.984433\n",
      "batch 5705: loss 0.001816 accuracy: 0.984436\n",
      "batch 5706: loss 0.004467 accuracy: 0.984438\n",
      "batch 5707: loss 0.002949 accuracy: 0.984441\n",
      "batch 5708: loss 0.029153 accuracy: 0.984443\n",
      "batch 5709: loss 0.005642 accuracy: 0.984446\n",
      "batch 5710: loss 0.003275 accuracy: 0.984448\n",
      "batch 5711: loss 0.004992 accuracy: 0.984451\n",
      "batch 5712: loss 0.004332 accuracy: 0.984454\n",
      "batch 5713: loss 0.003835 accuracy: 0.984457\n",
      "batch 5714: loss 0.006291 accuracy: 0.984459\n",
      "batch 5715: loss 0.006479 accuracy: 0.984462\n",
      "batch 5716: loss 0.002942 accuracy: 0.984465\n",
      "batch 5717: loss 0.004671 accuracy: 0.984467\n",
      "batch 5718: loss 0.003859 accuracy: 0.984470\n",
      "batch 5719: loss 0.003812 accuracy: 0.984473\n",
      "batch 5720: loss 0.003189 accuracy: 0.984476\n",
      "batch 5721: loss 0.002483 accuracy: 0.984478\n",
      "batch 5722: loss 0.006332 accuracy: 0.984481\n",
      "batch 5723: loss 0.006503 accuracy: 0.984484\n",
      "batch 5724: loss 0.007407 accuracy: 0.984486\n",
      "batch 5725: loss 0.004772 accuracy: 0.984489\n",
      "batch 5726: loss 0.005191 accuracy: 0.984492\n",
      "batch 5727: loss 0.003079 accuracy: 0.984495\n",
      "batch 5728: loss 0.012481 accuracy: 0.984496\n",
      "batch 5729: loss 0.003671 accuracy: 0.984498\n",
      "batch 5730: loss 0.006255 accuracy: 0.984501\n",
      "batch 5731: loss 0.005144 accuracy: 0.984504\n",
      "batch 5732: loss 0.003749 accuracy: 0.984506\n",
      "batch 5733: loss 0.003139 accuracy: 0.984509\n",
      "batch 5734: loss 0.002956 accuracy: 0.984512\n",
      "batch 5735: loss 0.003923 accuracy: 0.984514\n",
      "batch 5736: loss 0.007063 accuracy: 0.984517\n",
      "batch 5737: loss 0.002046 accuracy: 0.984520\n",
      "batch 5738: loss 0.003705 accuracy: 0.984523\n",
      "batch 5739: loss 0.002847 accuracy: 0.984525\n",
      "batch 5740: loss 0.003124 accuracy: 0.984528\n",
      "batch 5741: loss 0.003886 accuracy: 0.984531\n",
      "batch 5742: loss 0.001846 accuracy: 0.984533\n",
      "batch 5743: loss 0.002693 accuracy: 0.984536\n",
      "batch 5744: loss 0.003685 accuracy: 0.984539\n",
      "batch 5745: loss 0.006412 accuracy: 0.984541\n",
      "batch 5746: loss 0.004852 accuracy: 0.984544\n",
      "batch 5747: loss 0.009471 accuracy: 0.984546\n",
      "batch 5748: loss 0.006911 accuracy: 0.984549\n",
      "batch 5749: loss 0.003319 accuracy: 0.984551\n",
      "batch 5750: loss 0.005068 accuracy: 0.984554\n",
      "batch 5751: loss 0.004620 accuracy: 0.984557\n",
      "batch 5752: loss 0.003346 accuracy: 0.984559\n",
      "batch 5753: loss 0.003747 accuracy: 0.984562\n",
      "batch 5754: loss 0.006034 accuracy: 0.984565\n",
      "batch 5755: loss 0.004108 accuracy: 0.984567\n",
      "batch 5756: loss 0.008349 accuracy: 0.984570\n",
      "batch 5757: loss 0.003336 accuracy: 0.984573\n",
      "batch 5758: loss 0.002549 accuracy: 0.984575\n",
      "batch 5759: loss 0.009296 accuracy: 0.984578\n",
      "batch 5760: loss 0.010826 accuracy: 0.984580\n",
      "batch 5761: loss 0.005865 accuracy: 0.984583\n",
      "batch 5762: loss 0.007366 accuracy: 0.984585\n",
      "batch 5763: loss 0.017145 accuracy: 0.984587\n",
      "batch 5764: loss 0.004430 accuracy: 0.984590\n",
      "batch 5765: loss 0.007119 accuracy: 0.984592\n",
      "batch 5766: loss 0.003694 accuracy: 0.984595\n",
      "batch 5767: loss 0.006683 accuracy: 0.984598\n",
      "batch 5768: loss 0.005973 accuracy: 0.984600\n",
      "batch 5769: loss 0.007325 accuracy: 0.984602\n",
      "batch 5770: loss 0.007294 accuracy: 0.984605\n",
      "batch 5771: loss 0.002271 accuracy: 0.984608\n",
      "batch 5772: loss 0.002360 accuracy: 0.984610\n",
      "batch 5773: loss 0.004346 accuracy: 0.984613\n",
      "batch 5774: loss 0.003529 accuracy: 0.984616\n",
      "batch 5775: loss 0.001297 accuracy: 0.984618\n",
      "batch 5776: loss 0.005990 accuracy: 0.984621\n",
      "batch 5777: loss 0.004355 accuracy: 0.984624\n",
      "batch 5778: loss 0.004070 accuracy: 0.984626\n",
      "batch 5779: loss 0.007390 accuracy: 0.984629\n",
      "batch 5780: loss 0.004887 accuracy: 0.984632\n",
      "batch 5781: loss 0.008288 accuracy: 0.984634\n",
      "batch 5782: loss 0.003947 accuracy: 0.984637\n",
      "batch 5783: loss 0.005098 accuracy: 0.984640\n",
      "batch 5784: loss 0.002869 accuracy: 0.984642\n",
      "batch 5785: loss 0.004401 accuracy: 0.984645\n",
      "batch 5786: loss 0.003681 accuracy: 0.984648\n",
      "batch 5787: loss 0.001305 accuracy: 0.984650\n",
      "batch 5788: loss 0.007724 accuracy: 0.984653\n",
      "batch 5789: loss 0.005883 accuracy: 0.984655\n",
      "batch 5790: loss 0.002701 accuracy: 0.984658\n",
      "batch 5791: loss 0.017698 accuracy: 0.984660\n",
      "batch 5792: loss 0.003187 accuracy: 0.984663\n",
      "batch 5793: loss 0.004219 accuracy: 0.984665\n",
      "batch 5794: loss 0.008729 accuracy: 0.984668\n",
      "batch 5795: loss 0.004640 accuracy: 0.984670\n",
      "batch 5796: loss 0.004112 accuracy: 0.984673\n",
      "batch 5797: loss 0.006258 accuracy: 0.984676\n",
      "batch 5798: loss 0.004742 accuracy: 0.984678\n",
      "batch 5799: loss 0.005637 accuracy: 0.984681\n",
      "batch 5800: loss 0.007108 accuracy: 0.984684\n",
      "model saved to ./save\\ckpt-5800\n",
      "batch 5801: loss 0.001643 accuracy: 0.984686\n",
      "batch 5802: loss 0.014234 accuracy: 0.984689\n",
      "batch 5803: loss 0.010442 accuracy: 0.984691\n",
      "batch 5804: loss 0.005222 accuracy: 0.984693\n",
      "batch 5805: loss 0.004209 accuracy: 0.984696\n",
      "batch 5806: loss 0.016538 accuracy: 0.984698\n",
      "batch 5807: loss 0.006673 accuracy: 0.984700\n",
      "batch 5808: loss 0.010539 accuracy: 0.984701\n",
      "batch 5809: loss 0.006280 accuracy: 0.984704\n",
      "batch 5810: loss 0.013190 accuracy: 0.984705\n",
      "batch 5811: loss 0.003308 accuracy: 0.984707\n",
      "batch 5812: loss 0.008830 accuracy: 0.984710\n",
      "batch 5813: loss 0.011231 accuracy: 0.984712\n",
      "batch 5814: loss 0.003322 accuracy: 0.984715\n",
      "batch 5815: loss 0.007258 accuracy: 0.984717\n",
      "batch 5816: loss 0.007836 accuracy: 0.984720\n",
      "batch 5817: loss 0.003983 accuracy: 0.984722\n",
      "batch 5818: loss 0.005846 accuracy: 0.984725\n",
      "batch 5819: loss 0.008854 accuracy: 0.984727\n",
      "batch 5820: loss 0.011505 accuracy: 0.984729\n",
      "batch 5821: loss 0.005461 accuracy: 0.984731\n",
      "batch 5822: loss 0.014544 accuracy: 0.984733\n",
      "batch 5823: loss 0.011238 accuracy: 0.984734\n",
      "batch 5824: loss 0.001984 accuracy: 0.984737\n",
      "batch 5825: loss 0.003641 accuracy: 0.984739\n",
      "batch 5826: loss 0.005101 accuracy: 0.984742\n",
      "batch 5827: loss 0.006194 accuracy: 0.984744\n",
      "batch 5828: loss 0.008988 accuracy: 0.984747\n",
      "batch 5829: loss 0.003823 accuracy: 0.984750\n",
      "batch 5830: loss 0.007058 accuracy: 0.984751\n",
      "batch 5831: loss 0.006677 accuracy: 0.984754\n",
      "batch 5832: loss 0.001878 accuracy: 0.984757\n",
      "batch 5833: loss 0.004180 accuracy: 0.984759\n",
      "batch 5834: loss 0.004180 accuracy: 0.984762\n",
      "batch 5835: loss 0.006301 accuracy: 0.984764\n",
      "batch 5836: loss 0.006621 accuracy: 0.984767\n",
      "batch 5837: loss 0.004979 accuracy: 0.984770\n",
      "batch 5838: loss 0.002534 accuracy: 0.984772\n",
      "batch 5839: loss 0.007647 accuracy: 0.984774\n",
      "batch 5840: loss 0.007678 accuracy: 0.984777\n",
      "batch 5841: loss 0.005350 accuracy: 0.984779\n",
      "batch 5842: loss 0.009597 accuracy: 0.984782\n",
      "batch 5843: loss 0.001822 accuracy: 0.984784\n",
      "batch 5844: loss 0.002721 accuracy: 0.984787\n",
      "batch 5845: loss 0.003375 accuracy: 0.984790\n",
      "batch 5846: loss 0.009439 accuracy: 0.984791\n",
      "batch 5847: loss 0.006807 accuracy: 0.984794\n",
      "batch 5848: loss 0.087546 accuracy: 0.984796\n",
      "batch 5849: loss 0.003629 accuracy: 0.984798\n",
      "batch 5850: loss 0.013286 accuracy: 0.984800\n",
      "batch 5851: loss 0.001397 accuracy: 0.984803\n",
      "batch 5852: loss 0.003444 accuracy: 0.984805\n",
      "batch 5853: loss 0.012548 accuracy: 0.984807\n",
      "batch 5854: loss 0.005428 accuracy: 0.984810\n",
      "batch 5855: loss 0.006008 accuracy: 0.984812\n",
      "batch 5856: loss 0.008918 accuracy: 0.984815\n",
      "batch 5857: loss 0.012634 accuracy: 0.984816\n",
      "batch 5858: loss 0.004602 accuracy: 0.984819\n",
      "batch 5859: loss 0.006785 accuracy: 0.984822\n",
      "batch 5860: loss 0.003722 accuracy: 0.984824\n",
      "batch 5861: loss 0.006893 accuracy: 0.984827\n",
      "batch 5862: loss 0.003881 accuracy: 0.984829\n",
      "batch 5863: loss 0.014033 accuracy: 0.984831\n",
      "batch 5864: loss 0.003369 accuracy: 0.984834\n",
      "batch 5865: loss 0.005859 accuracy: 0.984836\n",
      "batch 5866: loss 0.004270 accuracy: 0.984839\n",
      "batch 5867: loss 0.006920 accuracy: 0.984842\n",
      "batch 5868: loss 0.006708 accuracy: 0.984844\n",
      "batch 5869: loss 0.004836 accuracy: 0.984847\n",
      "batch 5870: loss 0.004625 accuracy: 0.984849\n",
      "batch 5871: loss 0.010357 accuracy: 0.984850\n",
      "batch 5872: loss 0.009567 accuracy: 0.984853\n",
      "batch 5873: loss 0.003809 accuracy: 0.984855\n",
      "batch 5874: loss 0.006079 accuracy: 0.984858\n",
      "batch 5875: loss 0.006811 accuracy: 0.984860\n",
      "batch 5876: loss 0.003183 accuracy: 0.984863\n",
      "batch 5877: loss 0.003758 accuracy: 0.984866\n",
      "batch 5878: loss 0.024290 accuracy: 0.984867\n",
      "batch 5879: loss 0.004678 accuracy: 0.984870\n",
      "batch 5880: loss 0.005168 accuracy: 0.984872\n",
      "batch 5881: loss 0.004127 accuracy: 0.984875\n",
      "batch 5882: loss 0.005966 accuracy: 0.984878\n",
      "batch 5883: loss 0.005878 accuracy: 0.984880\n",
      "batch 5884: loss 0.003343 accuracy: 0.984883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5885: loss 0.011333 accuracy: 0.984885\n",
      "batch 5886: loss 0.012039 accuracy: 0.984887\n",
      "batch 5887: loss 0.002435 accuracy: 0.984890\n",
      "batch 5888: loss 0.010515 accuracy: 0.984891\n",
      "batch 5889: loss 0.004425 accuracy: 0.984894\n",
      "batch 5890: loss 0.003007 accuracy: 0.984896\n",
      "batch 5891: loss 0.006264 accuracy: 0.984899\n",
      "batch 5892: loss 0.004073 accuracy: 0.984902\n",
      "batch 5893: loss 0.007077 accuracy: 0.984903\n",
      "batch 5894: loss 0.008696 accuracy: 0.984905\n",
      "batch 5895: loss 0.007659 accuracy: 0.984907\n",
      "batch 5896: loss 0.001705 accuracy: 0.984909\n",
      "batch 5897: loss 0.007120 accuracy: 0.984912\n",
      "batch 5898: loss 0.006315 accuracy: 0.984914\n",
      "batch 5899: loss 0.006484 accuracy: 0.984917\n",
      "batch 5900: loss 0.002106 accuracy: 0.984919\n",
      "model saved to ./save\\ckpt-5900\n",
      "batch 5901: loss 0.011074 accuracy: 0.984921\n",
      "batch 5902: loss 0.005378 accuracy: 0.984924\n",
      "batch 5903: loss 0.017370 accuracy: 0.984925\n",
      "batch 5904: loss 0.007893 accuracy: 0.984927\n",
      "batch 5905: loss 0.008117 accuracy: 0.984930\n",
      "batch 5906: loss 0.008403 accuracy: 0.984931\n",
      "batch 5907: loss 0.003542 accuracy: 0.984934\n",
      "batch 5908: loss 0.002876 accuracy: 0.984937\n",
      "batch 5909: loss 0.004438 accuracy: 0.984939\n",
      "batch 5910: loss 0.004330 accuracy: 0.984942\n",
      "batch 5911: loss 0.018033 accuracy: 0.984943\n",
      "batch 5912: loss 0.002607 accuracy: 0.984946\n",
      "batch 5913: loss 0.007889 accuracy: 0.984948\n",
      "batch 5914: loss 0.008190 accuracy: 0.984951\n",
      "batch 5915: loss 0.002327 accuracy: 0.984954\n",
      "batch 5916: loss 0.003167 accuracy: 0.984956\n",
      "batch 5917: loss 0.006516 accuracy: 0.984959\n",
      "batch 5918: loss 0.002649 accuracy: 0.984961\n",
      "batch 5919: loss 0.001607 accuracy: 0.984964\n",
      "batch 5920: loss 0.002640 accuracy: 0.984966\n",
      "batch 5921: loss 0.004172 accuracy: 0.984969\n",
      "batch 5922: loss 0.005220 accuracy: 0.984971\n",
      "batch 5923: loss 0.003629 accuracy: 0.984974\n",
      "batch 5924: loss 0.002918 accuracy: 0.984976\n",
      "batch 5925: loss 0.004475 accuracy: 0.984979\n",
      "batch 5926: loss 0.001964 accuracy: 0.984981\n",
      "batch 5927: loss 0.007933 accuracy: 0.984984\n",
      "batch 5928: loss 0.005739 accuracy: 0.984986\n",
      "batch 5929: loss 0.008236 accuracy: 0.984989\n",
      "batch 5930: loss 0.005369 accuracy: 0.984992\n",
      "batch 5931: loss 0.003592 accuracy: 0.984994\n",
      "batch 5932: loss 0.003160 accuracy: 0.984997\n",
      "batch 5933: loss 0.003155 accuracy: 0.984999\n",
      "batch 5934: loss 0.003775 accuracy: 0.985002\n",
      "batch 5935: loss 0.003722 accuracy: 0.985004\n",
      "batch 5936: loss 0.002970 accuracy: 0.985007\n",
      "batch 5937: loss 0.009117 accuracy: 0.985008\n",
      "batch 5938: loss 0.003173 accuracy: 0.985011\n",
      "batch 5939: loss 0.005542 accuracy: 0.985013\n",
      "batch 5940: loss 0.003767 accuracy: 0.985016\n",
      "batch 5941: loss 0.002624 accuracy: 0.985018\n",
      "batch 5942: loss 0.004790 accuracy: 0.985020\n",
      "batch 5943: loss 0.004343 accuracy: 0.985023\n",
      "batch 5944: loss 0.002829 accuracy: 0.985025\n",
      "batch 5945: loss 0.005193 accuracy: 0.985028\n",
      "batch 5946: loss 0.004387 accuracy: 0.985030\n",
      "batch 5947: loss 0.006160 accuracy: 0.985033\n",
      "batch 5948: loss 0.005306 accuracy: 0.985035\n",
      "batch 5949: loss 0.003810 accuracy: 0.985038\n",
      "batch 5950: loss 0.003394 accuracy: 0.985040\n",
      "batch 5951: loss 0.004771 accuracy: 0.985043\n",
      "batch 5952: loss 0.004765 accuracy: 0.985045\n",
      "batch 5953: loss 0.003377 accuracy: 0.985048\n",
      "batch 5954: loss 0.004036 accuracy: 0.985050\n",
      "batch 5955: loss 0.008094 accuracy: 0.985052\n",
      "batch 5956: loss 0.003263 accuracy: 0.985055\n",
      "batch 5957: loss 0.003525 accuracy: 0.985057\n",
      "batch 5958: loss 0.007620 accuracy: 0.985060\n",
      "batch 5959: loss 0.006995 accuracy: 0.985062\n",
      "batch 5960: loss 0.010371 accuracy: 0.985064\n",
      "batch 5961: loss 0.003204 accuracy: 0.985066\n",
      "batch 5962: loss 0.007073 accuracy: 0.985069\n",
      "batch 5963: loss 0.003403 accuracy: 0.985071\n",
      "batch 5964: loss 0.003076 accuracy: 0.985074\n",
      "batch 5965: loss 0.005234 accuracy: 0.985076\n",
      "batch 5966: loss 0.002788 accuracy: 0.985079\n",
      "batch 5967: loss 0.002891 accuracy: 0.985081\n",
      "batch 5968: loss 0.003214 accuracy: 0.985084\n",
      "batch 5969: loss 0.004879 accuracy: 0.985086\n",
      "batch 5970: loss 0.006043 accuracy: 0.985088\n",
      "batch 5971: loss 0.005788 accuracy: 0.985090\n",
      "batch 5972: loss 0.003886 accuracy: 0.985093\n",
      "batch 5973: loss 0.006386 accuracy: 0.985095\n",
      "batch 5974: loss 0.002801 accuracy: 0.985098\n",
      "batch 5975: loss 0.004659 accuracy: 0.985100\n",
      "batch 5976: loss 0.004293 accuracy: 0.985103\n",
      "batch 5977: loss 0.003533 accuracy: 0.985105\n",
      "batch 5978: loss 0.003611 accuracy: 0.985108\n",
      "batch 5979: loss 0.003784 accuracy: 0.985110\n",
      "batch 5980: loss 0.001685 accuracy: 0.985113\n",
      "batch 5981: loss 0.003089 accuracy: 0.985115\n",
      "batch 5982: loss 0.000922 accuracy: 0.985118\n",
      "batch 5983: loss 0.002589 accuracy: 0.985120\n",
      "batch 5984: loss 0.004594 accuracy: 0.985123\n",
      "batch 5985: loss 0.002167 accuracy: 0.985125\n",
      "batch 5986: loss 0.005122 accuracy: 0.985128\n",
      "batch 5987: loss 0.007901 accuracy: 0.985129\n",
      "batch 5988: loss 0.003261 accuracy: 0.985132\n",
      "batch 5989: loss 0.007304 accuracy: 0.985134\n",
      "batch 5990: loss 0.005160 accuracy: 0.985137\n",
      "batch 5991: loss 0.002670 accuracy: 0.985139\n",
      "batch 5992: loss 0.002118 accuracy: 0.985142\n",
      "batch 5993: loss 0.002353 accuracy: 0.985144\n",
      "batch 5994: loss 0.012092 accuracy: 0.985146\n",
      "batch 5995: loss 0.002870 accuracy: 0.985148\n",
      "batch 5996: loss 0.009933 accuracy: 0.985150\n",
      "batch 5997: loss 0.001445 accuracy: 0.985153\n",
      "batch 5998: loss 0.002261 accuracy: 0.985155\n",
      "batch 5999: loss 0.002839 accuracy: 0.985157\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train()\n",
    "    #test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.980800\n"
     ]
    }
   ],
   "source": [
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist 极简\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, verbose=1)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:{}, acc:{}'.format(test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
