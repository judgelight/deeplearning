{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "num_epochs = 8\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "data_dir = './data/cats-vs-dogs/'\n",
    "train_cats_dir = data_dir + 'train/cats/'\n",
    "train_dogs_dir = data_dir + 'train/dogs/'\n",
    "test_cats_dir = data_dir + 'valid/cats/'\n",
    "test_dogs_dir = data_dir + 'valid/dogs/'\n",
    "checkpoint_path = \"training_1/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "def _decode_and_resize(filename, label):\n",
    "    image_string = tf.io.read_file(filename)                   # 读取原始文件\n",
    "    image_decoded = tf.image.decode_jpeg(image_string)         # 解码JPEG图片\n",
    "    image_resized = tf.image.resize(image_decoded, [225, 225]) / 255.0\n",
    "    return image_resized, label\n",
    "\n",
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_7x7x64s2 = self.conv2d(7, 64, 2)\n",
    "        self.pool3x3 = tf.keras.layers.MaxPool2D(pool_size=[3, 3], strides=2, padding='same')\n",
    "        \n",
    "        # inception1\n",
    "        self.conv_1x1x64_in1 = self.conv2d(1, 64, 1)\n",
    "        self.conv_1x1x32_in1 = self.conv2d(1, 32, 1)\n",
    "        self.conv_3x3x64_in1 = self.conv2d(3, 64, 1)\n",
    "        self.conv_1x1x16_in1 = self.conv2d(1, 16, 1)\n",
    "        self.conv_5x5x32_in1 = self.conv2d(5, 32, 1)\n",
    "        self.pool3x3s1_in1 = tf.keras.layers.MaxPool2D(pool_size=[3, 3], strides=1, padding='same')\n",
    "        self.conv_1x1x32_in12 = self.conv2d(1, 64, 1)\n",
    "        self.pool2x2_in1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "        \n",
    "        # inception2\n",
    "        self.conv_1x1x128_in2 = self.conv2d(1, 128, 1)\n",
    "        self.conv_1x1x64_in2 = self.conv2d(1, 64, 1)\n",
    "        self.conv_3x3x128_in2 = self.conv2d(3, 128, 1)\n",
    "        self.conv_1x1x32_in2 = self.conv2d(1, 32, 1)\n",
    "        self.conv_5x5x64_in2 = self.conv2d(5, 64, 1)\n",
    "        self.pool3x3s1_in2 = tf.keras.layers.MaxPool2D(pool_size=[3, 3], strides=1, padding='same')\n",
    "        self.conv_1x1x64_in22 = self.conv2d(1, 64, 1)\n",
    "        self.pool2x2_in2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "        \n",
    "        # inception3\n",
    "        self.conv_1x1x128_in3 = self.conv2d(1, 128, 1)\n",
    "        self.conv_1x1x64_in3 = self.conv2d(1, 64, 1)\n",
    "        self.conv_3x3x128_in3 = self.conv2d(3, 128, 1)\n",
    "        self.conv_1x1x32_in3 = self.conv2d(1, 32, 1)\n",
    "        self.conv_5x5x64_in3 = self.conv2d(5, 64, 1)\n",
    "        self.pool3x3s1_in3 = tf.keras.layers.MaxPool2D(pool_size=[3, 3], strides=1, padding='same')\n",
    "        self.conv_1x1x64_in32 = self.conv2d(1, 64, 1)\n",
    "        self.pool2x2_in3 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "        \n",
    "        # inception4\n",
    "        self.conv_1x1x256_in4 = self.conv2d(1, 256, 1)\n",
    "        self.conv_1x1x64_in4 = self.conv2d(1, 64, 1)\n",
    "        self.conv_3x3x256_in4 = self.conv2d(3, 256, 1)\n",
    "        self.conv_1x1x32_in4 = self.conv2d(1, 32, 1)\n",
    "        self.conv_5x5x128_in4 = self.conv2d(5, 128, 1)\n",
    "        self.pool3x3s1_in4 = tf.keras.layers.MaxPool2D(pool_size=[3, 3], strides=1, padding='same')\n",
    "        self.conv_1x1x128_in4 = self.conv2d(1, 128, 1)\n",
    "        \n",
    "        self.concatenate = tf.keras.layers.Concatenate()\n",
    "\n",
    "        self.avgpool7x7 = tf.keras.layers.AveragePooling2D(pool_size=[7, 7])\n",
    "        self.flatten = tf.keras.layers.Reshape(target_shape=(1 * 1 * 768,))\n",
    "        #self.avgpool = tf.keras.layers.GlobalAveragePooling2D  可以直接把每个特征图所有像素取一个均值点，\n",
    "                                                                #代替上面的AveragePooling2D+Reshape\n",
    "                                                                #output shape:(batch_size, channels)\n",
    "        self.dense1 = tf.keras.layers.Dense(units=256, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    def conv2d(self, size, filters, stride):\n",
    "        return tf.keras.layers.Conv2D(\n",
    "            filters = filters,\n",
    "            kernel_size = [size, size],\n",
    "            strides = (stride, stride),\n",
    "            padding = 'same',\n",
    "            activation = tf.nn.relu\n",
    "        )\n",
    "\n",
    "    def inception1(self, inputs):\n",
    "        x1 = self.conv_1x1x64_in1(inputs)\n",
    "        x2 = self.conv_1x1x32_in1(inputs)\n",
    "        x2 = self.conv_3x3x64_in1(x2)\n",
    "        x3 = self.conv_1x1x16_in1(inputs)\n",
    "        x3 = self.conv_5x5x32_in1(x3)\n",
    "        x4 = self.pool3x3s1_in1(inputs)\n",
    "        x4 = self.conv_1x1x32_in12(x4)\n",
    "        output = self.concatenate([x1, x2, x3, x4])\n",
    "        return output\n",
    "\n",
    "    def inception2(self, inputs):\n",
    "        x1 = self.conv_1x1x128_in2(inputs)\n",
    "        x2 = self.conv_1x1x64_in2(inputs)\n",
    "        x2 = self.conv_3x3x128_in2(x2)\n",
    "        x3 = self.conv_1x1x32_in2(inputs)\n",
    "        x3 = self.conv_5x5x64_in2(x3)\n",
    "        x4 = self.pool3x3s1_in2(inputs)\n",
    "        x4 = self.conv_1x1x64_in22(x4)\n",
    "        output = self.concatenate([x1, x2, x3, x4])\n",
    "        return output\n",
    "\n",
    "    def inception3(self, inputs):\n",
    "        x1 = self.conv_1x1x128_in3(inputs)\n",
    "        x2 = self.conv_1x1x64_in3(inputs)\n",
    "        x2 = self.conv_3x3x128_in3(x2)\n",
    "        x3 = self.conv_1x1x32_in3(inputs)\n",
    "        x3 = self.conv_5x5x64_in3(x3)\n",
    "        x4 = self.pool3x3s1_in3(inputs)\n",
    "        x4 = self.conv_1x1x64_in32(x4)\n",
    "        output = self.concatenate([x1, x2, x3, x4])\n",
    "        return output\n",
    "\n",
    "    def inception4(self, inputs):\n",
    "        x1 = self.conv_1x1x256_in4(inputs)\n",
    "        x2 = self.conv_1x1x64_in4(inputs)\n",
    "        x2 = self.conv_3x3x256_in4(x2)\n",
    "        x3 = self.conv_1x1x32_in4(inputs)\n",
    "        x3 = self.conv_5x5x128_in4(x3)\n",
    "        x4 = self.pool3x3s1_in4(inputs)\n",
    "        x4 = self.conv_1x1x128_in4(x4)\n",
    "        output = self.concatenate([x1, x2, x3, x4])\n",
    "        return output\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv_7x7x64s2(inputs)    # [112, 112, 64]\n",
    "        x = self.pool3x3(x)    # [56, 56, 64]\n",
    "        x = self.inception1(x) # [56, 56, 192]\n",
    "        x = self.pool2x2_in1(x)    # [28, 28, 192]\n",
    "        x = self.inception2(x) # [28, 28, 384]\n",
    "        x = self.pool2x2_in2(x)    # [14, 14, 384]\n",
    "        x = self.inception3(x) # [14, 14, 384]\n",
    "        x = self.pool2x2_in3(x)    # [7, 7, 384]\n",
    "        x = self.inception4(x) # [7, 7, 768]\n",
    "        x = self.avgpool7x7(x)    # [1, 1, 768]\n",
    "        x = self.flatten(x)   # [1*1*768]\n",
    "        x = self.dense1(x)    # [256]\n",
    "        x = self.dense2(x)    # [10]\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output\n",
    "\n",
    "def train_and_checkpoint(net, manager):\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    if manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "\n",
    "    for example in toy_dataset():\n",
    "        loss = train_step(net, example, opt)\n",
    "        ckpt.step.assign_add(1)\n",
    "        if int(ckpt.step) % 10 == 0:\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
    "            print(\"loss {:1.2f}\".format(loss.numpy()))\n",
    "\n",
    "def train():\n",
    "    # 构建训练数据集\n",
    "    train_cat_filenames = tf.constant([train_cats_dir + filename for filename in os.listdir(train_cats_dir)])\n",
    "    train_dog_filenames = tf.constant([train_dogs_dir + filename for filename in os.listdir(train_dogs_dir)])\n",
    "    train_filenames = tf.concat([train_cat_filenames, train_dog_filenames], axis=-1)\n",
    "    train_labels = tf.concat([\n",
    "        tf.zeros(train_cat_filenames.shape, dtype=tf.int32),\n",
    "        tf.ones(train_dog_filenames.shape, dtype=tf.int32)],\n",
    "        axis=-1\n",
    "    )\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_filenames, train_labels))\n",
    "    train_dataset = train_dataset.map(\n",
    "        map_func = _decode_and_resize,\n",
    "        num_parallel_calls = tf.data.experimental.AUTOTUNE\n",
    "    )# 取出前buffer_size个数据放入buffer，并从其中随机采样，采样后的数据用后续数据替换\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=23000)\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    summary_writer = tf.summary.create_file_writer('./tensorboard')     # 训练过程可视化，参数为记录文件所保存的目录\n",
    "\n",
    "    cp_callback_mc = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                        save_weights_only=True,\n",
    "                                                        verbose=0)\n",
    "\n",
    "    model = CNN()\n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    model.load_weights(latest)  \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
    "    )\n",
    "      \n",
    "    model.fit(train_dataset, epochs=num_epochs, callbacks=[cp_callback_mc])\n",
    "    model.summary()\n",
    "\n",
    "def test():\n",
    "    # 构建测试数据集\n",
    "    test_cat_filenames = tf.constant([test_cats_dir + filename for filename in os.listdir(test_cats_dir)])\n",
    "    test_dog_filenames = tf.constant([test_dogs_dir + filename for filename in os.listdir(test_dogs_dir)])\n",
    "    test_filenames = tf.concat([test_cat_filenames, test_dog_filenames], axis=-1)\n",
    "    test_labels = tf.concat([\n",
    "        tf.zeros(test_cat_filenames.shape, dtype=tf.int32), \n",
    "        tf.ones(test_dog_filenames.shape, dtype=tf.int32)], \n",
    "        axis=-1)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_filenames, test_labels))\n",
    "    test_dataset = test_dataset.map(_decode_and_resize)\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "    model = CNN()\n",
    "    # 加载权重\n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    model.load_weights(latest)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
    "    )\n",
    "        \n",
    "    print(model.metrics_names)\n",
    "    print(model.evaluate(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "360/360 [==============================] - 129s 358ms/step - loss: 0.0344 - sparse_categorical_accuracy: 0.9871\n",
      "Epoch 2/8\n",
      "360/360 [==============================] - 127s 353ms/step - loss: 0.0334 - sparse_categorical_accuracy: 0.9876\n",
      "Epoch 3/8\n",
      "360/360 [==============================] - 123s 341ms/step - loss: 0.0276 - sparse_categorical_accuracy: 0.9900\n",
      "Epoch 4/8\n",
      "360/360 [==============================] - 124s 343ms/step - loss: 0.0305 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 5/8\n",
      "360/360 [==============================] - 124s 344ms/step - loss: 0.0307 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 6/8\n",
      "360/360 [==============================] - 124s 344ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9922\n",
      "Epoch 7/8\n",
      "360/360 [==============================] - 123s 342ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9918\n",
      "Epoch 8/8\n",
      "360/360 [==============================] - 123s 341ms/step - loss: 0.0236 - sparse_categorical_accuracy: 0.9914\n",
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  9472      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  4160      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  2080      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            multiple                  1040      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            multiple                  12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            multiple                  4160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            multiple                  28800     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            multiple                  14400     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            multiple                  73856     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           multiple                  7200      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           multiple                  51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           multiple                  14400     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           multiple                  49280     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           multiple                  24640     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           multiple                  73856     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           multiple                  12320     \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           multiple                  51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           multiple                  24640     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           multiple                  98560     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           multiple                  24640     \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           multiple                  147712    \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           multiple                  12320     \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           multiple                  102528    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           multiple                  49280     \n",
      "_________________________________________________________________\n",
      "concatenate (Concatenate)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo multiple                  0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  196864    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  2570      \n",
      "=================================================================\n",
      "Total params: 1,112,634\n",
      "Trainable params: 1,112,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if __name__ ==  '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss']\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.4886 - sparse_categorical_accuracy: 0.9155\n",
      "[0.48864244050309935, 0.9155]\n"
     ]
    }
   ],
   "source": [
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_image(dir):\n",
    "    filename_list = os.listdir(dir)\n",
    "    ind = np.random.randint(0, filename_list.len())\n",
    "    return tf.constant([dir + filename_list[int]])\n",
    "\n",
    "def evaluate_one_image():\n",
    "    '''Test one image against the saved models and parameters\n",
    "    '''\n",
    "\n",
    "    # you need to change the directories to yours.\n",
    "    # 数据集路径\n",
    "    test_dir = 'F:/Downloads/fastai-datasets-cats-vs-dogs-2/test1/'\n",
    "    test_filename = get_one_image(test_dir)      #调用get_one_image随机选取一幅图片并显示\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        BATCH_SIZE = 1\n",
    "        N_CLASSES = 2\n",
    "\n",
    "        image = tf.cast(image_array, tf.float32)\n",
    "        image = tf.image.per_image_standardization(image)\n",
    "        image = tf.reshape(image, [1, 208, 208, 3])     #inference输入数据需要是4维数据，需要对image进行resize\n",
    "        logit = model.inference(image, BATCH_SIZE, N_CLASSES)       \n",
    "        logit = tf.nn.softmax(logit)    #inference的softmax层没有激活函数，这里增加激活函数\n",
    "\n",
    "        #因为只有一副图，数据量小，所以用placeholder\n",
    "        x = tf.placeholder(tf.float32, shape=[208, 208, 3])\n",
    "\n",
    "        # you need to change the directories to yours.\n",
    "        # 训练模型路径\n",
    "        logs_train_dir = 'D:/Test/Cats_vs_Dogs/logs/train'\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # 从指定路径下载模型\n",
    "            print(\"Reading checkpoints...\")\n",
    "            ckpt = tf.train.get_checkpoint_state(logs_train_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "                print('Loading success, global_step is %s' % global_step)\n",
    "            else:\n",
    "                print('No checkpoint file found')\n",
    "\n",
    "            prediction = sess.run(logit, feed_dict={x: image_array})\n",
    "            # 得到概率最大的索引\n",
    "            max_index = np.argmax(prediction)\n",
    "            if max_index==0:\n",
    "                print('This is a cat with possibility %.6f' %prediction[:, 0])\n",
    "            else:\n",
    "                print('This is a dog with possibility %.6f' %prediction[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
