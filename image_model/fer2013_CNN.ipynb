{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           multiple                  64        \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           multiple                  320       \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           multiple                  832       \n",
      "_________________________________________________________________\n",
      "concatenate_8 (Concatenate)  multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           multiple                  55360     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           multiple                  73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             multiple                  1179904   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             multiple                  1799      \n",
      "=================================================================\n",
      "Total params: 1,312,135\n",
      "Trainable params: 1,312,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "data_dir = './data/fer2013/'\n",
    "# 0 anger 生气； 1 disgust 厌恶； 2 fear 恐惧； 3 happy 开心； 4 sad 伤心；5 surprised 惊讶； 6 normal 中性\n",
    "train_anger_dir = data_dir + 'train/0/'\n",
    "train_disgust_dir = data_dir + 'train/1/'\n",
    "train_fear_dir = data_dir + 'train/2/'\n",
    "train_happy_dir = data_dir + 'train/3/'\n",
    "train_sad_dir = data_dir + 'train/4/'\n",
    "train_surprised_dir = data_dir + 'train/5/'\n",
    "train_normal_dir = data_dir + 'train/6/'\n",
    "\n",
    "test_anger_dir = data_dir + 'valid/0/'\n",
    "test_disgust_dir = data_dir + 'valid/1/'\n",
    "test_fear_dir = data_dir + 'valid/2/'\n",
    "test_happy_dir = data_dir + 'valid/3/'\n",
    "test_sad_dir = data_dir + 'valid/4/'\n",
    "test_surprised_dir = data_dir + 'valid/5/'\n",
    "test_normal_dir = data_dir + 'valid/6/'\n",
    "\n",
    "checkpoint_path = \"training_fer2013_CNN_1/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "def _decode_and_resize(filename, label):\n",
    "    image_string = tf.io.read_file(filename)                   # 读取原始文件\n",
    "    image_decoded = tf.image.decode_jpeg(image_string)         # 解码JPEG图片\n",
    "    image_resized = tf.image.resize(image_decoded, [48, 48]) / 255.0\n",
    "    return image_resized, label\n",
    "\n",
    "class CNN(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv11 = tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=[1, 1],\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    self.conv12 = tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=[3, 3],\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    self.conv13 = tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    self.concatenate = tf.keras.layers.Concatenate()\n",
    "    self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "    self.conv2 = tf.keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=[3, 3],\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "    self.conv3 = tf.keras.layers.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=[3, 3],\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    self.pool3 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "    self.flatten = tf.keras.layers.Reshape(target_shape=(6 * 6 * 128,))\n",
    "    self.dense1 = tf.keras.layers.Dense(units=256, activation=tf.nn.relu)\n",
    "    self.dense2 = tf.keras.layers.Dense(units=7)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x1 = self.conv11(inputs)  # [48, 48, 32]\n",
    "    x2 = self.conv12(inputs)  # [48, 48, 32]\n",
    "    x3 = self.conv13(inputs)  # [48, 48, 32]\n",
    "    x = self.concatenate([x1, x2, x3]) # [48, 48, 96]\n",
    "    x = self.pool1(x)    # [24, 24, 96]\n",
    "    x = self.conv2(x)    # [24, 24, 64]\n",
    "    x = self.pool2(x)    # [12, 12, 64]\n",
    "    x = self.conv3(x)    # [12, 12, 128]\n",
    "    x = self.pool3(x)    # [6, 6, 128]\n",
    "    x = self.flatten(x)   # [6*6*128]\n",
    "    x = self.dense1(x)    # [256]\n",
    "    x = self.dense2(x)    # [7]\n",
    "    output = tf.nn.softmax(x)\n",
    "    return output\n",
    "\n",
    "def train():\n",
    "    # 构建训练数据集\n",
    "    # 0 anger 生气； 1 disgust 厌恶； 2 fear 恐惧； 3 happy 开心； 4 sad 伤心；5 surprised 惊讶； 6 normal 中性\n",
    "    train_anger_filenames = tf.constant([train_anger_dir + filename for filename in os.listdir(train_anger_dir)])\n",
    "    train_disgust_filenames = tf.constant([train_disgust_dir + filename for filename in os.listdir(train_disgust_dir)])\n",
    "    train_fear_filenames = tf.constant([train_fear_dir + filename for filename in os.listdir(train_fear_dir)])\n",
    "    train_happy_filenames = tf.constant([train_happy_dir + filename for filename in os.listdir(train_happy_dir)])\n",
    "    train_sad_filenames = tf.constant([train_sad_dir + filename for filename in os.listdir(train_sad_dir)])\n",
    "    train_surprised_filenames = tf.constant([train_surprised_dir + filename for filename in os.listdir(train_surprised_dir)])\n",
    "    train_nromal_filenames = tf.constant([train_normal_dir + filename for filename in os.listdir(train_normal_dir)])\n",
    "    train_filenames = tf.concat([train_anger_filenames, train_disgust_filenames, train_fear_filenames, train_happy_filenames, train_sad_filenames, train_surprised_filenames, train_nromal_filenames], axis=-1)\n",
    "    train_labels = tf.concat([\n",
    "        tf.zeros(train_anger_filenames.shape, dtype=tf.int32),\n",
    "        tf.ones(train_disgust_filenames.shape, dtype=tf.int32),\n",
    "        tf.ones(train_fear_filenames.shape, dtype=tf.int32) * 2,\n",
    "        tf.ones(train_happy_filenames.shape, dtype=tf.int32) * 3,\n",
    "        tf.ones(train_sad_filenames.shape, dtype=tf.int32) * 4,\n",
    "        tf.ones(train_surprised_filenames.shape, dtype=tf.int32) * 5,\n",
    "        tf.ones(train_nromal_filenames.shape, dtype=tf.int32) * 6],\n",
    "        axis=-1\n",
    "    )\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_filenames, train_labels))\n",
    "    train_dataset = train_dataset.map(\n",
    "        map_func = _decode_and_resize,\n",
    "        num_parallel_calls = tf.data.experimental.AUTOTUNE\n",
    "    )# 取出前buffer_size个数据放入buffer，并从其中随机采样，采样后的数据用后续数据替换\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=23000)\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    model.fit(train_dataset, epochs=num_epochs, callbacks=[cp_callback_mc])\n",
    "\n",
    "def test():\n",
    "    # 构建测试数据集\n",
    "    test_anger_filenames = tf.constant([test_anger_dir + filename for filename in os.listdir(test_anger_dir)])\n",
    "    test_disgust_filenames = tf.constant([test_disgust_dir + filename for filename in os.listdir(test_disgust_dir)])\n",
    "    test_fear_filenames = tf.constant([test_fear_dir + filename for filename in os.listdir(test_fear_dir)])\n",
    "    test_happy_filenames = tf.constant([test_happy_dir + filename for filename in os.listdir(test_happy_dir)])\n",
    "    test_sad_filenames = tf.constant([test_sad_dir + filename for filename in os.listdir(test_sad_dir)])\n",
    "    test_surprised_filenames = tf.constant([test_surprised_dir + filename for filename in os.listdir(test_surprised_dir)])\n",
    "    test_nromal_filenames = tf.constant([test_normal_dir + filename for filename in os.listdir(test_normal_dir)])\n",
    "    test_filenames = tf.concat([test_anger_filenames, test_disgust_filenames, test_fear_filenames, test_happy_filenames, test_sad_filenames, test_surprised_filenames, test_nromal_filenames], axis=-1)\n",
    "    test_labels = tf.concat([\n",
    "        tf.zeros(test_anger_filenames.shape, dtype=tf.int32),\n",
    "        tf.ones(test_disgust_filenames.shape, dtype=tf.int32),\n",
    "        tf.ones(test_fear_filenames.shape, dtype=tf.int32) * 2,\n",
    "        tf.ones(test_happy_filenames.shape, dtype=tf.int32) * 3,\n",
    "        tf.ones(test_sad_filenames.shape, dtype=tf.int32) * 4,\n",
    "        tf.ones(test_surprised_filenames.shape, dtype=tf.int32) * 5,\n",
    "        tf.ones(test_nromal_filenames.shape, dtype=tf.int32) * 6],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_filenames, test_labels))\n",
    "    test_dataset = test_dataset.map(_decode_and_resize)\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    \n",
    "    print(model.evaluate(test_dataset))\n",
    "    \n",
    "if __name__ ==  '__main__':\n",
    "    model = CNN()\n",
    "    model.build(input_shape=(None, 48, 48, 1))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                    metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "    \n",
    "    cp_callback_mc = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                        save_weights_only=True,\n",
    "                                                        verbose=0)\n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    if(latest != None):\n",
    "        model.load_weights(latest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "225/225 [==============================] - 159s 708ms/step - loss: 0.1011 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 2/30\n",
      "225/225 [==============================] - 161s 713ms/step - loss: 0.0844 - sparse_categorical_accuracy: 0.9765\n",
      "Epoch 3/30\n",
      "225/225 [==============================] - 164s 730ms/step - loss: 0.0772 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 4/30\n",
      "225/225 [==============================] - 169s 752ms/step - loss: 0.0673 - sparse_categorical_accuracy: 0.9820\n",
      "Epoch 5/30\n",
      "225/225 [==============================] - 166s 738ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9827\n",
      "Epoch 6/30\n",
      "225/225 [==============================] - 159s 709ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9759\n",
      "Epoch 7/30\n",
      "225/225 [==============================] - 160s 711ms/step - loss: 0.0610 - sparse_categorical_accuracy: 0.9834\n",
      "Epoch 8/30\n",
      "225/225 [==============================] - 160s 713ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9842\n",
      "Epoch 9/30\n",
      "225/225 [==============================] - 160s 709ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9831\n",
      "Epoch 10/30\n",
      "225/225 [==============================] - 161s 713ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9830\n",
      "Epoch 11/30\n",
      "225/225 [==============================] - 159s 708ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9815\n",
      "Epoch 12/30\n",
      "225/225 [==============================] - 160s 709ms/step - loss: 0.0505 - sparse_categorical_accuracy: 0.9873\n",
      "Epoch 13/30\n",
      "225/225 [==============================] - 159s 708ms/step - loss: 0.0479 - sparse_categorical_accuracy: 0.9867\n",
      "Epoch 14/30\n",
      "225/225 [==============================] - 161s 715ms/step - loss: 0.0503 - sparse_categorical_accuracy: 0.9865\n",
      "Epoch 15/30\n",
      "225/225 [==============================] - 160s 712ms/step - loss: 0.0647 - sparse_categorical_accuracy: 0.9820\n",
      "Epoch 16/30\n",
      "225/225 [==============================] - 159s 709ms/step - loss: 0.0634 - sparse_categorical_accuracy: 0.9814\n",
      "Epoch 17/30\n",
      "225/225 [==============================] - 162s 720ms/step - loss: 0.0511 - sparse_categorical_accuracy: 0.9858\n",
      "Epoch 18/30\n",
      "225/225 [==============================] - 165s 735ms/step - loss: 0.0386 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 19/30\n",
      "225/225 [==============================] - 163s 724ms/step - loss: 0.0360 - sparse_categorical_accuracy: 0.9912\n",
      "Epoch 20/30\n",
      "225/225 [==============================] - 163s 723ms/step - loss: 0.0573 - sparse_categorical_accuracy: 0.9842\n",
      "Epoch 21/30\n",
      "225/225 [==============================] - 163s 725ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9848\n",
      "Epoch 22/30\n",
      "225/225 [==============================] - 162s 720ms/step - loss: 0.0458 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 23/30\n",
      "225/225 [==============================] - 168s 746ms/step - loss: 0.0478 - sparse_categorical_accuracy: 0.9862\n",
      "Epoch 24/30\n",
      "225/225 [==============================] - 162s 720ms/step - loss: 0.0365 - sparse_categorical_accuracy: 0.9908\n",
      "Epoch 25/30\n",
      "225/225 [==============================] - 162s 722ms/step - loss: 0.0343 - sparse_categorical_accuracy: 0.9915\n",
      "Epoch 26/30\n",
      "225/225 [==============================] - 162s 722ms/step - loss: 0.0394 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 27/30\n",
      "225/225 [==============================] - 162s 718ms/step - loss: 0.0571 - sparse_categorical_accuracy: 0.9837\n",
      "Epoch 28/30\n",
      "225/225 [==============================] - 160s 713ms/step - loss: 0.0525 - sparse_categorical_accuracy: 0.9842\n",
      "Epoch 29/30\n",
      "225/225 [==============================] - 161s 714ms/step - loss: 0.0391 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 30/30\n",
      "225/225 [==============================] - 162s 720ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9872\n"
     ]
    }
   ],
   "source": [
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 7s 242ms/step - loss: 4.2449 - sparse_categorical_accuracy: 0.5464\n",
      "[4.2448750611009265, 0.5463917]\n"
     ]
    }
   ],
   "source": [
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
